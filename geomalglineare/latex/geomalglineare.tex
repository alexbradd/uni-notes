\documentclass[a4paper,12pt,oneside]{article}
\usepackage[a4paper,margin=1.5cm]{geometry}
\usepackage[italian]{babel}
\usepackage[utf8]{inputenc}
\usepackage[normalem]{ulem}

% Uncomment based on usage
\usepackage{mathtools}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{float}
\usepackage{soulutf8}
%\usepackage{enumerate}
%\usepackage{graphicx}
%\usepackage{wrapfig}
%\usepackage{xcolor}

\title{Appunti Geometria e algebra lineare}
\author{Alexandru Gabriel Bradatan}
\date{Data di compilazione: \today}

\begin{document}

\maketitle

\section{Insiemi}
\hl{Un insieme è una collezione di oggetti}. Tutta la matematica si basa
sulla teoria assiomatica degli insiemi. \hl{Un insieme A si può indicare
per elencazione ($A = \{a_1, \dots, a_n\}$) o con una condizione
($A = \{x|\textit{condizione}\}$)}. La \hl{cardinalità di $A$ è il numero di
oggetti: $|A| = n$}. La cardinalità dell'insieme vuoto è 0.

\paragraph{Esempi} $\mathbb{N} = \{0, 1, 2,\dots\}$,
$\mathbb{Q} = \{q = \frac{m}{n} | m,n \in \mathbb{Z}, n \neq 0\}$,
$\mathbb{R} = \{\text{x numeri decimali}\}$.

Un \hl{insieme particolare è l'insieme con nessun elemento detto vuoto, indicato
con $\emptyset$}. Un altro insieme particolare è \hl{l'insieme di tutti gli tutto
detto insieme universo $U$}.

\subsection{Sottoinsiemi}
Un insieme può essere sottoinsieme di un altro, ossia contenere una parte degli
elementi dell'insieme più grande. Formalizzando si può dire che:
\[
    A \subset B \implies \forall a \in A, a \in B
\]

\subsection{Insiemi numerici}
Trattati nel dettaglio negli appunti di \hl{Analisi 1}.

\subsection{Operazioni}
Le operazioni più usate sono:
\begin{description}
    \item[Unione] $A \cup B = \{x | x \in A \vee x \in B\}$
    \item[Intersezione] $A \cap B = \{x | x \in A \wedge x \in B\}$
    \item[Complementare] $A^C = \bar{A} = \{x \in U | x \notin A\}$
    \item[Differenza] $A - B = \{x | x \in A \wedge x \notin B\}$
        Si può anche trovare indicata con $ \setminus $
    \item[Prodotto cartesiano] $A \times B = \{(a,b) | a \in A, b \in B \}$
        Le coppie $(a,b)$ sono anche dette \hl{coppie} (m-uple per $m$ elementi)
\end{description}

\section{Relazioni}
\hl{Una relazione è un sottoinsieme del prodotto cartesiano tra due insiemi}.

Per indicare che due elementi $(a_i, b_j)$ sono legati da una relazione
$R$ usiamo \hl{$a_i \sim_R b_j$}. Per rappresentare le relazioni si possono usare i
diagrammi di Venn (le patate) con le frecce che collegano i vari elementi tra di
loro.

\paragraph{Esempio} Presi $A = \{a_1, a_2\}, B = \{b_1, b_2\}$, calcoliamo il
loro prodotto cartesiano e otterremo 16 possibili sottoinsiemi:
\begin{align*}
    R_0 &= \emptyset \\
    R_1 &= \{(a_1, b_1)\}, \dots, R_4 \\
    R_5 &= \{(a_1, b_1), (a_1, b_2)\}, \dots, R_{10} \\
    R_{11} &= \{(a_1, b_1), (a_1, b_2), (a_2, b_1)\}, \dots, R_{14} \\
    R_{15} &= A \times B
\end{align*}

\subsection{Relazioni particolari}
\paragraph{Relazione d'ordine} Prendiamo una \hl{relazione
$R \subseteq A \times A$, essa è d'ordine se}:
\begin{itemize}
    \item \hl{è riflessiva}: $(a,a) \in R \forall a \in R$
    \item \hl{è antisimmetrica}: $(a,b),(b,a) \in R \implies a=b$
    \item \hl{è transitiva}: $(a,b), (b,c) \in R \implies (a,c) \in R$
\end{itemize}

\subparagraph{Insieme totalmente e parzialmente ordinato} Siano $A$ un insieme ed
$R$ una relazione d’ordine su $A$. \hl{Se per ogni $a1 , a2 \in A$ vale
$(a1, a2) \in R$ oppure $(a2 , a1 ) \in R$, $R$ si dice relazione d’ordine
totale e la coppia $(A, R)$ si dice insieme totalmente ordinato. In caso
contrario si dice che $R$ è una relazione d’ordine parziale e la coppia $(A, R)$
si dice insieme parzialmente ordinato}.

\paragraph{Relazione di equivalenza} Prendiamo una \hl{relazione
$R \subseteq A \times A$, essa è di equivalenza se}:
\begin{itemize}
    \item \hl{è riflessiva}: $(a,a) \in R \forall a \in R$
    \item \hl{è simmetrica}: $(a,b) \in R \implies (b,a) \in R$
    \item \hl{è transitiva}: $(a,b), (b,c) \in R \implies (a,c) \in R$
\end{itemize}
Una modo di vedere la relazione di equivalenza è come \hl{generalizzazione
dell'uguaglianza}.

\subparagraph{Classe di equivalenza} Data una relazione di equivalenza $R$, preso
un elemento $a$, la \hl{classe di equivalenza di $a$ sono tutti gli elementi
equivalenti equivalenti ad $a$, ossia:}
    \[ {[a]}_R = \{ b \in A | a \sim_R a \} \]
La classe di equivalenza è in sostanza l'insieme di tutti gli elementi
equivalenti tra di loro.

\hl{Teorema}: Ogni elemento $a \in A$ appartiene a una sola classe di equivalenza
(dimostrazione nella dispensa, teorema 2.38).
\hl{Teorema}: Un insieme $A$ sul quale agisce una relazione di equivalenza $R$
è l'unione disgiunta delle sue classi di equivalenza.

\subparagraph{Insieme quoziente} \hl{L'insieme quoziente $A/R$} di $A$ rispetto
a una relazione di equivalenza $R$ è \hl{l'insieme di tutte le classi di
equivalenza}.

\section{Funzioni}
\hl{Le funzioni sono speciali relazioni che associano a ogni elemento del
primo insieme un solo elemento del secondo}. Una funzione in genere si indica
con la lettera minuscola e usa questa notazione: \[ f: A \to B \]
\hl{L'insieme $A$ è detto dominio, $B$ il codominio. L'insieme di tutte le
possibili funzioni che vanno da $A$ a $B$ si indica con $B^A$.}

Preso \hl{$a \in A, b = f(a)$ sarà la sua immagine}. La \hl{controimmagine
di $b$ è l'elemento tale che $f^{-1}(b) = \{ a \in A | f(a) = b \}$}

\hl{L'insieme di tutte le immagini è detto insieme immagine} e si indica con
$Im(f)$.

\paragraph{Funzione particolare} \hl{La funzione
$A \times A = \Delta A = Id(A) = \{(a,a) | a \in A\}$ è detta funzione identità
o insieme diagonale}.

\paragraph{Iniettività} Una funzione è detta \hl{iniettiva se
$\forall a,b \in A, a \neq b \implies f(a) \neq f(b)$}.

\paragraph{Suriettività} Una funzione è detta \hl{suriettiva se
$\forall b \in B, \exists a \in A | f(a) = b$}.

\paragraph{Funzione biunivoca} Se una funzione è \hl{sia iniettiva che
suriettiva è detta biunivoca}. Se una funzione è biunivoca può essere invertita
ottenendo $f^{-1}: B \to A$.

\paragraph{Composizione di funzioni} Date due funzioni $f: A \to B, g: B \to C$,
la composizione $g \circ f$ delle due è una nuova funzione tale che
$g \circ f: A \to C$. Ciò equivale a dire che $(g \circ f)(a) = g(f(a))$

\section{Operazioni}
Le operazioni sono delle \hl{speciali funzioni: dati $n+1$ insiemi
$A_1, \dots, A_{n+1}$ non vuoti, una operazione n-aria $\ast$ è una funzione
che}:\[
    \begin{array}{cccc}
        \ast: &A_1 \times \cdots \times A_{n} &\to &A_{n+1} \\
        &(a_1, \dots, a_n) &\mapsto & \ast (a_1, \dots, a_n)
    \end{array}
\]
Se \hl{$A_1 = \cdots = A_{n+1}$ allora l'operazione è detta interna}, altrimenti
è detta esterna. Se \hl{$n = 2$ allora l'operazione è detta binaria} e si può
indicare con $a_1 \ast a_2$.

\paragraph{Esempi}La somma + un'operazione binaria interna a $\mathbb{N}$
\[
    \begin{array}{cccc}
       +: &\mathbb{N} \times \mathbb{N} &\to &\mathbb{N} \\
        &(n1, n2) &\mapsto &n3 = n1 + n2
    \end{array}
\]
La differenza è sempre un'operazione binaria, ma esterna ad $\mathbb{N}$
\[
    \begin{array}{cccc}
        -: &\mathbb{N} \times \mathbb{N} &\to &\mathbb{Z} \\
        &(n1, n2) &\mapsto &n3 = n1 - n2
    \end{array}
\]

Le varie operazioni possono essere rappresentate in tabelle che indicano tutti i
possibili casi. Ad esempio, esistono $2^4 = 16$ diverse operazioni binarie
interne ($\ast: A \times A \to A$) ad $A = \{a_1, a_2\}$.

\paragraph{Proprietà delle operazioni} Le operazioni possono godere di alcune
proprietà:
\begin{description}
    \item[Elemento neutro] $a \ast e = a$
    \item[Inverso] $a \ast a^{-1} = e$
    \item[Proprietà commutativa] $a \ast b = b \ast a$
    \item[Proprietà assocativa] $a \ast (b \ast c) = (a \ast b) \ast c$
    \item[Proprietà distributiva] Lega due operazioni:
        $a \cdot (b \ast c) = (a \cdot b) \ast (a \cdot c)$
\end{description}

\section{Struttura algebrica}
\hl{Dicesi struttura algebrica l'insieme di un certo numero di insiemi
$A_1, \ldots, A_n$, chiamato \textit{supporto della struttura} e delle
operazioni $\ast_1, \ldots, \ast_n$ su questi insiemi.}

Tre importanti strutture sono \hl{il gruppo, l'anello e il campo}.

\subsection{Il gruppo}
Il gruppo è una struttura algebrica del tipo $(G, \ast)$ dove \hl{$G$ è un insieme
e $\ast$ è un'operazione binaria interna a $G$} che deve rispettare \hl{queste date proprietà $\forall a \in G$:}
\begin{itemize}
    \item \hl{Deve possedere l'elemento neutro in $G$}
    \item \hl{Deve possedere l'inverso in $G$}
    \item \hl{Deve godere della proprietà associativa}
\end{itemize}
Se l'operazione è anche \hl{commutativa il gruppo viene detto abeliano}.

\subsection{L'anello}
Un anello è una \hl{struttura algebrica del tipo $(A, \ast, \cdot)$} dove le due
operazioni devono soddisfare le \hl{seguenti proprietà}:
\begin{itemize}
    \item \hl{$(A, \ast)$ è un gruppo abeliano}
    \item \hl{$\cdot$ deve avere elemento neutro in $A$}
    \item \hl{$\cdot$ deve godere della proprietà associativa}
    \item \hl{$\cdot$ e $\ast$ devono essere legate dalla proprietà distributiva}
\end{itemize}
Se \hl{la seconda operazione è commutativa, allora l'anello si dice commutativo}.

\subsection{Il campo}
Un campo è una \hl{struttura algebrica del tipo $(K, \ast, \cdot)$} dove le due
operazioni devono soddisfare le \hl{seguenti proprietà}:
\begin{itemize}
    \item \hl{$(K, \ast)$ deve essere un gruppo abeliano con elemento neutro $e$}
    \item Detto $K^* = K - {e}$, \hl{$(K^*, \cdot)$ deve essere un gruppo abeliano}
    \item \hl{Le due operazioni sono legate dalla proprietà distributiva}
\end{itemize}

Il campo $(\mathbb{R}, +, \times)$ è uno dei campi più importanti.

\subsection{Omomorfismo}
\hl{Un omomorfismo tra due strutture algebriche è una funzione $f$ che commuta
tra le due con le loro operazioni}. Se \hl{$f$ è invertibile}, allora viene
chiamata \hl{isomorfismo}.

\paragraph{Omomorfismo di gruppi} Dati due gruppi $(A, \ast)$ e $(B, \cdot)$ la
funzione \hl{$f: A \to B$ è un omomorfismo se}
\[
    f(a_1 \ast a_2) = f(b_1) \cdot f(b_2)
\]

\paragraph{Omomorfismo di campo} Dati due campi $(A, \ast_1, \cdot_1)$ e
$(B, \ast_2, \cdot_2)$ la funzione \hl{$f: A \to B$ è un omomorfismo se}
\[
    f(a_1 \ast_1 a_2) = f(b_1) \ast_2 f(b_2) \wedge
        f(a_1 \cdot_1 a_2) = f(b_1) \cdot_2 f(b_2)
\]

\section{Polinomi}
Un polinomio $P(x)$ è una \hl{particolare funzione della forma}:
\[
    P(x) = \sum_{i=0}^{n} a_i x^i \text{ con } n \in \mathbb{N}
\]
Dove \hl{$(a_1, \ldots, a_n)$ (i coefficienti) appartengono a un campo $K^{n+1}$}.
\hl{L'insieme di tutti i possibili coefficienti si indica con $K[x]$}.
Un polinomio nelle m variabili $x_1, \dots ,x_m$ è definito induttivamente come
l’espressione:
\[
    P(x_1, \ldots, x_m) = \sum_{i=0}^n Q_i(x_1, \ldots, x_{m-1})x_m^i
\]
dove $Q_1, \ldots, Q_n$ sono polinomi nelle prime $m - 1$ variabili. L’insieme
di tutti i polinomi di questo tipo si indica con $K[x_1, \ldots, x_m]$.

Se il campo \hl{$K$ coincide con il campo dei reali ($(\mathbb{R}, +, \times)$)
allora $K[x] = \mathbb{R}[x]$} e sarà l'insieme di tutti i possibili polinomi
con variabile reale.

Un polinomio è generalmente scritto come somma di monomi.

\paragraph{Il grado di un polinomio} Il grado di un polinomio $P(x)$ è il
\hl{massimo grado dei suoi monomi con grado diverso da 0}. Il polinomio nullo
ha per definizione grado indeterminato.

\subsection{Divisione tra polinomi}
Data la coppia \hl{$(A, B) \in K[x] \times K[x], B \neq 0$, esiste una sola coppia
$(Q, R) \in K[x] \times K[x]$ tale che $A = QB + R$ per la quale $grado(R) < grado(Q)$
o $grado(R) = 0$}. $Q$ e $R$ sono rispettivamente quoziente e resto della divisione
di $A$ e $B$.

\paragraph{Molteplicità algebrica} Dati \hl{$P \in K[x], r \in \mathbb{N}$} esiste
un valore \hl{$m < grado(P)$} tale che \hl{${(x-r)}^m$ divida $P(x)$}. Tale valore è
detto \hl{molteplicità algebrica di $r$ rispetto a $P$. La $r$ sarà la radice} del
polinomio. \hl{Se la molteplicità algebrica di $r$ è $1$, $r$ è una radice semplice.}

\paragraph{Chiusura algebrica} Le \hl{radici di un polinomio $P \in K[x]$} di grado
$n$ rispettano la regola \\ \hl{$m_1 + \cdots + m_i \leq n$} dove \hl{$m_i$ è la
molteplicità algebrica di $r_i$} con $i = 1, \ldots, k$. \hl{Per ogni campo $K$
esisterà un altro campo $\bar{K}$ che lo contiene} tale che ogni polinomio
appartenente ad esso \hl{abbia le radici che soddisfino $m_1 + \cdots + m_i = n$}.
Tale campo è detto \hl{chiusura algebrica di $K$}. Se \hl{$K$ e la sua chiusura
coincidono, $K$ si dice algebricamente completo}.

\hl{Il campo dei $\mathbb{C}$ è algebricamente chiuso, è la chiusura algebrica di
$\mathbb{R}$ e contiene la chiusura algebrica di $\mathbb{Q}$}.

\section{Matrici}
Le matrici sono uno strumento fondamentale per fare i conti in matematica.

Dati due insiemi \hl{$M = {1, \ldots, m}$ e $N = {1, \ldots, n}$, una matrice di
ordine $(m, n)$ ad elementi nel campo $K$ è una funzione definita come}:
\[
    \begin{array}{cccc}
        A: &M \times N &\to &K \\
        &(i,j) &\mapsto &a_{ij}
    \end{array}
\]
L'insieme di \hl{tutte le matrici di ordine $(m,n)$ su $K$ viene indicato con
$Mat(m,n;K)$}.

\paragraph{Matrici particolari} La matrice nulla è indicata con $0_{mn}$. La
matrice identità $I_{mn}$ è, invece, una matrice del tipo:
\[
    \begin{array}{cccc}
        I_{mn}: & M \times N & \to & K \\
        & (m,n) & \mapsto & \Delta
    \end{array} \text{ con } \Delta{} = 1 \text{ se } i = j
\]

\paragraph{Rappresentazione} Una matrice può essere pensata come una tabella di
numeri di $m$ righe ed $n$ colonne:
\[
    A =
    \bordermatrix{~ & 1 & \cdots & n \cr
                  1 & a_{11} & \cdots & a_{1n} \cr
                  \vdots & \vdots & \ddots & \vdots \cr
                  m & a_{m1} & \cdots & a_{mn} \cr }
    \in Mat(m,n;K)
\]
Una matrice si può anche indicare con la notazione $[a_{ij}]$.

\paragraph{Il rango di una matrice} \hl{Il rango $r(A)$ di una matrice $A$ è il
rango di una matrice a scala $S$ ottenuta tramite riduzione di Gauss di $A$}.

\subsection{Le matrici quadrate}
Data una matrice $A \in Mat(m,n;\mathbb{K})$, essa è quadrata se \hl{$m = n$}.
Una matrice quadrata si \hl{indica con $Mat(m,\mathbb{K})$}. Solo le matrici
quadrate sono matrici invertibili (teorema che non abbiamo fatto).

\paragraph{Matrici quadrate particolari} Se $a_{ij} = 0$ per
\begin{itemize}
    \item $i>j$ è triangolare alta
    \item $i \leq j$ è strettamente triangolare alta
    \item $i<j$ è triangolare bassa
    \item $i \geq j$ è strettamente triangolare bassa
    \item $i \neq j$ è diagonale
\end{itemize}
Inoltre se $a_{ij} = a_{ji}$ la matrice è simmetrica, invece se $a_{ij} = a_{ji}$
viene detta antisimmetrica.

\subsection{Matrice invertibile}
Prese tre matrici quadrate $A, B, C$ allora:
\begin{itemize}
    \item $B$ si dice \hl{inversa sinistra se $BA = I_{n}$}
    \item $C$ si dice \hl{inversa destra se $AC = I_{n}$}
\end{itemize}
\hl{$A$ si dice invertibile se $B = C$}. La matrice inversa di $A$ è unica e
si indica con $A^{-1}$.

\paragraph{Teorema di caratterizzazione delle matrici invertibili} Possiamo
affermare che \hl{$\exists A^{-1}$} se e solo se:
\begin{itemize}
    \item \hl{$r(A) = n$}
    \item Esiste l'inversa sinistra o la destra
\end{itemize}

\subsection{La matrice trasposta}
Data una matrice $A$, la matrice trasposta è \hl{un'altra matrice $A^T$ che si
ottiene trasformando tutte le righe in colonne e viceversa}:
\[
    A \in Mat(m,n;K); A^T \in Mat(n,m,K)
\]

\subsection{Operazioni con le matrici}
\begin{description}
    \item[Somma] \'E un'operazione binaria interna. Somma gli elementi uno a uno:
        \[
            \begin{array}{cccc}
                +: & Mat(m,n;K) \times Mat(m,n;K) & \to &Mat(m,n;K) \\
                & ([a_{ij}], [b_{ij}]) &\mapsto  & [a_{ij} + b_{ij}]
            \end{array}
        \]
    \item[Prodotto con scalare] \'E un'operazione binaria esterna:
        \[
            \begin{array}{cccc}
                \cdot: & K \times Mat(m,n;K) & \to &Mat(m,n;K) \\
                & (t, [a_{ij}]) &\mapsto  & [t \cdot a_{ij}]
            \end{array}
        \]
    \item[Prodotto matriciale] \'E un'operazione binaria esterna:
        \[
            \begin{array}{cccc}
                \ast: & Mat(m,p;K) \times Mat(p,n;K) & \to &Mat(m,n;K) \\
                & ([a_{ij}], [b_{ij}]) &\mapsto  & [\sum_{k=0}^p a_{ik}b_{kj}]
            \end{array}
        \]
        \hl{Osserva: il numero di colonne della prima deve essere uguale al numero
            di righe della seconda!}
\end{description}

\paragraph{Proprietà della somma} La struttura $(Mat(m,n:\mathbb{r}), +)$ è un
gruppo abeliano quindi:
\begin{itemize}
    \item \hl{\'E commutativa}: $A + B = B + A$
    \item \hl{\'E associativa}: $(A + B) + C = A + (B + C)$
    \item \hl{Esiste l'elemento neutro} $e = 0_{mn}$
    \item \hl{Esiste l'inverso}: $A + (-A) = 0_{mn}$
\end{itemize}

\paragraph{Proprietà del prodotto con scalare}
\begin{itemize}
    \item \hl{\'E distributiva con la somma}: $k (A + B) = kA + kB$
    \item \hl{\'E distributiva con la somma in $K$}: $(j + k)A = jA + kA$
    \item \hl{\'E omogenea rispetto alla moltiplicazione in $K$}:
        $(jk)A = j(kA)$
    \item \hl{Esiste la normalizzazione} $A = 1 \cdot A$
\end{itemize}

\paragraph{Proprietà del prodotto matriciale}
\begin{itemize}
    \item \hl{Non vale la proprietà commutativa}
    \item \hl{Non esiste l'annullamento}
    \item \hl{L'elemento neutro è $I_{m}A_{mn} = A, A_{mn}I_{n} = A$}
    \item \hl{Non esiste l'inverso}
    \item \hl{\'E associativo}
    \item \hl{\'E distributivo con la somma}: $A(B+C) = (AB) + (AC)$
    \item \hl{\'E omogenea con l'altro prodotto}: $t(AB) = (tA)B = A(tB)$
\end{itemize}

\subsection{Pivot e matrice a scala}
\paragraph{Pivot} Un pivot $Pi$ è \hl{il primo elemento non nullo della riga $i$}
della matrice.

\paragraph{Matrice a scala} Una matrice nella quale \hl{il pivot della prima riga
compare prima del pivot della seconda riga, che a sua volta compare prima del
pivot della terza riga e così andare}, con le eventuali righe nulle per ultime, si
dice matrice a scala.
\[
    A =
    \begin{bmatrix}
        P1 & *  & *  & * \\
        0  & P2 & *  & * \\
        0  & 0  & P3 & * \\
        0  & 0  & 0  & P4 \\
        & & 0_{m-r, n} &
    \end{bmatrix} \in Mat(m,n;K)
\]

\paragraph{Il rango di una matrice a scala} \hl{Il rango $r(S)$ di una matrice
a scala $S$ è il numero di pivot in $S$}.

\subsection{Eliminazione di Gauss}
Il metodo di eliminazione di Gauss ci permette \hl{di ridurre qualsiasi matrice
in una nuova matrice a scala tramite alcune operazioni }. Esisteranno \hl{diverse
riduzioni, ma tutte hanno lo stesso rango}.

\paragraph{Le operazioni di Gauss}
\begin{description}
    \item[Permutazione] Scambio due righe tra di loro
    \item[Moltiplicazione per uno scalare non nullo] Moltiplico tutti gli elementi
        di una riga per un numero diverso da $0$
    \item[Somma tra righe] Sommo uno a uno gli elementi di due righe e la riga
        risultante la inserisco al posto di uno dei due addendi:
        $A_{R(i)} \to A_{R(i)} + tA_{R(j)} \text{ con } i \neq j$
\end{description}

\section{Sistemi lineari}
Un sistema lineare è un insieme di espressioni che hanno questa forma:
\[
    \begin{cases}
        a_{11}x_1 + \cdots + a_{1n}x_n = b_1 \\
        \cdots + \cdots + \cdots = \cdots \\
        a_{m1}x_1 + \cdots + a_{mn}a_n = b_m
    \end{cases}
\]
Dove:
\begin{itemize}
    \item $a_{ij}, b_i \in K$
    \item $x_n$ sono incognite
    \item $1 \leq i \leq m, 1 \leq j \leq n$
\end{itemize}

\hl{Un sistema lineare può anche essere scritto come un'equazione matriciale:}
\begin{align*}
    & A =
    \begin{bmatrix}
        a_{11} & \cdots & a_{1n} \\
        \vdots & \ddots & \vdots \\
        a_{m1} & \cdots & a_{mn}
    \end{bmatrix}, B =
    \begin{bmatrix}
        b_1 \\ \vdots \\ b_m
    \end{bmatrix}, X =
    \begin{bmatrix}
        x_1 \\ \vdots \\ x_n
    \end{bmatrix} \\
    & AX = B
\end{align*}

\hl{La matrice $[A|B]$ è detta la matrice completa del sistema. $[A|0]$ è detta
matrice del sistema omogeneo associato.}

\subsection{Sistema lineare omogeneo}
Un sistema lineare omogeneo è un \hl{sistema lineare del tipo $[A|0_{m1}]$} e avrà
sempre \hl{almeno una soluzione, di cui una $X=0_{n1}$}. La soluzione del sistema
lineare omogeneo \hl{è detta soluzione generale}. Un \hl{sistema lineare omogeneo e
il corrispettivo sistema normale condividono la soluzione generale}:
\begin{align*}
    \begin{cases}
        x + y + z = 0 \\
        z = 0
    \end{cases} & X_0 =
    \begin{bmatrix}
        -t \\
        t \\
        0
    \end{bmatrix} \\
    \begin{cases}
        x + y + z = 1 \\
        z = 0
    \end{cases} & X =
    \begin{bmatrix}
        1-t \\
        t \\
        0
    \end{bmatrix} =
    \begin{bmatrix}
        1 \\
        0 \\
        0
    \end{bmatrix} +
    \begin{bmatrix}
        -t \\
        t \\
        0
    \end{bmatrix} =
    \begin{bmatrix}
        1 \\
        0 \\
        0
    \end{bmatrix} + X_0
\end{align*}
Questo ci permette di enunciare il \hl{teorema di costruzione delle soluzioni}.

\paragraph{Nucleo di una matrice} In nucleo di $A = Ker(A)$ è \hl{l'insieme delle
soluzioni del sistema lineare omogeneo associato}
($Ker(A) = \{x \in Mat(m,n;K) | AX = 0\} \neq \emptyset$)

\subsection{Teorema di struttura delle soluzioni}
Sia $[A|B]$ risolvibile, \hl{la soluzione del sistema sarà la soluzione particolare di
$[A|B]$ sommata alla soluzione generale del sistema omogeneo associato $[A|0_{m1}]$}

\subsection{Forma chiusa per il calcolo della soluzione di un sistema lineare}
La forma chiusa per \hl{la risoluzione di un generico sistema lineare $AX = B$ è}
\[
    A^{-1}AX = BA^{-1}
\]
Questa forma chiusa è il \hl{teorema di Cramer}

\paragraph{Teorema di Cramer} Se una matrice $A$ è invertibile, allora il
sistema lineare $[A|B]$ associato avrà soluzione $X = BA^{-1}$.

\subparagraph{Dimostrazione} Se $A$ è invertibile, allora $r(A) = n$. Per il
teorema di Rouché-Capelli, la soluzione del sistema associato ad $A$ sarà unica.
Possiamo allora scrivere:
\[
    AX = A(A^{-1}B) = (AA^{-1})B = I_n B = B
\]
Confermando il fatto che $X = BA^{-1}$ è soluzione del sistema.

\subsection{Equivalenza dei sistemi lineari}
Sia $[A|B]$ un generico sistema lineare e $[S|B]$ una sua riduzione a scala.
\hl{I due sistemi avranno le stesse soluzioni}.

\paragraph{Dimostrazione} Per dimostrare il teorema verifichiamo che ogni
operazione di Gauss non modifichi le soluzioni:
\begin{itemize}
    \item Permutazione: modifica solo l'ordine delle equazioni, ma non le soluzioni
    \item Moltiplicazione per scalare: se lo scalare $t \neq 0$ le soluzioni non
        cambiano in quanto
        \[\not{t}(a_{i1}x_1 + \cdots + a_{ij}) = \not{t}(b_i)\]
    \item Somma tra righe: Prendiamo due sistemi così definiti:
        \[
            \begin{cases}
                a_{i1}x_1 + \cdots + a_{in} - b_i = 0 \\
                a_{j1}x_1 + \cdots + a_{jn} - b_j = 0
            \end{cases}
            \begin{cases}
                (a_{i1}x_1 + \cdots + a_{in} - b_i) + t(a_{j1}x_1 + \cdots + a_{jn} - b_j) = 0 \\
                a_{j1}x_1 + \cdots + a_{jn} - b_j = 0
            \end{cases}
        \]
        Siano $(x_1, \ldots, x_n)$ le soluzioni del primo sistema. Allora
        \begin{align*}
            &a_{i1}x_1 + \cdots + a_{in} - b_i = 0 \text{ per ipotesi}\\
            &a_{j1}x_1 + \cdots + a_{jn} - b_j = 0 \text{ per ipotesi}\\
            &(a_{i1}x_1 + \cdots + a_{in} - b_i) + t(a_{j1}x_1 + \cdots + a_{jn} - b_j) = 0
        \end{align*}
        Siano $(x_1, \ldots, x_n)$ le soluzioni anche per il secondo sistema.
        Allora:
        \begin{align*}
            &a_{i1}x_1 + \cdots + a_{in} - b_i = 0 \text{ per soluzione del primo sistema}\\
            &a_{j1}x_1 + \cdots + a_{jn} - b_j = 0 \text{ per ipotesi}\\
            &(a_{i1}x_1 + \cdots + a_{in} - b_i) + t(a_{j1}x_1 + \cdots + a_{jn} - b_j) = 0
        \end{align*}
        Le stesse $(x_1, \ldots, x_n)$ risolvono entrambi i sistemi
\end{itemize}
Le operazioni gaussiane, quindi, non modificano le soluzioni.

\subsection{Algoritmo di Gauss per la risoluzione dei sistemi lineari}
L'algoritmo di Gauss per risolvere i sistemi lineari \hl{si basa sull'equivalenza
dei sistemi lineari}. Consiste nella \hl{riduzione a scala della matrice completa
del sistema lineare}.

\subsection{Teorema di Rouché-Capelli}
Il teorema di Rouché-Capelli ci \hl{permette di capire la risolvibilità di un sistema
lineare in base al rango della sua matrice associata}
($r(A) \leq r([A|B]) \leq r([A]) + 1$). Sia un sistema che ha come matrice dei
coefficienti $[A]$ e matrice completa $[A|B]$. Se:
\begin{itemize}
    \item \hl{$r([A|B]) > r(A)$: il sistema sarà impossibile} Il sistema si dice
        \hl{sovradeterminato}
    \item \hl{$r([A|B]) = r(A) = n$: il sistema avrà un'unica soluzione}
    \item \hl{$r([A|B]) = r(A) < n$: il sistema avrà infinite soluzioni}
\end{itemize}

Consideriamo il sistema associato ad $[A|B] \in Mat(m,n;K)$, per il teorema
sopra enunciato:
\begin{itemize}
    \item La soluzione non esiste se $r([A|B]) > r(A)$
    \item La soluzione esiste unica se $r([A|B]) = r(A) = n$ ($\infty^{0} = 1$
        soluzioni)
    \item Esistono infinite soluzioni dipendenti da $n-r(A)$ parametri se e
        solo se $r([A|B]) = r(A) < n$ ($\infty^{n-r}$ soluzioni)
\end{itemize}


\end{document}
