# 1 ottobre 2019

## Matrici
[...]

### Matrici inverse
[...]

Se abbiamo $A^{-1}, B^{-1}$, allora $(AB)^1 = B^{-1}A^{-1}$. Generalizzato, 
possiamo affermare che $(A1 * ... * Ak)^{-1} = Ak^{-1} * ... * A1^{-1}$

#### Caratterizzazione delle matrici inverse (vedi dispensa)
Per dimostrare questo teorema andremo a passi:

1. Dimostrare l'unicità della matrice inversa
2. Operazioni di Gauss e le matrici elementari
3. Condizione sufficiente di invertibilità
4. Se $r(A) < n$ allora la matrice inversa non esiste

##### L'unicità della matrice inversa (Dispensa 3.43)
Sia una matrice $A \in Mat(m;n;K)$ con $B,C$ inverse da destra e sinistra. Allora
$B = C$ e sono uniche, quindi le indichiamo con $A^{-1}$.

##### Matrici elementari (Dispensa 3.45)
A ogni operazione di gauss corrisponde una matrice elementare (Esempi in 1.0):

- prendiamo $I_n$ e scambiamo le righe: otteniamo la matrice di permutazione $P(i,j)$
    (prima matrice elementare)
- prendiamo $I_n$ e moltiplico una riga per uno scalare: otteniamo la matrice di
    'prodotto' $T(i,t)$ con $t \in K*$
- prendiamo $I_n$ e moltiplico una riga per uno scalare e la sommo ad un'altra: 
    otteniamo la matrice di 'somma' $T(i,j,t)$ con $t \in K*$

Le operazioni di Gauss possono essere tradotte con le matrici elementari: data
$A \in Mat(m,n;K)$, le mosse elementari sono:

- $A \leftrightarrow B = P(i,j)A$
- $A \leftrightarrow B = T(i,t)A$
- $A \leftrightarrow B = T(i,j,t)A$

La riduzione a scala, quindi, consiste nel moltiplicare una matrice con determinate 
matrici elementari in modo da ottenere una matrice a scala (Dispensa 3.48).

Le inverse delle matrici elementari esistono e sono a loro volta matrici 
elementari:

- $P(i,j)^{-1} = P(i,j)$
- $T(i;r)^{-1} ) T(i;\frac{1}{t})$
- $T(i,j;t)^{-1} ) T(i,j;\frac{1}{t})$

Ciò ci permette di affermare che l'algoritmo di riduzione è sempre invertibile.


Se $S = t_1 ... E_k A \implies A = E_k^{-1} ... E_1^{-1}S$. Ossia ogni matrice
è decomponibile in un prodotto di $K$ matrici elementari e di una matrice a
scala.

**Dimostrazione**: $(E_1 ... E_k)^{-1} = E_1^{-1} ... E_k^{-1}$ per proprietà
dimostrata precedentemente. Quindi
$E_1^{-1} ... E_k^{-1} S = (E_1 ... E_k)^{-1} (E_1 ... E_k)A = A$ per ipotesi.

##### Condizione sufficiente di invertibilità
Se $A \in Mat(m;K)$, esiste la riduzione da $A$ alla matrice $I_n$ se e solo
se $r(A) = n$ (Disp 3.5.2). Di conseguenza si può affermare che $A$ è prodotto
di matrici elementari se e solo se $r(A) = n$ e vale anche il contrario.

##### Collegamento tra il rango e la matrice inversa (Dispensa 3.59)
Se $r(A) < n$ allora non esistono inverse a sinistra e a destra.

### Algoritmo di Gauss-Jordan
Supponiamo che $A \in Mat(m,n;K)$ sia invertibile. Allora:

- esiste l'inversa che può scrivere come $A^{-1} = E_1 \ldots E_k$
- se faccio $A \cdot [A|I_n]$ allora $A \cdot [A|I_n] = [I_n|A^{-1}]$

Questa forma di inversione di una matrice è nota come algoritmo di Gauss-Jordan.

### La traccia (Disp 3.63)
Partiti da una matrice i cui elementi sono $A[a_{ij}] \in Mat(m,n;K)$, la traccia
è la somma degli elementi sulla diagonale.

#### Proprietà
- $Tr(s*A + t*B) = s*Tr(A) + t*Tr(B)$
- $Tr(A^T) = Tr(A)$
- $Tr(AB) = Tr(BA)$

### Sottomatrice (Disp 3.65)
Presa una matrice $A$, una sottomatrice di $A$ è un'altra matrice ottenuta 
eliminando alcune righe e alcune colonne. Si indica con $A_{\widehat{i...j}\widehat{i...j}}$

Il determinante di una sottomatrice è detto minore.

### Il determinante (Disp 3.67)
Presa una matrice $A \in Mat(m,n;K)$ il determinante $|A| = det(A)$ è un numero
appartenente a $K$. Si calcola come:

- per $n = 1, det([a_{11}]) = a_{11}$
- per $n > 1, det(A) = \sum_{j=1}^n a_{1j} * C_{1j}$ dove $C$ è il complemento
    algebrico ($C_{ij} = (-1)^{i+j} * det(A_{\hat{j}\hat{j}}$)

Esempi in 1.1. Sempre in 1.1 il determinante di una matrice di ordine 2.

Nota bene: $det(I_n) = 1$

