# 8 ottobre

## Spazi vettoriali
[...] 

### Sottospazi vettoriali
[...]

#### Esempi di sottospazi
Dimostrare che $A \in Mat(m,n;K) \implies Ker(A)$ è un sottospazio di $Mat(m,1;K)$

Dimostriamo che è chiuso rispetto alle operazioni. Siano $B,C \in Ker(A)$, allora
$AB=0, AC=0$ avremo quindi:

- $A(B+C) = AB + AC = 0 + 0 = 0 \implies B+C \in Ker(A)$
- $A(tB) = t(AB) = t * 0 = 0 \implies t*B \in Ker(A)$
- $0 \in Ker(A)$ sempre perché $0$ è sempre soluzione di un sistema omogeneo

Allora $Ker(A)$ è un sottospazio di $Mat(m,1;K)$

#### Operazioni con i sottospazi
Le operazioni con i sottospazi sono quasi le stesse che si possono fare con gli 
insiemi:

- intersezione
- unione
- somma (Disp 4.15): 
    $U_1, U_2 \subseteq V, U_1 + U_2 = \{v \in V \mid v = u_1 + u_2 \quad u_1 \in U_1, u_2 \in U_2\}$
- somma diretta (capitolo a parte)

##### Proprietà delle operazioni (dispensa 4.16):

- $U_1 \cap U_2$ è ancora un sottospazio
- $U_1 \cup U_2$ è ancora uno sottospazio $\iff U_1 \subseteq U_2 \vee U_2 \subseteq U_1$
- $U_1 + U_2$ è il più piccolo sottospazio che contiene $U_1 \cup U_2$

##### Somma diretta (dispensa 4.19)
Dati $U_1, \dotsc, U_n \subseteq V$ sottospazi. Si dice $V = U_1 \oplus \ldots \oplus u_n = \bigoplus_{i=1}^n$ è 
somma diretta dei sottospazi se per ogni $v \in V$ esiste un'unica m-upla
contenuta in $U_1 \times \ldots \times U_n$ tale che $v = u_1 + \ldots + u_n$.

Esempi interessanti: 

- Una matrice può essere scritta come la somma diretta di una matrice triangolare 
    alta e una matrice strettamente basse: $Mat(n;K) = T_a(n;K) \oplus T_{sb}(n;K)$
- Una matrice può essere scritta come somma diretta di una matrice a scala e una
    matrice antisimmetrica

##### Caratterizzazione della somma diretta
$V = U_1 \oplus \ldots \oplus U_n$ con $n \geq 2$:

- $V = U_1 + \ldots - U_n$
- $U_k \cap U_{\hat{k}} = \{\underline{0}\} \quad \forall k \in K$,
    $U_{\hat{k}} = U_1 + \ldots + U_{k-1} + U_{k+1} + \ldots + U_n$

## Dimensione
Il numero di dimensioni è il numero minimo di spostamenti fondamentali che
bisogna eseguire per definire qualsiasi vettore in quello spazio.

## Combinazione lineare
$v = t_1 * u_1 + \ldots + t_n * u_n$ questa è detta combinazione lineare di 
vettori.

## Base
E' detta base di di $V$ un insieme $B = \{ v_1, \dotsc, v_m \} \subset V$ se per
ogni $v \in V$ esiste unica la decomposizione $v = t_1 * u_1 + \ldots + t_n * u_n$

In uno spazio non per forza esistono le basi.

Poiché i coefficienti della scomposizione sono unici (per definizione di base),
è possibile definire una funzione (la mappa delle componenti) che associa a 
un vettore di uno spazio la su

### Basi canoniche
Le basi canoniche sono le basi più semplici che vengono convenientemente usate:

- $Mat(m,n;K): \quad B_{mn} = \{ E_{11}, E_{12}, \dotsc, E_{mn} \}$ dove $E$ è 
    una matrice che solo l'elemento $a_{mn}$ pari a 1.

    Una matrice $A$ si può scrivere come $A = \sum_{i=1}^m \sum_{j=1}^n a_{ij} * E_{ij}$
- $K^n: \quad B_n = \{ e_1 = (1, \dotsc, 0), \dotsc, e_n = (0, \dotsc, n)\}$

    Un generico vettore sarà: $x §= \sum_{i=1}^n x_i * e_i$
- $K[x]: \quad B = \{1, x, \dotsc, x^n, \dotsc \}$ (spazio vettoriale con base infinita)

    Un generico polimonio sarà: $P(x) = \sum_{i=0}^n a^0 * x^n$

### Mappa delle componenti
Sia $B = \{v_1, \dotsc, v_n\}$ base di $V$ e $v = t_1v_1 + \ldots + t_nv_n$,
definiamo mappa delle componenti la funzione:
$$\begin{align}
    \phi_{B} : &V &\to &Mat(n, 1;K) \\
    &v &\mapsto &v_{|B} =   \begin{bmatrix}
                                t_1 \\
                                \vdots \\
                                t_n
                            \end{bmatrix}
\end{align}$$

#### Mappa delle componenti come isomorfismo
La funzione mappa è un isomorfismo di spazi vettoriali da $V$ in $Mat(m,1;K)$.

Dimostrazione: La mappa è biunivoca, quindi ammette inversa. Per proprietà
delle applicazioni lineare, ci basta dimostrare che la mappa è anche un omomorfismo
per dimostrare che è un isomorfismo: siano $v, \tilde{v} \in V$, allora
$v = \sum_{i=1}^n t_iv_i, \tilde{v} = \sum_{i=1}^n \tilde{t}_iv_i$. Allora
$$\begin{align}
    \phi_B(\alpha v + \beta \tilde{v}) &= \\
    &= \phi_B(\alpha \sum_{i=1}^n t_iv_i + \beta \sum_{i=1}^n \tilde{t}_iv_i) = \\
    &= \phi_B(\sum_{i=1}^n (\alpha t_i + \beta \tilde{t}_i)v_i = \\
    &= [\alpha t_i + \beta \tilde{t}_i] = \\
    &= \alpha [t_i] + \beta [\tilde{t_i}] = \\
    &= \alpha \phi_B(v) + \beta \phi_B(\tilde{v})
\end{align}$$
