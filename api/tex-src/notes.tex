\documentclass[a4paper,11pt,oneside]{article}

% chktex-file 8
% chktex-file 18
% chktex-file 36
% chktex-file 40
% chktex-file 44

\usepackage[a4paper,margin=2cm]{geometry}
\usepackage[italian]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}

\usepackage{booktabs}
\usepackage[bookmarks,colorlinks]{hyperref}
\usepackage{enumerate}
\usepackage[dvipsnames]{xcolor}
\usepackage{soulutf8}

\usepackage{mathtools}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}

\usepackage{listings}
\usepackage{caption}

\usepackage{tikz}
\usetikzlibrary{
  arrows,
  arrows.meta,
  automata,
  positioning
}

\definecolor{hlcolor}{RGB}{253,241,98}
\sethlcolor{hlcolor}

\theoremstyle{plain}
\newtheorem{lem}{Lemma}[section]
\newtheorem{prop}{Proposizione}[section]
\newtheorem{thm}{Teorema}[section]

\theoremstyle{definition}
\newtheorem{defn}{Definizione}[section]

\theoremstyle{remark}
\newtheorem{esempio}{Esempio}[section]
\newtheorem*{nota}{Nota}

\newcommand{\mhl}[1]{\colorbox{hlcolor}{$\displaystyle #1$}}
\newcommand*{\deriv}[1][]{\xRightarrow[#1]{}}
\newcommand*{\derivstar}[1][]{\xRightarrow[#1]{\star}}
\newcommand*{\termsep}[0]{\blacklozenge}

\newcommand{\peq}{$\gets$}
\newcommand{\pcom}{$\triangleright$}

\DeclareMathOperator{\succc}{succ}
\DeclareMathOperator{\last}{last}

\lstdefinestyle{mystyle}{
  basicstyle=\ttfamily,
  columns=fixed,
  keepspaces=true,
  numbers=left,
  numbersep=5pt,
  showspaces=false,
  showstringspaces=false,
  showtabs=false,
  tabsize=2,
  mathescape=true,
  escapechar=`,
  xleftmargin=1cm,
  captionpos=b
}
\lstset{
  style=mystyle,
}
\lstdefinelanguage{pseudocodice}{
  morekeywords={if,else,for,each,to,downto,while,do,return,NIL},
  sensitive=true,
  morestring=[b]",
  morecomment=[l]{//}
}
\renewcommand\lstlistingname{Snippet}

\title{Appunti di ``Algoritmi e Principi dell'informatica''}
\author{Alexandru Gabriel Bradatan}
\date{\today}

\begin{document}

\maketitle
\tableofcontents
\newpage

\section{Introduzione ai modelli}\label{sec:modelli}

I modelli sono fondamentali nell'ingegneria. I modelli sono talvolta fisici e
spesso sono \hl{modelli formali, ossia oggetti matematici che fungono da
rappresentazioni astratte di entità reali complesse.} Un modello è \hl{adeguato
se i risultati ottenuti riflettono le proprietà che ci interessano del sistema
fisico entro i limiti della nostra approssimazione.} I modelli dell'informatica
si basano principalmente sulla matematica discreta. Definiamo i due tipi di
modelli che costruiremo.

\begin{defn}[\hl{Modello operazionale}]\label{def:modello-op}
  È un modello basato sul \hl{concetto di stato e di meccanismo} per la sua
  evoluzione.
\end{defn}

\begin{defn}[\hl{Modello descrittivo}]\label{def:modello-desc}
  È un modello che \hl{formula le proprietà desiderate o no del sistema}
  piuttosto che il suo funzionamento.
\end{defn}

\hl{Le differenze tra questi due tipi di modellizzazione non sono spesso molto
ben definite}. Le fasi dell'ingegneria del software ricalcano quelli della
modellizzazione di un problema:

\begin{itemize}
  \item Analisi dei requisiti: Stesura della specifica del sistema
  \item Progetto: Architettura del software
  \item Implementazione: Scrittura effettiva del codice
\end{itemize}

\begin{esempio}
  Modellizziamo lo stesso problema, l'ordinamento di una sequenza di interi,
  secondo i due criteri enunciati sopra:
  \begin{itemize}
    \item Modello operazionale: Calcola il minimo in tutto l'array e mettilo al
      primo posto. Continua ad eseguire l'operazione finché l'array non è in
      ordine.
    \item Modello descrittivo: Individua una permutazione degli elementi
      dell'array tale che \(\forall i a[i] \leq a[i+1]\).
  \end{itemize}
\end{esempio}

\section{I linguaggi}\label{sec:linguaggi}

Il \hl{meta-modello fondamentale che useremo sarà il linguaggio}. Il termine
linguaggio è un termine che conosciamo già ed è utilizzabile a diversi ambiti
diversi come la linguistica, l'informatica, la grafica e la musica.

\subsection{Costruzione di un linguaggio}\label{sec:linguaggi-costruzione}

Iniziamo a definire i vari elementi un linguaggio. Il \hl{primo elemento formale
di un linguaggio è l'alfabeto o vocabolario}. In matematica essi sono sinonimi
anche se in italiano naturale non lo sono.

\begin{defn}[\hl{Alfabeto}]\label{def:alfabeto}
  Si dice alfabeto un \hl{insieme finito} $A$ di \hl{simboli base}.
\end{defn}

Una volta definito il concetto di alfabeto possiamo anche definire il concetto
di \hl{stringa}.

\begin{defn}[\hl{Stringa}]\label{def:stringa}
  Si dice stringa una \hl{sequenza ordinata e finita di elementi dell'alfabeto}
  $A$.
\end{defn}

Naturalmente ogni stringa possiede una \hl{lunghezza $|a|$ pari al numero di
elementi dell'alfabeto contenuti al suo interno}. Definiamo anche la \hl{stringa
nulla $\epsilon$ tale che $|\epsilon|=0$}. Definiamo infine \hl{$A^\star$
l'insieme di tutte le stringhe scrivibili con un certo alfabeto}.

\begin{nota}
  L'operatore \hl{$\star$ è detto stella, star, iterazione o stella di Kleene.}
  L'insieme $A^\star$ è infinito numerabile.
\end{nota}

Sulle stringhe possiamo definire l'operazione di \hl{concatenazione}:

\begin{defn}[\hl{Concatenazione di stringhe}]\label{def:concatenazione-stringhe}
  \begin{equation}
    \begin{array}{cccc}
      . : & A^\star \times A^\star & \to & A^\star \\
          & (x, y) & \mapsto & x.y
    \end{array}
  \end{equation}
\end{defn}

\begin{nota}
  La scrittura dell'operatore di concatenazione può essere omessa, scrivendo al
  posto di $z = x.y$ $z = xy$.
\end{nota}

L'operazione di concatenazione gode della proprietà \hl{associativa ma non della
commutativa} e ha come \hl{elemento neutro la stringa vuota}. Possiamo quindi
definire il \hl{monoide non commutativo delle stringhe rispetto alla
concatenazione $\langle A^\star, . \rangle$}.

Definito tutti questi elementi possiamo finalmente definire un \hl{linguaggio}.

\begin{defn}[\hl{Linguaggio}]\label{def:linguaggio}
  Chiamiamo un linguaggio un \hl{insieme $L$} tale che:
  \hl{$L \subseteq A^\star$}.
\end{defn}

Notiamo che \hl{$L$ può anche essere infinito}. Inoltre, poiché $L$ è un
insieme, le \hl{operazioni insiemistiche sono tutte ben definite.} Un
\hl{insieme di linguaggi che condividono le stesso proprietà è detto famiglia di
linguaggi}.

\subsection{Operazioni sui linguaggi}

\begin{defn}[\hl{Concatenazione di linguaggi}]\label{def:concatenazione-ling}
  \begin{equation}
    \mhl{ L_1 . L_2 = \{ x.y : x \in L_1, y \in L_2 \} }
  \end{equation}
\end{defn}

\begin{defn}[\hl{Potenze di linguaggi}]\label{def:potenze-linguaggi}
  \begin{equation}
    \begin{aligned}
      L^0 & = \{\epsilon\} \\
      L^i & = L^{i-1}.L
    \end{aligned}
  \end{equation}
\end{defn}

\begin{defn}[\hl{Star (Linguaggi)}]\label{def:star-linguaggi}
  \begin{equation}
    \mhl{ L^\star = \bigcup^{\infty}_{i=0} L^i }
  \end{equation}
\end{defn}

\begin{defn}[\hl{Plus (Linguaggi)}]\label{def:plus-linguaggi}
  \begin{equation}
    \mhl{ L^+ = \bigcup^{\infty}_{i=1} L^i }
  \end{equation}
\end{defn}

\begin{nota}
  La differenza tra scrivere $L^\star$ e $L^+$ è che in $L^+$ è assente il
  linguaggio vuoto!
\end{nota}

\subsection{A cosa utilizzeremo i linguaggi?}

Il nostro \hl{principale utilizzo del concetto di linguaggio sarà per definire
in maniera astratta il concetto di problema informatico}. Il nostro \hl{primo}
problema informatico sarà:

\begin{equation}
  \mhl{ x \in A^\star, L \subseteq A^\star \quad  x \in L? }
\end{equation}

Questa semplice questione è capace di modellizzare una grande varietà di
problemi diversi, scelti $A$ ed $L$ in modo adatto. Un \hl{secondo} problema sarà
quello di \hl{trovare una traduzione}, ossia una funzione così definita:

\begin{defn}[\hl{Traduzione}]\label{def:traduzione}
  \begin{equation}
    \begin{array}{cccc}
      \tau: & L_1 & \to     & L_2 \\
            & x   & \mapsto & \tau(x)
    \end{array}
  \end{equation}
\end{defn}

\section{Modelli operazionali}\label{sec:modelli-operazionali}

\subsection{Automi a stati finiti}\label{sec:fsa}

Gli \hl{automi a stati finiti (FSA) sono il modello operazionale più semplice}.
Essi sono caratterizzati da un \hl{insieme finito di stati e da un insieme di
regole di transizione}. Gli \hl{stati} possono essere di \hl{accettazione o no}.
Le \hl{regole di transizione permettono al nostro automa di passare da uno stato
all'altro in base a ciò che forniamo come input}. Quando un automa riceve un
\hl{input lo elabora e produce un output. L'elaborazione inizia in uno stato
iniziale e consiste nel leggere l'input e spostarsi da uno stato all'altro
secondo le leggi di transizione}. \hl{Se alla fine} della lettura l'automa
\hl{si trova in uno stato di accettazione, diremo che esso ha accettato l'input,
altrimenti diremo che l'ha rifiutato}.

\begin{defn}[\hl{Automa a stati finiti}]\label{def:fsa}
  Un automa a stati finiti $\mathcal{A}$ è una \hl{quintupla}
  $\langle Q, I, \delta, q_0, F \rangle$ dove:
  \begin{enumerate}
    \item \hl{$Q$} è \hl{l'insieme finito non vuoto di tutti gli stati};
    \item \hl{$I$} è \hl{l'alfabeto} di ingresso;
    \item \hl{$\delta: Q \times I \to Q$} è la \hl{funzione (relazione) di
      transizione};
    \item \hl{$q_0 \in Q$} è lo \hl{stato iniziale};
    \item \hl{$F \subseteq Q$} è l'insieme degli \hl{stati di accettazione}.
  \end{enumerate}
\end{defn}

\begin{figure}[htb]
  \centering
  \begin{tikzpicture}[node distance=2cm,auto]
    \node[state,initial,accepting]  (q0)                {$q_0$};
    \node[state]                    (q1) [right of=q0]  {$q_1$};

    \path[->]
    (q0) edge                node {0,1}  (q1)
    (q1) edge  [loop above]  node {0,1}  ();
  \end{tikzpicture}
  \caption{Esempio di diagramma di stato di FSA.}\label{fig:fsa-diagramma-stato}
\end{figure}

Se \hl{$\delta$ è una funzione l'automa si dice completo, altrimenti non
completo}. Gli \hl{automi non completi} possono facilmente \hl{resi completi
``riempiendo'' le transizioni mancanti con delle transizioni verso uno stato di
``sink'' dal quale non si può più uscire}.

Un automa \hl{processa l'input tramite una sequenza di transizioni di stato
effettuate iterando su ogni carattere della stringa e muovendosi allo stato
corrispondente a $\delta(q, i)$}. Definiamo formalmente la sequenza di mosse
eseguita da un automa a stati finiti.

\begin{defn}[\hl{Sequenza di mosse}]\label{def:fsa-seq-mosse}
  Sia un FSA $\mathcal{A}$, la sequenza di mosse è una funzione:

  \begin{equation}
    \mhl{ \delta^\star: Q \times I^\star \to Q }
  \end{equation}

  Definita \hl{induttivamente} da:

  \begin{enumerate}
    \item \hl{$\delta^\star(q, \epsilon) = q$}
    \item \hl{$\delta^\star(q, y.i) = \delta(\delta^\star(q,y), i)$} con
      $y \in I^\star, i \in I$
  \end{enumerate}
\end{defn}

Gli \hl{FSA rappresentano dei linguaggi}, più nello specifico la famiglia dei
\hl{linguaggi regolari} ($\mathbf{REG}$). Se \hl{$L$ è un linguaggio accettato}
da $\mathcal{A}$ allora diremo che esso è il \hl{linguaggio di $\mathcal{A}$ e
lo indichiamo come $L(\mathcal{A})$}. Usando la definizione di \hl{sequenza di
mosse possiamo scrivere $L(\mathcal{A})$ come}:

\begin{equation}
  L(\mathcal{A}) = \{ x \in I^\star : \delta^\star(q_0, x) \in F \}
\end{equation}

Per \hl{rappresentare il linguaggio} accettato da un FSA possiamo usare la pura
notazione insiemistica oppure, visto che i linguaggi sono regolari, delle
\hl{espressioni regolari}. Definiamo la sintassi delle espressioni regolari.

\begin{defn}[Espressioni regolari]\label{def:regex}
  Dato una \hl{alfabeto $A$}, siano le \hl{seguenti operazioni}:

  \begin{itemize}
    \item \hl{$R + S = R \cup S$} con $R \subseteq A^\star$ e
      $S \subseteq A^\star$ (notazione equivalente: $R | S$)
    \item \hl{$\star$ la star di Kleene:}
      $R^\star = \{x^n : n \in \mathbb{N}, x \in R\}$
    \item \hl{$R^+ = \{x^n : n \in \mathbb{N}^*, x \in R\}$}
    \item la \hl{concatenazione}: $RS = \{xy : x \in R, y \in S\}$
  \end{itemize}

  Allora, dato un \hl{alfabeto $A$} e un \hl{insieme di simboli}
  \hl{$\{+,\star,(,),.,\emptyset\}$} si dice \hl{espressione regolare su $A$} la
  \hl{stringa} $R \in A \cup \{+,\star,(,),.,\emptyset\}$ che \hl{rende vera una
  delle seguenti condizioni}:

  \begin{enumerate}
    \item \hl{$R = \emptyset$};
    \item \hl{$R \in A$};
    \item \hl{$R = S + T$, $R = ST$, $R = S^\star$, $R = S^+$} con $S,T$
      espressioni regolari su $A$.
  \end{enumerate}
\end{defn}

Gli \hl{automi a stato finito sono modelli di calcolo con una memoria finita
pari al numero di stati}. Infatti \hl{ogni stato} rappresenta una \hl{istantanea
della situazione in cui si trova il sistema in un dato istante}. Il fatto di
\hl{possedere una memoria finita}, come vedremo in~\ref{sec:fsa-analisi}, è uno
degli \hl{aspetti più limitanti} degli automi a stato finito e ci costringeranno
a costruire modelli più sofisticati.

\subsubsection{Automi a stati finiti traduttori}\label{sec:fsa-trad}

Un FSA può anche essere \hl{usato come traduttore tra un linguaggio ed un
altro}. Ci basta \hl{aggiungere la capacità di dare un output} al nostro automa.

Un semplice FSA si limita semplicemente ad interpretare un input senza produrre
nessun output. Se ad un \hl{FSA} aggiungiamo la possibilità di \hl{produrre un
output} otteniamo un \hl{trasduttore}. Un \hl{particolare tipo} di trasduttore
che ci interessa è il \hl{traduttore}.

Prima di parlare di traduttori, però, formalizziamo come un automa produce un
output.

\begin{defn}[\hl{Funzione di transizione con uscita}]\label{def:fsa-transizione-uscita}
  Chiamiamo \hl{$\delta(q, i/w)$} con \hl{$i \in I$ e $w \in O$, $I, O$
  alfabeti}, una \hl{funzione di transizione tra stati che restituisce il nuovo
  stato del FSA e un simbolo complesso $w$}.
\end{defn}

Ora possiamo definire il traduttore.

\begin{defn}[\hl{Automa a stati finiti traduttore}]\label{def:fsa-trad}
  Sia $\mathcal{A} = \langle Q, I, \delta, q_0, F \rangle $ un \hl{automa a
  stati finiti} con funzione di transizione \hl{$\delta(q, i/w)$}, definiamo
  \hl{automa a stati finiti traduttore} $\mathcal{T}$ la \hl{terna} \hl{$\langle
  \mathcal{A}, O, \eta \rangle$} dove:

  \begin{itemize}
    \item \hl{$O$} è \hl{l'alfabeto di uscita} di $\delta$;
    \item \hl{$\eta : Q \times I \to O^\star$} \hl{funzione di traduzione}.
  \end{itemize}
\end{defn}

\hl{Analogamente a quanto fatto in}~\ref{def:fsa-seq-mosse} \hl{possiamo
iterare} la funzione di traduzione usando la stella di Kleene, così da \hl{poter
finalmente enunciare la traduzione come}:

\begin{equation}
  \mhl{\tau(x) = \eta^\star(q_0, x)}
\end{equation}

Se il \hl{traduttore conclude} la propria esecuzione \hl{su uno stato di
accettazione}, allora possiamo dire che la \hl{stringa di input e corretta e la
sua traduzione nel linguaggio di output è $\tau(x)$}.

\subsubsection{Analisi degli automi a stati finiti}\label{sec:fsa-analisi}

Gli automi a stati finiti sono un modello molto semplice ed intuitivo, applicato
a molti settori. Abbiamo già visto in~\ref{sec:fsa} che sono adatti a modellare
linguaggi regolari e che sono modelli a memoria finita. Studiamone ora nel
dettaglio le proprietà ed eventuali limitazioni.

Innanzitutto esiste qualche \hl{condizione affinché un automa a stati finiti sia
o no accettore di un linguaggi finito o infinito} (il caso di linguaggio vuoto è
banale)? Si dimostra che \hl{esistono} due condizioni \hl{necessarie e
sufficienti} per l'accettazione dei linguaggi, \hl{una per il caso finito e un
per l'infinito}.

\begin{thm}[\hl{Condizione di accettazione di un linguaggio finito}]\label{thm:accettazione-ling-finito}
  \hl{Condizione sufficiente e necessaria} affinché un \hl{automa a stati finiti
  accetti un linguaggio finito non vuoto} è che possa accettare una stringa di
  lunghezza inferiore al numero di stati (\hl{$|x| < |Q|$}).
\end{thm}

\begin{thm}[\hl{Condizione di accettazione di un linguaggio infinito}]\label{thm:accettazione-ling-infinito}
  \hl{Condizione sufficiente e necessaria} affinché un \hl{automa a stati finiti accetti
  un linguaggio infinito} è che possa accettare una stringa tale che:
  \hl{$|Q| \leq |x| < 2|Q|$}.
\end{thm}

Questo teorema deriva dall'osservazione che \hl{se un automa accetta un
linguaggio infinito, nel suo grafo saranno presenti dei cicli che potranno
essere percorsi un numero arbitrario di volte}. Nel \hl{caso peggiore} verranno
\hl{ripercorsi tutti gli stati} dell'automa \hl{tranne l'ultimo} che deve essere
di accettazione.

\begin{figure}[htb]
  \centering
  \begin{tikzpicture}[node distance=2cm,auto]
    \node[state,initial]            (q0)                {$q_0$};
    \node[state]                    (q1) [right of=q0]  {$q_1$};
    \node[state]                    (q2) [right of=q1]  {$q_2$};
    \node[state]                    (q3) [right of=q2]  {$q_3$};
    \node[state]                    (q4) [right of=q3]  {$q_4$};
    \node[state,accepting]          (q5) [right of=q4]  {$q_5$};

    \path[->]
    (q0) edge                node {} (q1)
    (q1) edge                node {} (q2)
    (q2) edge                node {} (q3)
    (q3) edge                node {} (q4)
    (q4) edge                node {} (q5)
    (q5) edge  [bend left]   node {} (q0);
  \end{tikzpicture}
  \caption{Peggior caso del teorema~\ref{thm:accettazione-ling-infinito}.}%
  \label{fig:fsa-accettazione-ling-infinito}
\end{figure}

Possiamo quindi vedere \hl{una stringa di un linguaggio infinito come composta
da 3 parti: un preambolo al ciclo, il ciclo e l'epilogo}. Il ciclo può ripetersi
un numero infinito di volte, generando la seguente espressione regolare:

\begin{equation}
  \mhl{x = x_i x_c^\star x_f}
\end{equation}

Questa è una \hl{condizione necessaria affinché una stringa di un linguaggio
infinito sia riconosciuta da un FSA} e rappresenta il \hl{contenuto del
``Pumping lemma''}:

\begin{lem}[\hl{Pumping lemma}]\label{thm:pumping-lemma}
  Sia un \hl{automa a stati finiti} $\mathcal{A}$ che accetta un linguaggio
  $L(\mathcal{A})$. Allora per ogni \hl{$x \in L$ con $|x| > |Q|$ esiste $q \in
  Q$ e $w \in I^+$} tali da verificare una di queste condizioni:

  \begin{itemize}
    \item \hl{$x = ywz$}
    \item \hl{$\delta^\star(q,w) = q$}
  \end{itemize}

  Come \hl{conseguenza} si ha: \hl{$\forall n \in \mathbb{N} \geq 0, y w^n z \in
  L$}.
\end{lem}

Il Pumping lemma, quindi, ci \hl{mette dei paletti sui tipi di linguaggi
infiniti che un FSA può accettare}. Infatti consideriamo il seguente linguaggio
infinito:

\begin{equation}
  \mhl{L = \{ a^n b^n : n \in \mathbb{N} \}}
\end{equation}

\hl{Supponiamo} che un \hl{FSA sia in grado di accettarlo}, allora consideriamo
la stringa \hl{$x = a^m b^m$ con $m > |Q|$} e applichiamo il \hl{Pumping lemma}.
Otterremo \hl{3 casi possibili}:

\begin{enumerate}
  \item \hl{$w = a^p$} e quindi dovrebbe essere:

    \begin{equation}
      \mhl{
      x = a^m b^m = a^r a^p a^s b^m = a^r w a^s b^m \in L \text{ con } r+p+s=m
      }
    \end{equation}

    \hl{Se il Pumping lemma dovesse valere}, allora si dovrebbe avere che
    \hl{$a^r w^k b^m \in L$} che ci porta ad un \hl{assurdo}.
  \item \hl{$w = b^p$ analogo al precedente}.
  \item \hl{$w = a^p b^q$} e quindi dovrebbe essere:

    \begin{equation}
      \mhl{
      x = a^m b^m = a^r a^p b^q b^s = a^r w b^s \in L \text{ con } r+p=q+s=m
      }
    \end{equation}

    \hl{Se il Pumping lemma dovesse valere}, allora si dovrebbe avere che
    \hl{$a^r w^k b^s \in L$} che ci porta ad un \hl{assurdo}.
\end{enumerate}

Ciò significa che \hl{considerare $L$ come accettato da una FSA è un assurdo}.
Il linguaggio $L$ appena costruito ci dimostra quindi la necessità di costruire
modelli di calcolo più potenti. \hl{Infatti per contare fino a $n$ non basta la
memoria finita degli FSA ma servirebbe una memoria infinita!}

\subsubsection{Proprietà di chiusura degli automi a stati finiti}\label{sec:chiusura-fsa}

Il concetto di chiusura di un insieme rispetto ad un'operazione o proprietà è
un concetto già affrontato nel precedente corso di logica e algebra lineare. In
questo contesto ci occupiamo della \hl{chiusura della famiglia dei linguaggi
regolari}.

\hl{La famiglia dei linguaggi regolari è chiusa rispetto a tutte le operazioni
insiemistiche, alla concatenazione, alla star di Kleene e praticamente tutte le
altre viste fino ad ora.} Proviamo a costruirne qualcuno.

\paragraph{Intersezione} Proviamo a costruire l'intersezione di due automi. Il
risultato sarà un automa che \hl{accetta solo stringe solo stringhe accettate da
entrambi gli automi di partenza}. Dati i due automi di partenza:

\begin{align}
  A^1 &= \langle Q^1, I, \delta^1, q_0^1, F^1 \rangle \\
  A^2 &= \langle Q^2, I, \delta^2, q_0^2, F^2 \rangle
\end{align}

\noindent Possiamo scrivere l'automa intersezione come:

\begin{gather}
  \langle A^1, A^2 \rangle = \langle Q^1 \times Q^2, I, \delta,
    \langle q_0^1, q_0^2 \rangle, F^1 \times F^2 \rangle\label{eqn:automa-intersezione} \\
  \delta(\langle q^1, q^2 \rangle, i) = \langle \delta(q^1, i),
    \delta(q^2, i) \rangle
\end{gather}

\noindent Con una semplice induzione si può dimostrare che il linguaggio di un
automa così definito è \\ $L(\langle A^1, A^2 \rangle) = L(A^1) \cap L(A^2)$.

\begin{figure}[htb]
  \begin{tikzpicture}[node distance=2cm,auto]
    \node[state,initial]   (q0) {$q_0$};
    \node[state]           (q1) [right of=q0] {$q_1$};
    \node[state]           (q2) [right of=q1] {$q_2$};
    \node[state,accepting] (q3) [right of=q2] {$q_3$};
    \node[] (t) [left=1.5cm of q0] {$A^1$:};

    \path[->]
      (q0) edge node {$b$} (q1)
      (q1) edge node {$a$} (q2)
      (q2) edge node {$a$} (q3);
  \end{tikzpicture}
  \begin{tikzpicture}[node distance=2cm,auto]
    \node[state,initial]   (p0) {$p_0$};
    \node[state]           (p1) [right of=p0] {$p_1$};
    \node[state]           (p2) [right of=p1] {$p_2$};
    \node[state,accepting] (p3) [right of=p2] {$p_3$};
    \node[] (t) [left=1.5cm of p0] {$A^2$:};

    \path[->]
      (p0) edge node {$b$} (p1)
      (p1) edge node {$a$} (p2)
      (p2) edge node {$a$} (p3);
  \end{tikzpicture}
  \begin{tikzpicture}[node distance=3cm,auto]
    \node[state,initial]   (q0) {$\langle q_0, p_0 \rangle$};
    \node[state]           (q1) [right of=q0] {$\langle q_1, p_1 \rangle$};
    \node[state]           (q2) [right of=q1] {$\langle q_2, p_2 \rangle$};
    \node[state,accepting] (q3) [right of=q2] {$\langle q_3, p_3 \rangle$};
    \node[] (t) [left=1.5cm of q0] {$\langle A^1, A^2 \rangle$:};

    \path[->]
      (q0) edge node {$b$} (q1)
      (q1) edge node {$a$} (q2)
      (q2) edge node {$a$} (q3);
  \end{tikzpicture}
  \centering
  \caption{Due automi e la loro intersezione.}%
  \label{fig:esempio-automa-intersezione}
\end{figure}

\paragraph{Unione} Per l'unione il tutto funziona in \hl{modo analogo}. L'automa
risultante sarà un automa che \hl{accetterà stringhe accettate da almeno uno dei
due automi di partenza}. Eseguendo un procedimento simile a quello effettuato
per ottenere~\ref{eqn:automa-intersezione} abbiamo:

\begin{equation}
  \langle A^1, A^2 \rangle = \langle Q^1 \times Q^2, I, \delta,
    \langle q_0^1, q_0^2 \rangle, F^1 \times Q^2 \cup Q^1 \times F^2 \rangle
\end{equation}

\noindent Questo approccio presenta, però, un \hl{problema}: \hl{non funziona se
l'automa di partenza non è completo}. Con l'intersezione non avevamo problemi
perché l'automa intersezione accettava solo stringhe accettate da entrambi gli
automi iniziali, rimuovendo il problema della non completezza. Con l'unione
invece otterremo un automa che accetta anche quando uno degli automi iniziali
non accetta, rendendo problematico il caso di un errore dovuto alla parzialità
della funzione di transizione. \hl{Bisogna, quindi, ricordarsi di completare gli
automi aggiungendo eventuali stati di errore prima di eseguirne l'unione}.

\paragraph{Complemento} Per il complemento la situazione è \hl{analoga
all'unione}: anche qui dobbiamo stare attenti alla completezza dei due automi di
partenza. L'automa complemento sarà praticamente uguale all'automa di partenza,
solo che \hl{gli stati di accettazione ora saranno di non accettazione e
viceversa}.

\begin{equation}
  \neg A = \langle Q, I, \delta, q_0, Q \setminus F \rangle
\end{equation}

\subsection{Automi a stati finiti con pila}\label{sec:pda}

Arricchiamo ora i nostri automi a stati finiti con della \hl{memoria}. Questa
memoria sarà \hl{strutturata come una pila (stack)} di dimensione potenzialmente
illimitata. L'automa può \hl{manipolare la pila tramite le due operazioni
fondamentali} delle pile: \hl{push e pop}. L'automa così strutturato si chiama
``automa a pila'', in breve PDA (dall'inglese ``Push Down Automata'').
Indicheremo convenzionalmente \hl{l'inizio della pila con $Z_0$}.

A grandi linee, una \hl{mossa} dell'automa a pila è \hl{strutturata in diversi
passi}:

\begin{enumerate}
  \item \hl{Leggi un simbolo (o nulla) dall'input} (d'ora in poi lo chiameremo
    nastro d'ingresso);
  \item Esegui una \hl{pop di un elemento} dalla stack;
  \item \hl{Cambia stato};
  \item Sposta di una posizione il puntatore del carattere corrente (la testina
    del nastro d'ingresso);
  \item Esegui una \hl{push di una serie di caratteri (anche nulla)};
  \item Se è un automa traduttore, \hl{scrivi una stringa (anche nulla)
    sull'output} (nastro d'uscita).
\end{enumerate}

Come per gli FSA, \hl{la stringa in ingresso viene riconosciuta se l'automa la
scandisce completamente e termina su uno stato di accettazione}. Lo stato della
\hl{pila non è rilevante}. Se l'automa è \hl{traduttore}, allora \hl{se accetta}
la stringa \hl{l'output corrisponde alla stringa tradotta, altrimenti} viene
detta \hl{indefinita} e lo indichiamo con \hl{$\tau(x) = \bot$}. In generale
useremo il simbolo $\bot$ anche con la funzione $\delta$ per indicare una
transizione indefinita.

Poiché le transizioni di stato sono più ricche di quelle degli FSA, dobbiamo
adottare una \hl{notazione ben definita per indicare le varie azioni compiute}:

\begin{equation}
  \mhl{a, A / B\ldots, c}
\end{equation}

\begin{itemize}
  \item \hl{$a$} il carattere \hl{letto in input};
  \item \hl{$A$} il carattere \hl{letto dalla pila tramite stack};
  \item \hl{$B\ldots$} i caratteri \hl{reinseriti nella pila} tramite la push;
  \item \hl{$c$} il carattere \hl{scritto sull'output}.
\end{itemize}

Nel caso in cui l'automa \hl{non leggesse nulla} dal nastro d'ingresso diciamo
che l'automa \hl{ha effettuato una $\epsilon$-mossa} e la indichiamo
\hl{riportando $\epsilon$ come carattere letto} dal nastro d'ingresso. Vale
\hl{lo stesso anche con il carattere della push}.

\begin{nota}
  Un automa a pila \hl{non può non leggere nessun carattere dalla pila!}
  Scrivere, quindi, \hl{$a, \epsilon/B$ è sbagliato}.
\end{nota}

\begin{figure}[htb]
  \centering
  \begin{tikzpicture}[node distance=3cm,auto]
    \node[state,initial]   (q0) []            {$q_0$};
    \node[state]           (q1) [right of=q0] {$q_1$};
    \node[state]           (q2) [right of=q1] {$q_2$};
    \node[state,accepting] (q3) [right of=q2] {$q_3$};

    \path[->]
    (q0) edge              node {$a, Z_0/Z_0 A$} (q1)
    (q1) edge [loop above] node {$a, A/AA$} ()
    (q1) edge              node {$b, A/\epsilon$} (q2)
    (q2) edge [loop above] node {$b, A/\epsilon$} ()
    (q2) edge              node {$\epsilon, Z_0/\epsilon$} (q3);
  \end{tikzpicture}
  \caption{Esempio di un automa a pila.}%
  \label{fig:automa-pila}
\end{figure}

Formalizziamo ora i concetti introdotti.

\begin{defn}[\hl{Automa a stati finiti a pila}]\label{defn:automa-pila}
  Definiamo un \hl{automa a stati finiti con pila} $\mathcal{A}$ una
  \hl{eptupla} \hl{$\langle I, \Gamma, \delta, q_0, Z_0, F \rangle$} dove:

  \begin{itemize}
    \item \hl{$Q, I, q_0, F$} sono definiti alla \hl{stessa maniera} di un
      \hl{FSA};
    \item \hl{$\Gamma$} è l'\hl{alfabeto di pila};
    \item \hl{$Z_0$} è il \hl{simbolo iniziale di pila};
    \item \hl{$\delta: Q \times (I \cup \epsilon) \times \Gamma \to Q \times
      \Gamma^\star$} è la \hl{funzione di transizione}.
  \end{itemize}
\end{defn}

\begin{defn}[Automa a stati finiti a pila traduttore]\label{defn:automa-pila-trad}
  Definiamo un automa a stati finiti con pila $\mathcal{A}$ una ennupla
  $\langle I, \Gamma, \delta, q_0, Z_0, F, 0, \eta \rangle$ dove:

  \begin{itemize}
    \item $Q, I, q_0, F, O$ sono definiti alla stessa maniera di un FSA\@;
    \item $\Gamma$ è l'alfabeto di pila;
    \item $Z_0$ è il simbolo iniziale di pila;
    \item
      $\delta: Q \times (I \cup \epsilon) \times \Gamma \to Q \times \Gamma^\star$
      è la funzione di transizione;
    \item $\eta: Q \times (I \cup \epsilon) \times \Gamma \to O^\star$ è la
      funzione di traduzione.
  \end{itemize}
\end{defn}

\begin{nota}
  La funzione $\eta$ è definita ovunque lo è anche $\delta$.
\end{nota}

La funzione di \hl{$\delta$ deve essere parziale} perché l'esistenza delle
\hl{$\epsilon$-mosse causerebbe non-determinismo} in caso di completezza
dell'automa: \hl{non possono esistere una $\epsilon$-mossa tra due stati $q, q'$
se tra questi due stati esiste già un'altra mossa che legge lo stesso simbolo
dalla pila}. Un automa a stati finiti non può decidere deterministicamente tra
una $\epsilon$-mossa e una regolare. Ciò che abbiamo detto fino ad ora può
essere formalizzato come:

\begin{equation}
  \mhl{
  \forall q, A \delta(q, \epsilon, A) \neq \bot \implies
    \forall i \delta(q,i,A) = \bot
  }
\end{equation}

Il concetto intuitivo di stato che avevamo introdotto con gli FSA oramai non è
più adeguato in quanto è troppo semplicistico. Negli automi a pila, infatti, si
aggiunge anche lo stato della pila che anch'esso contribuisce allo stato
generale dell'automa. Formalizziamo, quindi, \hl{la generalizzazione dello
stato: la configurazione}.

\begin{defn}[Configurazione]\label{def:configurazione}
  Chiamiamo \hl{configurazione} di un automa a pila la \hl{tripla} (se traduttore
  quadrupla) $c = \langle q, x \gamma \rangle$
  ($\langle q, x \gamma, z \rangle$) dove:

  \begin{itemize}
    \item \hl{$q \in Q$} è lo \hl{stato} dell'organo di controllo;
    \item \hl{$x$} è la \hl{stringa ancora da leggere} nel nastro d'ingresso;
    \item \hl{$\gamma$} è la \hl{stringa di caratteri nella pila} (rappresentati
      usando la convenzione ``alto-destra basso-sinistra'').
    \item \hl{$z$} la \hl{stringa già scritta sul nastro di uscita}.
  \end{itemize}
\end{defn}

Tra le configurazioni di un automa a pila è presente una \hl{relazione di
transizione indicata con $\vdash$}. Possiamo esprimere il passaggio di stato
come:

\begin{equation}
  \mhl{
  c = \langle q, x, \gamma \rangle \vdash c' = \langle q', x', \gamma' \rangle
  }
\end{equation}

Indichiamo con \hl{$\vdash^\star$ la chiusura transitiva e riflessiva di
$\vdash$}. Essa non è altro che l'insieme delle nostre \hl{vecchie sequenze di
mosse}. Usando $\vdash^\star$ possiamo anche \hl{formalizzare l'accettazione di
una stringa} (e la sua eventuale traduzione) come:

\begin{equation}
  c_0 = \langle q_0, x, Z_0, (\epsilon) \rangle \vdash^\star
    c_f = \langle q, \epsilon, \gamma , (z) \rangle
\end{equation}

\begin{nota}
  D'ora in poi indicheremo la chiusura transitiva e riflessiva di una relazione
  $A$ con $A^\star$. La chiusura solo transitiva sarà $A^+$.
\end{nota}

\subsubsection{Analisi degli automi a pila}\label{sec:automi-pila-analisi}

Come anche per gli FSA, è facile trovare un \hl{linguaggi non riconosciuti dagli
automi a pila}. Uno di questi è:

\begin{equation}
  L = \{ a^n b^n c^n \}\label{eqn:automi-pila-lang-non-ric}
\end{equation}

L'incapacità di riconoscere il linguaggio~\ref{eqn:automi-pila-lang-non-ric} può
essere ricondotta al fatto che \hl{la pila è una memoria distruttiva}: bisogna
distruggere ciò che ci è salvato dentro per leggerla (pop). \hl{Quanto appena
detto si dimostra con una estensione al Pumping lemma}. Noi non la tratteremo.

Studiamo ora la chiusura della famiglia dei linguaggi riconosciuti da un automa
a pila. Prendiamo due linguaggi $L_1 = \{ a^n b^n \}, L_2 = \{ a^n b^{2n} \}$.
Essi sono individualmente riconosciuti dagli automi a pila, la loro unione però
non lo è (ovviamente si può dimostrare). Ciò ci indica che \hl{la famiglia dei
linguaggi riconosciuti dagli automi a pila non è chiusa rispetto all'unione e
(per motivi analoghi) neanche rispetto all'intersezione}. Per quanto riguarda
invece il \hl{complemento}? Usiamo la \hl{stessa idea degli automi a stati
finiti}: scambiamo gli stati di accettazione con quelli di non accettazione.
Anche in questo caso \hl{$\delta$ va ``completata'' cercando di evitare di
cadere nel non-determinismo}. Le \hl{$\epsilon$-mosse possono ancora causare
problemi}:

\begin{itemize}
  \item Si può creare un \hl{ciclo di $\epsilon$-mosse} che fa entrare l'automa
    in blocco;
  \item Può esserci una \hl{sequenza di $\epsilon$-mosse in cui si alternano
    stati di accettazione e di non accettazione}.
\end{itemize}

In entrambi i casi \hl{si possono costruire automi equivalenti che eliminano
questi problemi}, nel primo caso eliminando i cicli, nel secondo forzando
l'accettazione alla fine di una sequenza di $\epsilon$-mosse.

\subsection{Macchine di Turing}\label{sec:macchine-turing}

L'ultimo automa che tratteremo sarà la macchina di Turing. Partiamo dalla
\hl{versione a $k$-nastri}, un po' più semplice di quella originaria, ma che
gode delle stesse proprietà.

Come indica il nome, la macchina di Turing a $k$-nastri è \hl{analoga a un
automa a stati finiti al quale aggiungiamo $k$ nastri di memoria}. Le
\hl{testine dei nastri possono muoversi in ambo le direzioni} arbitrariamente.
Come anche per gli altri automi avremo i \hl{soliti stati e alfabeti}. Per
convenzione storica, \hl{i nastri sono rappresentati da sequenze infinite di
celle} invece che da stringhe finite. Per rappresentare una \hl{cella
inutilizzata} usiamo il simbolo speciale \hl{``blank''}, rappresentato da
\hl{uno spazio vuoto, $\_$ o $\not{b}$}. Assumeremo che ogni nastro \hl{contenga
solo un numero finito di celle non contenenti blank}. Come nel caso degli automi
a pila indichiamo \hl{l'inizio del nastro con $Z_0$}.

La mossa della macchina di Turing è simile a quella dell'automa a pila ma un po'
più articolata. Possiamo suddividerla in \hl{due ``fasi''}:

\begin{enumerate}
  \item \hl{Lettura}:
    \begin{itemize}
      \item \hl{Legge} il carattere in corrispondenza della testina del
        \hl{nastro d'ingresso};
      \item \hl{Legge} i $k$ caratteri dai \hl{nastri};
      \item Valuta lo \hl{stato} dell'organo di controllo.
    \end{itemize}
  \item \hl{Scrittura}:
    \begin{itemize}
      \item Cambia \hl{stato};
      \item \hl{Scrittura} di un carattere sui \hl{nastri di memoria};
      \item Eventuale \hl{scrittura} di un carattere sul \hl{nastro di uscita};
      \item \hl{Spostamento delle testine} di una posizione.
    \end{itemize}
\end{enumerate}

Introduciamo anche la \hl{nuova notazione per le transizioni} (tra parentesi è
riportata la parte aggiuntiva nel caso di presenza di output):

\begin{equation}
  \mhl{
  i, \langle A_1, \ldots, A_k \rangle/(o),
    \langle A'_1, \ldots, A'_k \rangle,
    \langle M_0, \ldots, M_k, (M_{k+1}) \rangle
  }
\end{equation}

\begin{itemize}
  \item $i$: carattere letto dal nastro di ingresso;
  \item $\langle A_1, \ldots, A_k \rangle$: le letture dai vari nastri;
  \item $o$: il carattere scritto sul nastro di uscita;
  \item $\langle A'_1, \ldots, A'_k \rangle$: le scritture sui vari nastri;
  \item $\langle M_0, \ldots, M_k, (M_{k+1}) \rangle$: i movimenti effettuati
    dai vari nastri dove:
    \begin{itemize}
      \item $M_0$ è il movimento della testina di ingresso;
      \item $M_{k+1}$ è il movimento della testina di output.
    \end{itemize}
\end{itemize}

Le nuove funzioni di transizione e traduzioni saranno le seguenti:

\begin{align}
  \delta&: Q \times I \times \Gamma^k \to
    Q \times \Gamma^k \times {\{R,L,S\}}^{k+1} \\
  \eta&: Q \times I \times \Gamma^k \to
    Q \times \Gamma^k \times {\{R,L,S\}}^{k+1} \times O \times \{R,S\}
\end{align}

Lo \hl{stato iniziale} di una macchina di Turing è \hl{come ce lo
immagineremmo}: $Z_0$ seguito da blank nei nastri, uscita tutta blank, testine
in posizione 0 per ogni nastro, organo di controllo nello stato iniziale e
stringa iniziale scritta sul nastro iniziale a partire dalla posizione 0 seguita
da blank. \hl{Le condizioni di terminazione, e quindi di accettazione, sono
leggermente diverse da quelle viste fino ad ora}:

\begin{itemize}
  \item Gli \hl{stati di accettazione} sono sempre \hl{$F \subseteq Q$};
  \item Per convenzione la \hl{$\delta (\eta)$ non è definita a partire dagli
    stati finali}:

    \begin{equation}
      \forall q \in F \delta(q, \ldots) = \bot, (\eta (q, \ldots) = \bot)
    \end{equation}

  \item La macchina si \hl{ferma in uno stato $q$ quando
    $\delta(q, \ldots) = \bot$};
  \item La stringa in ingresso è \hl{accettata se e solo se dopo un numero
    finito di transizioni la macchina si ferma in uno stato di accettazione}.
\end{itemize}

Ciò significa che una stringa in ingresso non è accettata se la macchina si
ferma in uno stato di accettazione o se la macchina non si ferma.

\subsubsection{Proprietà di chiusura delle macchine di Turing}\label{sec:analisi-mt}

La famiglia dei linguaggi riconosciuti dalle macchine di Turing è \hl{chiusa}
per:

\begin{itemize}
  \item \hl{$\cup$} simulazione di \hl{esecuzione ``in parallelo''};
  \item \hl{$\cap$} simulazione di \hl{esecuzione ``in serie''};
  \item \hl{$ . $} simile a $\cap$;
  \item \hl{$\star$} come concatenazione.
\end{itemize}

Per quanto riguarda il \hl{complemento} la situazione è diversa. Il principale
problema sta nel fatto che \hl{non esistono macchine di Turing loop-free}, ossia
macchine di Turing equivalenti ad una data ma con eventuali cicli rimossi (come
si poteva fare per PDA e FSA). A causa di ciò il \hl{rischio di generare
computazioni infinite} non è eliminabile. La \hl{dimostrazione} di ciò verrà
vista in seguito nella \hl{parte di computabilità del corso}.

\subsubsection{Modelli equivalenti di macchine di Turing}\label{sec:modelli-mt}

Noi abbiamo introdotto il modello della macchina di Turing a $k$ nastri. \hl{Si
può dimostrare, però, che esistono diverse formulazioni equivalenti della
macchina di Turing. Queste diverse tipologie di macchina sono funzionalmente
equivalenti, con unica differenza la complessità dell'organo di controllo.}

\paragraph{TM a singolo nastro} Il primo modello, e anche il \hl{più
vecchio}, che enunceremo è quello della TM a singolo nastro. Essa, come implica
il nome, \hl{possiede un singolo nastro di memoria infinito sul quale la testina
si può muovere in entrambe le direzioni}. Questo unico nastro \hl{viene usato
come memoria, input ed eventualmente output}. Attenzione a \hl{non confonderla
con la TM con $k=1$ nastri} (chiamata ``ad un nastro di memoria'').

\paragraph{TM con nastro di memoria bidimensionale} Un altro modello
interessante è quello in cui il \hl{nastro di memoria è organizzato come una
tabella e la testina si può muovere in entrambe e 4 le direzioni cardinali
sequenzialmente}. Si ricorda che l'accesso randomico alla memoria non è
possibile con una semplice TM\@.

\paragraph{Macchine di von Neumann} La macchina di von Neumann è il
\hl{modello astratto di un computer con processore, memoria ad accesso randomico
e periferiche}. Le macchine di Turing \hl{possono simulare anche questo modello}
già più complesso. Il \hl{risultato} però è una macchina \hl{molto più complessa
e lenta}. Ciò vale in generale: \hl{si possono costruire modelli più prestanti e
complessi della macchina di Turing, ma essi non ne aumentano la capacità
espressiva}.

\subsection{Modelli operazionali non deterministici}\label{sec:modelli-non-det}

I modelli visti \hl{fino ad ora} sono detti \hl{deterministici}: \hl{in un certo
stato e con certi ingressi la mossa eseguita è sempre la stessa}. Se
\hl{neghiamo questa ipotesi} creiamo dei \hl{modelli} detti \hl{non
deterministici}. Ciò significa che \hl{per un certo stato l'automa potrà
eseguire più mosse diverse ed è lui a scegliere quale di queste eseguire}. Si
vengono a \hl{creare}, quindi, dei \hl{fili (thread) di esecuzione che l'automa
può seguire}. Il modello dell'esecuzione di un automa non deterministico può
visto come:

\begin{description}
  \item[Parallelo] L'automa esegue \hl{tutte le strade contemporaneamente}.
    L'automa si ferma quando tutti le fili di esecuzione hanno terminato o per
    esaurimento dell'input o per la parzialità delle funzione di transizione.
  \item[Sequenziale] L'automa \hl{esegue solo un filo, ma ad ogni biforcazione
    sceglie uno dei fili di esecuzione in modo casuale}.
\end{description}

Di solito i modelli non deterministici \hl{tendono ad essere più compatti
sacrificando l'operatività}. In un \hl{contesto pratico} essi possono essere
\hl{realizzati utilizzando più esecutori, seguendo il modello parallelo}.
Vediamo le varianti non deterministiche dei modelli già noti.

\subsubsection{Automi a stati finiti non deterministici}\label{sec:nfa}

Iniziamo con il primo modello, e il più semplice gli automi a stati finiti non
deterministici o NFA (``nondeterministic finite automata''). Diciamo che un
\hl{FSA è non deterministico se esiste $\delta(q, a) = \{q_1, q_2\}$} ossia
\hl{associati ad uno stato e ad un carattere è associato un insieme di
transizioni}. Sarà quindi necessario \hl{ridefinire $\delta$ e $\delta^\star$}.

\begin{gather}
  \mhl{ \delta: \; Q \times I \to \wp(Q) } \\
  \mhl{
    \delta^\star(q,x) =
    \begin{cases}
      \delta^\star(q, \epsilon) = \{q\} & x = \epsilon \\
      \delta^\star(q, y.i) = \bigcup_{q' \in \delta^\star(q, y)} \delta(q', i) &
        x=y.i, i \in I
    \end{cases}
  }
\end{gather}

\begin{figure}[htb]
  \centering
  \begin{tikzpicture}[node distance=3cm,auto]
    \node[state,initial]   (q0)  []                                  {$q_0$};
    \node[state]           (q1)  [above right of=q0, yshift=-0.25cm] {$q_1$};
    \node[state,accepting] (q11) [above right of=q1, yshift=-1cm]    {$q_{11}$};
    \node[state]           (q12) [below right of=q1, yshift=+1cm]    {$q_{12}$};
    \node[state]           (q2)  [below right of=q0, yshift=+0.25cm] {$q_2$};
    \node[state,accepting] (q21) [above right of=q2, yshift=-1cm]    {$q_{21}$};
    \node[state]           (q22) [below right of=q2, yshift=+1cm]    {$q_{22}$};

    \path[->]
    (q0) edge node {$a$} (q1)
    (q1) edge node {$a$} (q11)
    (q1) edge node {$a$} (q12)
    (q0) edge node {$a$} (q2)
    (q2) edge node {$b$} (q21)
    (q2) edge node {$a$} (q22);
  \end{tikzpicture}
  \caption{Un esempio di NFA.}\label{fig:nfa}
\end{figure}

Una \hl{stringa $x \in L$ appartiene al linguaggio modellato} da un NFA se:

\begin{equation}
  \mhl{ \delta^\star(q_0, x) \cap F \neq \emptyset }
\end{equation}

Ossia c'è \hl{almeno una sequenza di mosse che ci porta allo stato finale}. È
possibile anche considerare $\delta^\star(q_0, x) \subseteq F$.

È importante sottolineare che \hl{gli NFA non possiedono un potere riconoscitivo
maggiore dei semplici FSA}\@. Infatti \hl{possiamo sempre sintetizzare un FSA
equivalente ad uno non deterministico}. Intuitivamente, possiamo trasformare un
automa non deterministico in uno deterministico \hl{semplicemente unendo in un
singolo stato l'insieme di arrivo della $\delta$ e mantenendo gli archi}.
Possiamo anche operare nell'altro senso, ossia costruire un automa non
deterministico a partire da uno deterministico.

\subsubsection{Automi a pila non deterministici}\label{sec:npda}

Seguendo l'evoluzione svolta nella parte che tratta gli automi deterministici,
introduciamo gli automi a pila non deterministici o NPDA\@. Il concetto di \hl{non
determinismo è analogo a quello trattato in}~\ref{sec:nfa}. L'avevamo \hl{già
incontrato quando avevamo parlato delle $\epsilon$-mosse}. La nuova funzione di
transizione è:

\begin{equation}
  \mhl{
    \delta: Q \times (I \cup \{\epsilon\}) \times \Gamma \to
      \wp_f(Q \times \Gamma^\star)
  }
\end{equation}

Il \hl{pedice $f$} dell'insieme delle parti sta per \hl{``finito''}. Infatti i possibili
sottoinsiemi di $Q \times \Gamma^\star$ sono infiniti, ma noi \hl{consideriamo
solamente quelli ottenibili nell'immagine di $\delta$, ottenendo un insieme
delle parti finito}. Un \hl{NPDA accetta se} esiste una sequenza di mosse tale che:

\begin{equation}
  \mhl{
    c_0 \vdash^\star \{c_0, \ldots, c_n \}, \quad
      c_0 = \langle q_0, \epsilon, Z_0 \rangle,
      c_1 = \langle q, \epsilon, \gamma \rangle, \ldots, q \in F
  }
\end{equation}

\hl{Quindi la relazione $\vdash$ non è più univoca!}

Una \hl{semplice costruzione} come quella in \hl{figura}~\ref{fig:npda-unione}
ci permette di \hl{costruire sempre l'unione di due NPDA} e quindi di
\hl{dimostrare la chiusura degli NPDA rispetto all'unione}. Questa \hl{proprietà
non è condivisa dagli PDA}\@. Gli \hl{NPDA non sono, però, chiusi rispetto
all'intersezione}. Ciò implica che gli NPDA hanno un potere riconoscitivo
maggiore della controparte deterministica.

\begin{figure}[htb]
  \centering
  \begin{tikzpicture}[node distance=3cm,auto]
    \node[state,initial]   (q0)  []             {$q_0$};
    \node[state]           (q01) [above of=q0]  {$q_0'$};
    \node[state]           (q11) [right of=q01] {$q_1'$};
    \node[state]           (q21) [right of=q11] {$q_2'$};
    \node[state,accepting] (qf)  [right of=q21] {$q_f$};
    \node[state]           (q02) [below of=q0]  {$q_0''$};
    \node[state]           (q12) [right of=q02] {$q_1''$};
    \node[state]           (q22) [right of=q12] {$q_2''$};
    \node[state]           (q32) [right of=q22] {$q_3''$};

    \path[->]
    (q0)  edge []           node {$\epsilon,Z_0/Z_0$}      (q01)
    (q01) edge []           node {$a,Z_0/Z_0A$}            (q11)
    (q11) edge [loop above] node {$a,A/AA$}                ()
    (q11) edge []           node {$b,A/\epsilon$}          (q21)
    (q21) edge []           node {$\epsilon,Z_0/\epsilon$} (qf)
    (q21) edge [loop above] node {$b,A/\epsilon$}          ()
    (q0)  edge []           node {$\epsilon,Z_0/Z_0$}      (q02)
    (q02) edge []           node {$a,Z_0/Z_0A$}            (q12)
    (q12) edge []           node {$b,A/A$}                 (q22)
    (q12) edge [loop above] node {$a,A/AA$}                ()
    (q22) edge [bend left]  node {$b,A/\epsilon$}          (q32)
    (q32) edge []           node {$b,A/A$}                 (q22)
    (q32) edge []           node {$\epsilon,Z_0/\epsilon$} (qf);
  \end{tikzpicture}
  \caption{NPDA unione di due PDA\@. Lo NPDA riconosce $L = \{a^n b^n\} \cup
  \{a^n b^{2n}\}$. Da notare \hl{la $\epsilon$-mossa non deterministica che
  parte da $q_0$ e lega i due automi}, ognuno corrispondente ad uno dei due
  rami.}%
  \label{fig:npda-unione}
\end{figure}

Se la famiglia dei linguaggi riconosciuti dagli NPDA è \hl{chiusa rispetto a
$\cup$ ma non rispetto a $\cap$ non può esserlo rispetto al complemento a causa
delle leggi di De Morgan}.

Proviamo a dimostrare il risultato sopra. Procedendo con le \hl{stesse modalità
del caso deterministico}, possiamo ottenere una \hl{computazione che termina e
accetta il linguaggio complemento}. Se però \hl{consideriamo} il caso:

\begin{equation}
  \langle q_0, x, z_0 \rangle = c_0 \vdash^\star \{
    \langle q_1, \epsilon, \gamma_1 \rangle,
    \langle q_2, \epsilon, \gamma_2 \rangle \}, \mhl{ q_1 \in F, q_2 \notin F }
\end{equation}

La stringa \hl{$x$ è accettata anche se scambio $F$ con $Q \setminus F$},
rendendo impossibile la costruzione del complemento.

\subsubsection{Macchine di Turing non deterministiche}\label{sec:ntm}

Definiamo il concetto di \hl{non determinismo} in una macchina di Turing in modo
\hl{analogo ai casi precedenti}, ossia la capacità di poter \hl{assumere diversi
stati contemporaneamente}. Definiamo la relazione di \hl{transizione} per le NTM
(dall'inglese ``nondeterministic Turing machines''):

\begin{equation}
  \mhl{
    \delta : Q \times I \times \Gamma^k \to
      \wp(Q \times \Gamma^k \times \{ L,S,R \})
  }
\end{equation}

Non ripeteremo la definizione di \hl{configurazione, transizione, sequenza di
transizioni e accettazioni} poiché la loro \hl{definizione è invariata}.

Come nel caso degli NFA, le \hl{NTM non aggiungono capacità riconoscitiva}. Per
dimostrare ciò, costruiamo un \hl{algoritmo che permetta ad una macchina di
Turing deterministica di emulare il comportamento di una non deterministica}.
Poiché una stringa è accettata da una NTM solo se esiste un calcolo che termina
in uno stato di accettazione, rappresentiamo la \hl{computazione sotto forma di
un albero chiamato appunto albero delle computazioni}.

\begin{figure}[htb]
  \centering
  \begin{tikzpicture}[node distance=1cm and 3cm,every node/.style={scale=1.3}]
    \node[] (c0)  [] {$c_0$};
    \node[] (cx)  [below left=of c0] {$c_x$};
    \node[] (cy)  [below=of c0] {$c_y$};
    \node[] (cz)  [below right=of c0] {$c_z$};
    \node[] (cb)  [below right=of cx, xshift=-2.0cm] {\color{red}$c_b$};
    \node[] (cx2) [below=of cx] {$c_x$};
    \node[] (cd)  [below left=of cx, xshift=+2.0cm] {\color{ForestGreen}$c_d$};
    \node[] (cxi) [below=of cx2] {};
    \node[] (ce)  [below=of cy] {$c_e$};
    \node[] (cyi) [below right=of cy, xshift=-2.0cm] {};
    \node[] (cf)  [below right=of cz, xshift=-2.0cm] {\color{ForestGreen}$c_f$};
    \node[] (ca)  [below=of cz] {$c_a$};
    \node[] (ci)  [below left=of cz, xshift=+2.0cm] {\color{ForestGreen}$c_i$};
    \node[] (cf2) [below=of ce] {\color{ForestGreen}$c_f$};
    \node[] (cm)  [below=of ca] {\color{red}$c_m$};

    \path[->]
    (c0)  edge         (cx)
    (c0)  edge         (cy)
    (c0)  edge         (cz)
    (cx)  edge         (cb)
    (cx)  edge         (cx2)
    (cx)  edge         (cd)
    (cy)  edge         (ce)
    (cy)  edge[dotted] (cyi)
    (cz)  edge         (cf)
    (cz)  edge         (ca)
    (cz)  edge         (ci)
    (cx2) edge[dotted] (cxi)
    (ce)  edge         (cf2)
    (ca)  edge         (cm);
  \end{tikzpicture}
  \caption{Un esempio di albero delle computazioni. In verde sono indicati le
  configurazioni di accettazione, in rosso quelle di non accettazione e con le
  linee tratteggiati i percorsi che porterebbero ad una computazione infinita.}%
  \label{fig:albero-computazioni}
\end{figure}

Per emulare una NTM con una TM ci \hl{basterà}, quindi, \hl{percorrere in
larghezza questo albero, scandendo le varie configurazioni finché non ne
troveremo una di accettazione}. Per eseguire questa operazione in alberi
tradizionali esistono degli algoritmi ben consolidati
\hl{(``breadth first search'')}.

\section{Modelli descrittivi}\label{sec:modelli-descrittivi}

\subsection{Le grammatiche}\label{sec:grammatiche}

Le grammatiche sono un \hl{altro tipo di modello che possiamo usare per
modellare i linguaggi}. A differenza degli automi, le grammatiche sono un
\hl{modello generativo} più che riconoscitivo. Una automa, infatti, legge una
stringa in ingresso, la elabora e determina se appartiene al linguaggio; una
grammatica, invece, \hl{descrive una serie di regole per generare le stringhe
del linguaggio}.

Come anticipato, possiamo \hl{intuitivamente definire le grammatiche come un
insieme di regole usato per costruire le ``frasi''}, sinonimo di stringhe,
\hl{del linguaggio} di interesse. In modo \hl{analogo alle grammatiche dei
normali meccanismi linguistici}, una grammatica formale \hl{genera le stringe}
di un linguaggio attraverso un \hl{processo di riscrittura}. Esse \hl{descrivono
un oggetto principale} (la frase) come un \hl{insieme ordinato di componenti, a
loro volta descritti come composti da altri componenti fino ad arrivare agli
elementi fondamentali dell'alfabeto considerato}.

\begin{defn}[\hl{Grammatica}]\label{def:grammatica}
  Si definisce \hl{grammatica $G$} la \hl{quadrupla $(V_n, V_t, P, S)$} dove:

  \begin{itemize}
    \item \hl{$V_n$} è l'alfabeto o \hl{vocabolario non terminale};
    \item \hl{$V_t$} è l'alfabeto o \hl{vocabolario terminale};
    \item \hl{$S \in V_n$} è l'\hl{assioma} o simbolo iniziale;
    \item L'insieme di riscrittura o delle \hl{produzioni}:

      \begin{equation}
        P \subseteq V_n^+ \times {(V_t \cup V_n)}^\star =
          \{S \to \alpha, \alpha \to \beta, \ldots\}
      \end{equation}

  \end{itemize}
\end{defn}

\begin{nota}
  Per comodità indicheremo con \hl{$V$} l'insieme \hl{$V_t \cup V_n$}.
\end{nota}

\begin{defn}[\hl{Relazione di derivazione immediata}]\label{def:deriv}
  Definiamo la \hl{relazione di derivazione immediata $\deriv[G]$} per una
  grammatica $G = (V_t, V_n, P, S)$ come \hl{$\alpha \deriv[G] \beta$ se e solo
  se} dati $\alpha \in V^+$, $\beta \in V^\star$:

  \begin{enumerate}
    \item \hl{$\alpha = \alpha_1 \alpha_2 \alpha_3$};
    \item \hl{$\beta = \alpha_1 \beta_2 \alpha_3$};
    \item \hl{$\alpha_2 \to \beta_2 \in P$}.
  \end{enumerate}
\end{defn}

\begin{nota}
  Dove non ambiguo ometteremo il pedice indicante la grammatica per alleggerire
  la notazione. Indicheremo inoltre con $\derivstar$ la chiusura riflessiva
  e transitiva di $\deriv$.
\end{nota}

\begin{defn}[Linguaggio generato da una grammatica]\label{def:ling-gen-grammatica}
  Definiamo $L(G)$ il linguaggio generato dalla grammatica
  $G = (V_t, V_n, P, S)$ un linguaggio tale che:

  \begin{equation}
    L(G) = \{ x \in V_t^\star : S \derivstar x \}
  \end{equation}
\end{defn}

\begin{esempio}
  Definiamo una prima grammatica semplice: $V_t = \{a,b,c\}$, $V_n =
  \{S,A,B,C\}$ con assioma $S$ e produzioni $P = \{S \to A, A \to Aa, A \to B,
  B \to bB, B \to C, C \to cC, C \to \epsilon \}$. Una possibile derivazione
  consiste in $S \deriv A \deriv aA \deriv aaA \deriv aaB \deriv aaC \deriv aacC
  \deriv aaccC \deriv aacccC \deriv aaccc$ oppure $S \deriv A \deriv B \deriv bB
  \deriv bC \deriv b$. Evidentemente il linguaggio modellato è $L(G) =
  \{a^*b^*c^*\}$.
\end{esempio}

\begin{esempio}
  Definiamo una grammatica un po' più elaborata: $V_t = \{a,b\}$, $V_n = \{S\}$,
  assioma $S$ e produzioni $P = \{S \to aSbS, S \to \epsilon\}$. Studiando le
  varie derivazioni si vede che il linguaggio modellato è quello delle coppie di
  $a,b$ ``ben parentetizzate''.
\end{esempio}

\begin{esempio}
  Definiamo, infine, un'ultima grammatica ancora più complessa: $V_t =
  \{a,b,c\}$, $V_n = \{S,A,B,C,D\}$, assioma $S$ e produzioni
  $P = \{S \to aACD, A \to aAC, A \to \epsilon, B \to b, CD \to BDc, CB \to BC,
  D \to \epsilon\}$. Il linguaggio generato da questa grammatica sarà $L(G) =
  \{a^n b^n c^n \}$.
\end{esempio}

\subsection{Espressività di una grammatica}\label{sec:espressivita-grammatica}

Nella \hl{sezione precedente} abbiamo mostrato con degli \hl{esempi} che è
possibile \hl{generare linguaggi che sappiamo essere riconosciuti da degli
automi} (usando la potenza minima): il primo da un FSA, il secondo da un PDA e
il terzo da una TM\@. È possibile organizzare le \hl{grammatiche} in una
\hl{gerarchia in base al loro potere generativo} e inoltre \hl{è possibile che
ci sia una relazione tra le potenze riconoscitive dei vari autonomi e le
grammatiche}?

Alla \hl{prima domanda} ha già risposto \hl{Noam Chomsky con la sua gerarchia
delle grammatiche}. Essa è divisa in \hl{4 classi} a seconda delle
\hl{limitazioni imposte sulla forma delle produzioni} $\alpha \to \beta$
(tabella~\ref{tab:gerarchia-grammatiche}).

\begin{table}[htb]
  \centering
  \begin{tabular}{lll}
    \toprule
    Tipo & Nome            & Forma delle produzioni \\
    \midrule
    0    & \hl{Non limitate}    & --- \\
    1    & \hl{Contestuali}     & \hl{$|\alpha| \leq |\beta|$} \\
    2    & \hl{Non contestuali} & \hl{$|\alpha| = 1$} \\
    3    & \hl{Regolari}        & \hl{$|\alpha| = 1 \vee \beta \in V_t . V$} \\
    \bottomrule
  \end{tabular}
  \caption{La gerarchia delle grammatiche di Chomsky.}%
  \label{tab:gerarchia-grammatiche}
\end{table}

Utilizzando questa gerarchia una \hl{grammatica più potente genera tutti i
linguaggi di una meno potente}, andando a creare una situazione come in
figura~\ref{fig:gerarchia-grammatiche}. \hl{L'inclusione della famiglia di
grammatiche meno potenti in quella di grammatiche più potenti è però stretta}?

\begin{figure}[htb]
  \centering
  \begin{tikzpicture}
    \draw[line width=0.4mm] (5,5) ellipse (5cm and 3cm)       node (0) {};
    \draw[line width=0.4mm] (5,5) ellipse (3.75cm and 2.25cm) node (1) {};
    \draw[line width=0.4mm] (5,5) ellipse (2.5cm and 1.5cm)   node (2) {};
    \draw[line width=0.4mm] (5,5) ellipse (1.25cm and 0.75cm) node (3) {};

    \node at (5, 2.25cm) {Non limitate};
    \node at (5, 3cm)    {Contestuali};
    \node at (5, 4cm)    {Non contestuali};
    \node at (5, 4.5cm)  {Regolari};
  \end{tikzpicture}
  \caption{Diagramma di Venn rappresentante la gerarchia delle grammatiche.}%
  \label{fig:gerarchia-grammatiche}
\end{figure}

\subsection{Legame tra grammatiche e automi}\label{sec:gramamtiche-automi}

\hl{Generalizziamo ora l'osservazione della corrispondenza grammatica-automa}
fatta negli esempi in~\ref{sec:grammatiche}.

\paragraph{Grammatiche regolari} Come si potrebbe intuire, i \hl{linguaggi
generati fa grammatiche regolari coincidono con i linguaggi riconosciuti dagli
FSA (i linguaggi regolari)}. Poiché automa e grammatica sono in relazione di
equivalenza \hl{possiamo passare da un all'altro} (le due proposizioni si
dimostrano con una semplice induzione):

\begin{prop}[\hl{Passaggio da FSA a grammatica}]
  Per ottenere la grammatica equivalente ad un FSA\@:

  \begin{itemize}
    \item Poniamo \hl{$V_n = Q, V_t = I, S = \langle q_0 \rangle$};
    \item \hl{Per ogni $\delta(q, i) = q'$} diciamo che
      \hl{$\langle q \rangle \to i \langle q' \rangle \in P$}. Se
      \hl{$q' \in F$} aggiungiamo anche \hl{$\langle q \rangle \to i \in P$}.
  \end{itemize}
\end{prop}

\begin{prop}[\hl{Passaggio da grammatica a NFA}]
  Per ottenere lo NFA corrispondente alla grammatica:

  \begin{itemize}
    \item Poniamo \hl{$Q = V_n \cup \{q_f\}, I = V_t, q_0 = S, F = \{q_f\}$};
    \item Se \hl{$A \to bC \in P$} allora \hl{$\delta(A,b) = C$}. Invece se
      \hl{$A \to b \in P$} allora \hl{$\delta(A, b) = q_f$}.
  \end{itemize}
\end{prop}

\paragraph{Grammatiche non contestali} I linguaggi generati dalle
\hl{grammatiche libere dal contesto} coincidono con quelli riconosciuti dagli
\hl{NPDA}\@. La \hl{dimostrazione} di questa affermazione \hl{non è affatto
banale}, perciò diamo \hl{solamente l'intuizione} con la
\hl{figura}~\ref{fig:esempio-grammatica-to-npda}.

\begin{figure}[htb]
  \centering
  \begin{tikzpicture}[node distance=3cm,auto]
    \node[state,initial]   (q0) []            {$q_0$};
    \node[state]           (q1) [right=of q0] {$q_1$};
    \node[state,accepting] (q2) [right=of q1] {$q_2$};

    \path[->]
    (q0) edge []                      node {$\epsilon, Z_0/Z_0S$}     (q1)
    (q1) edge []                      node {$\epsilon, Z_0/\epsilon$} (q2)
    (q1) edge [out=45,in=75,loop]     node [above,xshift=+0.25cm] {$\epsilon, S/\underline{b}S\underline{a}$} ()
    (q1) edge [out=105,in=135,loop]   node [above,xshift=-0.25cm] {$\epsilon, S/\underline{ba}$} ()
    (q1) edge [out=-105,in=-135,loop] node {$a,\underline{a}/\epsilon$} ()
    (q1) edge [out=-45,in=-75,loop]   node {$b,\underline{b}/\epsilon$} ();
  \end{tikzpicture}
  \caption{NPDA corrispondente a $(\{S\}, \{a,b\} \{S \to aSb, S \to ab\}, S)$.}%
  \label{fig:esempio-grammatica-to-npda}
\end{figure}

\paragraph{Grammatiche non ristrette} Le \hl{grammatiche non ristrette} sono
equivalenti alla \hl{macchine di Turing}. \hl{Costruire una macchina di Turing
(a nastro singolo) non deterministica a partire da una grammatica non ristretta}
$G$ non è assai difficile: con la \hl{stringa} $x$ posizionata sul \hl{nastro
d'ingresso} eseguiamo un \hl{ciclo}:

\begin{enumerate}
  \item \hl{Scandiamo} il nastro \hl{finché non troviamo una parte destra}
    $\beta$ di una \hl{produzione} $\alpha \to \beta$ della grammatica;
  \item \hl{Quando se ne trova una}, scegliendola non deterministicamente, essa
    \hl{viene sostituita} dalla corrispondente \hl{parte sinistra} $\alpha$.
\end{enumerate}

\noindent Questo ciclo è chiamato \hl{``processo di riduzione''} della stringa.
Per come abbiamo strutturato il ciclo abbiamo che \hl{$\alpha \deriv \beta$ se e
solo se $\langle q, Z_0, \alpha \rangle \vdash^\star \langle q, Z_0, \beta
\rangle$}. Se e quando il \hl{contenuto del nastro d'ingresso} diviene
\hl{l'assioma $S$} della grammatica, la \hl{stringa} d'ingresso verrà
\hl{accettata}. Il procedimento descritto \hl{non garantisce che la macchina di
Turing generata riesca a concludere sempre la computazione}.

\subparagraph{Grammatica equivalente a TM} Eseguire il processo inverso è più
complicato. Poiché una \hl{grammatica non può ricevere una stringa in input e
può manipolare solo gli elementi non terminali di una stringa}, dobbiamo fare in
modo che essa \hl{generi tutte le possibili stringhe del tipo $x \termsep X$}
con $x \in V_t^\star$, $\termsep \in V_n$ un separatore  e \hl{$X$ una ``copia''
di $x$ fatta solo di elementi non terminali}. Il nostro \hl{obiettivo} è
ottenere una \hl{derivazione $x \termsep X \derivstar x$ se e solo se $x$ è
accettata dalla TM}\@. Innanzitutto la grammatica deve possedere le
\hl{produzioni che generano $x \termsep X$} (consideriamo $V_t = \{a,b\}$):

\begin{align}
  \mhl{S \to SA'A, S \to SB'B, S \to \termsep} & \quad
    \text{(genero coppie di simboli)}\\
  \mhl{AA' \to A'A, BA' \to A'B} & \quad \text{(scorro le $A'$ a sx)}\\
  \mhl{AB' \to B'A, BB' \to B'B} & \quad \text{(scorro le $B'$ a sx)}\\
  \mhl{\termsep A' \to a\termsep, B'\termsep \to b\termsep} & \quad
    \text{(quando scorro attraverso $\termsep$ trasformo)}
\end{align}

\noindent Dobbiamo ora \hl{simulare ogni possibile mossa della macchina di
Turing con una derivazione}. Consideriamo una \hl{macchina di Turing con
configurazione pari a quella rappresentata in
figura}~\ref{fig:grammatica-mt-stato}. Tale configurazione è \hl{rappresentata
dalla stringa $\termsep\alpha BqAC\beta$}. In base ai valori assunti da $\delta$
\hl{possiamo agire in 3 diversi modi}:

\begin{enumerate}
  \item \hl{$\delta(q, A) = \langle q', A', R \rangle$} aggiungo \hl{$qA \to
    A'q'$} alle produzioni;
  \item \hl{$\delta(q, A) = \langle q', A', S \rangle$} aggiungo \hl{$qA \to
    q'A'$} alle produzioni;
  \item \hl{$\delta(q, A) = \langle q', A', L \rangle$} aggiungo \hl{per ogni
    $B$} nell'alfabeto della TM la produzione \hl{$BqA \to q'B'A'$}.
\end{enumerate}

\begin{figure}[htb]
  \centering
  \begin{tikzpicture}
    \draw[black,thin] (0,0) grid (13, 1);

    \node[xshift=-0.05cm] at (0.5 ,0.5) [] ()  {\huge $\not{b}$};
    \node[xshift=-0.05cm] at (1.5 ,0.5) [] ()  {\huge $\not{b}$};
    \node[xshift=-0.05cm] at (2.5 ,0.5) [] ()  {\huge $\not{b}$};
    \node[xshift=-0.05cm] at (3.5 ,0.5) [] ()  {\huge $\not{b}$};
    \node[]               at (4.5 ,0.5) [] ()  {\huge $\alpha$};
    \node[]               at (5.5 ,0.5) [] ()  {\huge $B$};
    \node[]               at (6.5 ,0.5) [] (A) {\huge $A$};
    \node[]               at (7.5 ,0.5) [] ()  {\huge $C$};
    \node[]               at (8.5 ,0.5) [] ()  {\huge $\beta$};
    \node[xshift=-0.05cm] at (9.5 ,0.5) [] ()  {\huge $\not{b}$};
    \node[xshift=-0.05cm] at (10.5,0.5) [] ()  {\huge $\not{b}$};
    \node[xshift=-0.05cm] at (11.5,0.5) [] ()  {\huge $\not{b}$};
    \node[xshift=-0.05cm] at (12.5,0.5) [] ()  {\huge $\not{b}$};

    \node[anchor=north,draw] at (6.5,-1) [] (q) {\Huge $q$};

    \draw[-{Stealth[length=3mm,width=3mm]}] (q) -- (6.5,0);
  \end{tikzpicture}
  \caption{Configurazione della macchina di Turing in esame.}%
  \label{fig:grammatica-mt-stato}
\end{figure}

Per come abbiamo scritto le produzioni, i \hl{due stati in
figura}~\ref{fig:grammatica-mt-stati} sono in \hl{relazione se e solo se
$\termsep\alpha BqAC\beta \deriv \termsep\alpha BA'q'C\beta$}. La costruzione
della grammatica va, infine, \hl{completata aggiungendo le regole che cancellano
tutto ciò che sta a destra del separatore $\termsep$ (separatore incluso) se e
solo se la configurazione della macchina di Turing è accettante}, ad esempio
$\termsep\alpha Bq_f AC\beta$.

\begin{figure}[htb]
  \centering
  \begin{tikzpicture}
    \draw[black,thin] (0,0) grid (5, 1);
    \draw[black,thin] (6,0) grid (11, 1);

    \node[] at (0.5,0.5) [] () {\huge $\alpha$};
    \node[] at (1.5,0.5) [] () {\huge $B$};
    \node[] at (2.5,0.5) [] () {\huge $A$};
    \node[] at (3.5,0.5) [] () {\huge $C$};
    \node[] at (4.5,0.5) [] () {\huge $\beta$};

    \node[] at (6.5 ,0.5) [] () {\huge $\alpha$};
    \node[] at (7.5 ,0.5) [] () {\huge $B$};
    \node[] at (8.5 ,0.5) [] () {\huge $A$};
    \node[] at (9.5 ,0.5) [] () {\huge $C$};
    \node[] at (10.5,0.5) [] () {\huge $\beta$};

    \node[anchor=north,minimum size=1cm,draw] at (2.5,-1) [] (q)  {\huge $q$};
    \node[anchor=north,minimum size=1cm,draw] at (8.5,-1) [] (q') {\huge $q'$};

    \node[anchor=north] at (5.5, -1) [] () {\huge $\vdash$};

    \draw[-{Stealth[length=3mm,width=3mm]}] (q)  -- (2.5,0);
    \draw[-{Stealth[length=3mm,width=3mm]}] (q') -- (9.5,0);
  \end{tikzpicture}
  \caption{Due configurazioni della macchina di Turing in esame che sono legate
  dalla transizione.}\label{fig:grammatica-mt-stati}
\end{figure}

\paragraph{Grammatiche monotone} Possiamo notare che le \hl{produzioni si
accorciano man mano che vengono ``espanse''}. Quindi se \hl{costruiamo} una
\hl{macchina di Turing equivalente} utilizzando i \hl{metodi descritti} in
questa sezione, essa \hl{userà al massimo la memoria occupata inizialmente dalla
stringa} in ingresso $x$. Possiamo, allora, \hl{limitare la potenza} della
nostra macchina fornendogli una \hl{memoria di dimensione finita}, ottenendo
così la macchina a minore potenza equivalente alle grammatiche monotone. Un
\hl{automa così definito è detto automa lineare}.

\section{Altri modelli utili}\label{sec:altri-modelli}

Degli \hl{altri modelli molto usati per descrivere i linguaggi sono i pattern e
le espressioni regolari}. Non andremo per nulla del dettaglio e ci limiteremo a
\hl{enunciare solo la definizione e al massimo qualche proprietà}.

\subsection{I pattern}\label{sec:pattern}

\begin{defn}[Sistema di pattern]
  Un sistema di pattern è una tripla $\langle A, V, p \rangle$ dove $A$ è un
  alfabeto, $V$ è un insieme di variabili disgiunto con $A$ e $p$ è una stringa
  su $A \cup V$ detta pattern.
\end{defn}

\subsection{Le espressioni regolari}\label{sec:regex}

Le espressioni regolari, o regex, le abbiamo \hl{già incontrate nella
sezione}~\ref{sec:fsa} e definite con la definizione~\ref{def:regex}. Esse
seguono la \hl{stessa idea generale dei pattern, ma hanno un potere espressivo
molto diverso}. Le regex hanno la\hl{ stessa espressività dei linguaggi regolari
e delle grammatiche regolari}. Faremo solo una \hl{dimostrazione veloce di un
solo senso dell'implicazione} in quanto l'altro è più complesso e oggetto di
altri corsi:

\begin{proof}[$\mathcal{L}\in\mathbf{RE} \implies \mathcal{L}\in\mathbf{REG}$]%
  \label{proof:equiv-re-reg-1}
  Guardando la definizione di espressione regolare si può notare che ciascuno
  dei casi base definisce un linguaggio regolare. Poiché le regex sono anche
  chiuse rispetto alle operazioni definite tutte le regex generalo linguaggi
  regolari.
\end{proof}

Con un semplice \hl{esempio} si può anche vedere che \hl{la famiglia dei
linguaggi descrivibili da una regex non coincide con quella dei linguaggi
generati dai sistemi di pattern}:

\begin{itemize}
  \item $L = \{xx : x \in \{0,1\}\}$ non è un linguaggio regolare, ma può essere
    descritto con il pattern $\langle \{0,1\}, \{x\}, xx\rangle$;
  \item Il linguaggio generato da $0^* 1^*$ è, ovviamente, regolare ma non è
    esprimibile con un pattern.
\end{itemize}

\hl{Quindi non è contenimento tra le due famiglie. Diciamo che esse sono non
confrontabili}.

\section{Modelli dichiarativi}\label{sec:modelli-dichairativi}

\subsection{La logica}\label{sec:logica}

La logica è un \hl{elemento fondamentale dell'informatica}. Esistono molti
linguaggi logici, ognuno con diversi livelli di espressività e utilizzo.
Nell'ambito di questo corso \hl{useremo la logica del primo ordine} con due
scopi: \hl{definizione di linguaggi e specifica della proprietà dei programmi}.
La logica, infatti, ci \hl{permetterà} sia di \hl{definire i linguaggi
specificandone le proprietà} e di esprimere le condizioni che le nostre
computazioni devono rispettare.

\begin{esempio}
  Consideriamo il linguaggio $\{a^n b^n : n \geq 0\}$, come possiamo descriverlo
  con una formula del primo ordine? Una forma è:

  \[
    \forall x (x \in L \iff \exists n (N \geq 0 \land a = a^n . b^n))
  \]
  Definendo opportunamente i predicati $\in L$, $\geq$ e $=$ e le funzioni di
  concatenazione ed elevamento a potenza.
\end{esempio}

\begin{esempio}
  Caratterizziamo un altro linguaggio: $L_1 = a^*b^*$. Uno strumento utile per
  caratterizzare un linguaggio con la logica è quello di pensare in modo
  induttivo. Ragionando induttivamente possiamo ricavare una forma logica
  corrispondente a $L_1$:

  \[
    \forall x (x \in L_1 \iff (x = \epsilon) \lor
    \exists y (x = ay \land y \in L_1) \lor \exists y (x = yb \land y \in L_1))
  \]
\end{esempio}

\begin{esempio}
  Consideriamo il linguaggio $L_2 = a^* b^* c^*$. Possiamo vederlo come $a^* b^*
  . b^* c^*$ dove entrambi questi sotto-linguaggi, chiamiamoli $L_1$ ed $L_3$,
  hanno struttura simile a $L_1$. Quindi una stringa appartiene ad $L_2$ se
  appartiene ad uno dei due linguaggi oppure se la prima sotto-stringa inizia
  con `a' seguita da un suffisso $y$ composto sia da `a' e `b' e la seconda
  sotto-stringa è composta da un prefisso $y$ di `b' e `c' seguito da una c. Una
  formula del primo ordine che caratterizza la seguente è:

  \[
    \forall x (x \in L_2 \iff x\in L_1 \lor x \in L_3 \lor
      \exists y (x = ay \land (y \in L_2 \lor y \in L_3)) \lor
      \exists y (x = yc \land (y \in L_2 \lor y \in L_3)))
  \]

  Si può ridurre questa formula? Certo. Mantenendo la struttura come
  concatenazione possiamo scrivere:

  \[
    \forall x (x \in L_2 \iff \exists z \exists y
     (y \in L_1 \land z \in L_3 \land x = y.z))
  \]
\end{esempio}

\begin{esempio}
  Consideriamo l'ulteriore esempio del linguaggio:

  \[
    L_4 = \{x \in \{a,b\} : \text{ numero di } a \text{ è uguale al numero di } b\}
  \]

  Per indicare ``il numero di'' introduciamo la funzione di arietà 2 $\#(x,a)$ che
  indica il numero di occorrenze del carattere `a' nella stringa $x$ così
  formalmente definita:

  \begin{align*}
    & \forall x \forall y ((x = \epsilon \implies \#(x,a)=0) \land \\
      & \quad (x = a.y \implies \#(x,a) = \#(y,a)+1) \land \\
      & \quad (x=b.y \implies \#(x,a) = \#(y,a))) \land \\
      & \quad \forall x \forall y ((x = \epsilon \implies \#(x,b)=0) \land \\
      & \quad (x = b.y \implies \#(x,b) = \#(y,b)+1) \land \\
      & \quad (x=a.y \implies \#(x,b) = \#(y,b)))
  \end{align*}

  Il nostro linguaggio in formula del primo ordine sarà
  $\forall x (x \in L_4 \iff \#(x,a)=\#(x,b))$.
\end{esempio}

\subsubsection{Precondizioni e postcondizioni}

Approfondiamo qui un uso della logica che ci interessa ai fini del corso: la
specifica di condizioni che il nostri programma deve rispettare. Si preferisce
specificare le condizioni iniziali e finali dell'ambiente invece di specificare
il funzionamento specifico del programma perché di solito è più importante e
flessibile definire correttamente cosa un programma faccia rispetto a definire
una specifica implementazione. Infatti diverse implementazione possono
rispettare le stesse precondizioni e postcondizioni, portando a programmi
ottimizzati per diverse situazioni (uso minore di memoria, velocità di
esecuzione maggiore, uso di particolari costrutti ecc\ldots) che però sono
funzionalmente equivalenti.

Per la specifica delle condizioni useremo la notazione di Hoare:

\begin{equation}
  \begin{aligned}
    & \{ \mathit{Precondizione} \} \\
    & \mathit{Programma} \\
    & \{ \mathit{Postcondizione} \}
  \end{aligned}
\end{equation}

Se valgono le precondizioni, affinché il programma sia considerato corretto
dopo l'esecuzione dovranno valere le postcondizioni. Nella pratica la condizioni
possono essere definite tramite linguaggio naturale nei commenti, funzioni di
\texttt{assert} o linguaggi ad-hoc. Nel nostro contesto teorico le definiremo
usando la logica del primo ordine arricchita dei necessari predicati.

\begin{esempio}
  Sia un programma $P$ che implementa la ricerca di un
  elemento $x$ in un array ordinato di $n$ elementi. La precondizione sarà che
  l'array sia ordinato e la postcondizione che la variabile logica
  $\mathtt{found}$ debba essere vera se e solo se l'elemento $x$ esiste
  nell'array $a$. Notiamo che non ci interessa che tipo di algoritmo è
  implementato da $P$. Usando la notazione di Hoare, scriveremo:

  \[
    \begin{aligned}
      & \{ \forall i (1 \leq i \leq n-1 \implies a[i] \leq a[i+1] ) \} \\
      & P \\
      & \{ \mathtt{found} \iff \exists i (1 \leq u \leq n \land a[i] = x ) \}
    \end{aligned}
  \]

  Dove abbiamo definito ``implicitamente'' $a[i]$ l'$i$-esimo elemento di $a$.
\end{esempio}

\subsection{La logica monadica del primo ordine}\label{sec:mfo}

Consideriamo un \hl{frammento di logica del primo ordine} che ci permette di
\hl{descrivere parole su un alfabeto $I$}. Chiamiamo questa logica \hl{``logica
monadica del primo ordine''} o MFO\@. La sintassi di questa logica è la
seguente:

\begin{defn}[\hl{Sintassi della MFO}]\label{def:mfo-sintassi}
  Una \hl{formula} $\phi$ fa parte della \hl{logica monadica del primo ordine}
  se:

  \begin{equation}
    \mhl{
    \phi\coloneqq a(x) \mid x < y \mid\neg\phi\mid\phi\land\phi\mid\forall x(\phi)
    }
  \end{equation}

  Con:
  \begin{enumerate}
    \item \hl{$a \in I$ e $a(x)$} un predicato per ogni singolo simbolo
      dell'alfabeto;
    \item $<$ la relazione di minore;
    \item $\mathbb{N}$ dominio delle variabili.
  \end{enumerate}
\end{defn}

Data una \hl{parola $w \in I^+$} ed un \hl{simbolo $a\in I$, $a(x)$} è \hl{vera
se e solo se l'$x$-esimo simbolo di $w$ è $a$} (il primo simbolo di $w$ ha
indice 0). Per esempio una formula che è vera su tutte e solo le parole il cui
primo simbolo esiste ed è `a' è: $\exists x(x = 0 \land a(x))$. Considereremo
solo parole non vuote nelle definizioni poiché alleggerisce molto la notazione.
I concetti possono, però, essere estesi anche a parole vuote.

\hl{Il resto dei predicati consueti viene definito con}:

\begin{align}
  \mhl{\phi_1 \lor \phi_2}     & \mhl{\triangleq \neg(\neg\phi_1\land\neg\phi_2)} \\
  \mhl{\phi_1 \implies \phi_2} & \mhl{\triangleq \neg\phi_1\lor\phi_2} \\
  \mhl{\exists x(\phi)}        & \mhl{\triangleq \neg \forall x(\neg\phi)} \\
  \mhl{x = y}                  & \mhl{\triangleq \neg(x<y) \land \neg(y<x)} \\
  \mhl{x \leq y}               & \mhl{\triangleq \neg(y<x)}
\end{align}

Possiamo anche definire \hl{altri predicati utili}:

\begin{itemize}
  \item La \hl{costante $0$} tale che \hl{$x = 0 \triangleq \forall
    y(\neg(y<x))$};
  \item Il predicato \hl{``$y$ successore di  $x$''}
    \hl{$\succc(x,y) \triangleq x<y \land \neq\exists z(x<z \land z<y)$};
  \item Le \hl{costanti $1,2,3,\ldots$ come i successori di $0,1,2,\ldots$}.
\end{itemize}

Per comodità possiamo \hl{definire} altre \hl{abbreviazioni} del tipo
\hl{$y=x+1$ per indicare $\succc(x,y)$}, \hl{$y=x+k$} per indicare lo
\hl{spiazzamento di $k$}, \hl{$y=x-1$ per indicare $\succc(y,x)$},
\hl{analogamente $y=x-k$} e \hl{$\last(x)$ per indicare l'ultima posizione}.

Per definire la \hl{semantica} introduciamo la definizione di \hl{assegnamento}.

\begin{defn}[\hl{Assegnamento}]\label{def:mfo-assegnamento}
  Siano \hl{$w\in I^+$ e $V_1$ l'insieme delle variabili}. Un \hl{assegnamento}
  è una \hl{funzione $\nu_1 : V_1 \to \{0,1,\ldots,|w|-1\}$} tale che:

  \begin{itemize}
    \item \hl{$w,\nu_1 \models a(x)$} se e solo se \hl{$w = uav$} e
      $|u| = \nu_1(x)$;
    \item \hl{$w,\nu_1 \models x < y$} se e solo se \hl{$\nu_1(x) < \nu_1(y)$};
    \item \hl{$w,\nu_1 \models \neg\phi$} se e solo se \hl{non
      $w\nu_1 \models \phi$};
    \item \hl{$w,\nu_1 \models \phi_1 \land \phi_2$} se e solo se
      \hl{$w,\nu_1 \models \phi_1$ e $w,\nu_1 \models \phi_2$};
    \item \hl{$w,\nu_1 \models a(x)$} se e solo se \hl{$w,\nu_1' \models \phi$
      per ogni $v_1'$ con $\nu_1'(y) = \nu_1(y)$, $y \neq x$}.
  \end{itemize}
\end{defn}

Possiamo così definire il \hl{linguaggio corrispondente ad una formula chiusa
$\phi$ come}:

\begin{equation}
  \mhl{ L(\phi) = \{w\in I^+ : \exists\nu_1 (w, \nu_1 \models \phi)\} }
\end{equation}

\subsubsection{Proprietà}\label{sec:mfo-proprietà}

I \hl{linguaggi esprimibili tramite MFO} sono \hl{chiusi rispetto a unione,
intersezione e complemento come potrebbe far intendere la buona definizione di
$\land$, $\lor$ e $\neg$}. Essi però \hl{non sono chiusi rispetto alla star di
Kleene}. I linguaggi esprimibili da MFO sono perciò detti \hl{``star-free''}.

Un altra peculiarità delle formule MFO è il fatto che siano \hl{meno potenti
degli FSA\@}. Essi infatti \hl{non possono rappresentare un particolare
linguaggio regolare $L_p$ fatto di tutte e sole le parole di lunghezza pari su
un alfabeto di una singola lettera}. Quindi possiamo dire che i \hl{linguaggi
``star-free'' sono un sottoinsieme dei linguaggi regolari}.

\subsection{Logica monadica del secondo ordine}\label{sec:mso}

Per permettere alla logica \hl{MFO} di avere lo stesso potere espressivo degli
FSA bisogna \hl{aumentarne la potenza}. Un modo per fare ciò è \hl{permettere di
quantificare i predicati monadici}. Ammettiamo quindi \hl{formule del tipo
$\exists X(\phi)$ dove $X$ è una variabile il cui dominio è l'insieme dei
predicati monadici}.

In questo caso la \hl{semantica} prevede anche un \hl{secondo assegnamento}
\hl{$\nu_2: V_2 \to \wp(\{0,1,\ldots,|w|-1\})$} con le seguenti \hl{regole
aggiuntive}:

\begin{itemize}
  \item \hl{$w, \nu_1, \nu_2 \models X(x)$} se solo se
    \hl{$\nu_2(x) \in \nu_2(X)$};
  \item \hl{$w, \nu_1, \nu_2 \models \exists X(\phi)$} se e solo se
    \hl{$w, \nu_1, \nu_2' \models \phi$ per qualche $\nu_2'$ con
    $\nu_2'(Y) = \nu_2(Y)$, $Y \neq X$}.
\end{itemize}

\begin{esempio}
  Possiamo allora descrivere il linguaggio $L_p$ visto precedentemente
  (perdonate la lisp-syntax ma la formula era troppo lunga):

  \begin{align*}
    & \exists P( \\
    &   \quad \forall x(a(x) \land \neg P(0) \land \\
    &   \quad \quad \forall y (y = x+1 \implies (\neg P(x) \iff P(y))) \land \\
    &   \quad \quad (\last(x) \implies P(x)))) \\
  \end{align*}

  Dove $P$ indica un insieme di posizioni dispari.
\end{esempio}

\subsubsection{Trasformare da MSO a FSA}\label{sec:mso-fsa}

In generale, grazie alle quantificazioni del secondo ordine, \hl{per ogni FSA},
è possibile scrivere una \hl{formula MSO equivalente}. In modo non rigoroso
possiamo procedere così. Innanzitutto \hl{ogni predicato monadico quantificato
corrisponde a ciascuno stato}. \hl{Se} nell'automa \hl{non è possibile essere in
diversi stati contemporaneamente (determinismo), mettiamo i vari stati in
esclusione mutua}. Infine \hl{codifichiamo} tutte le \hl{transizioni} usando
\hl{$last(x)$} e \hl{$\neg last(x)$} per \hl{caratterizzare gli stati finali e
non finali} rispettivamente.

Si può eseguire anche la \hl{trasformazione inversa} tramite un processo ben
definito, il \hl{teorema di Büchi-Elgot-Trakhtenbrot}. Noi \hl{non lo vedremo}
poiché è un teorema molto tecnico.

Le due trasformazioni descritte ci premettono, quindi, di \hl{sancire
l'equivalenza tra FSA e MSO}\@.

\section{Teoria della computazione}\label{sec:teoria-computazione}

Automi, grammatiche e altri formalismi possono essere considerati modelli
meccanici per risolvere problemi matematici. Alcuni di questi sono più potenti
di altri, ad esempio le TM riconosco una famiglia di linguaggi che contiene
linguaggi non riconoscibili dai PDA\@. Abbiamo inoltre affermato che nessun
formalismo sarà più potente di una macchina di Turing. \hl{Questi modelli
possono, però, catturare l'essenza di un generico solutore meccanico?} Inoltre
se un \hl{problema è stato formalizzato adeguatamente, possiamo sempre
risolverlo mediante dispositivi meccanici?}

\subsection{Formalizzazione di problema}

Prima di parlare di risoluzione e risolvibilità, dobbiamo definire bene il
concetto di problema. Nei precedenti capitoli abbiamo \hl{già incontrato la
formalizzazione di un problema come riconoscimento} ($x \in L$) \hl{o
traduzione} ($y = \tau(x)$) \hl{di stringhe} su un alfabeto. Con questi due
formalismi \hl{è possibile descrivere tutti problemi con dominio numerabile}.
Infatti un \hl{problema con dominio numerabile può essere sempre ricondotto al
calcolo di una funzione $f: \mathbb{N} \to \mathbb{N}$}. Si può inoltre
dimostrare che riconoscimento e traduzione possono ridotte l'una all'altra:

\begin{thm}[Equivalenza tra traduzione e riconoscimento]\label{thm:equiv-trad-ric}
  Se una macchina può \hl{risolvere tutti i problemi del tipo $y = \tau(x)$}
  allora può \hl{risolvere anche i problemi del tipo $x \in L$ e viceversa}.
\end{thm}
\begin{proof}[Dimostrazione teorema~\ref{thm:equiv-trad-ric}]
  Dimostriamo i due versi dell'implicazione separatamente:

  \begin{description}
    \item[$\implies$] Se ho una macchina che può risolvere tutti i problemi
      della forma $y = \tau (x)$ e voglio usarla per risolvere il problema $x
      \in L$ è sufficiente definire $\tau(x) = 1$ se $x \in L$ e $0$ altrimenti.
    \item[$\impliedby$] Se ho una macchina che può risolvere tutti i problemi
      della forma $x \in L$, posso definire un linguaggio $L_{\tau} = \{
      x\termsep y : y = \tau(x) \}$. Per una $x$ fissata, posso enumerare
      tutte le possibili stringhe $y$ sull'alfabeto di uscita e per ognuna di
      esse posso chiedere alla macchina se $x\termsep y \in L_{\tau}$.
  \end{description}
\end{proof}

La \hl{classe dei problemi che possono essere risolti da una TM è indipendente
dall'alfabeto scelto, sempre che ci siano almeno due simboli}. Prima abbiamo
detto che le macchine di Turing sono il più potente formalismo di calcolo
automatico. Questa è la cosiddetta tesi di Church. Esso non è un teorema poiché
andrebbe verificato ogni volta che qualcuno inventa un nuovo modello
computazionale. Nonostante ciò è largamente accettato dagli studiosi come
teorema.

\begin{prop}[\hl{Tesi di Church}]\label{thm:tesi-church-1}
  \hl{Se un problema è umanamente calcolabile, allora esisterà una macchina di
  Turing in grado di risolverlo}.
\end{prop}

Tutti i \hl{modelli che abbiamo esaminato sono discreti}, in accordo con la
tecnologia digitale nel quale vengono impiegati. Inoltre \hl{data una TM, si può
costruire un programma in Java, C o FORTRAN che la simula e viceversa}. Questi
\hl{linguaggi di programmazione} hanno, quindi, la stessa espressività delle
macchine di Turing e \hl{vengono detti ``Turing-completi''}. Esistono anche dei
linguaggi che non sono Turing-completi come ad esempio il Datalog.

\subsection{Gli algoritmi}

Introduciamo un altro concetto fondamentale per l'informatica: l'algoritmo.

\begin{defn}[Algoritmo (intuitivo)]\label{def:alg-non-formale}
  Con algoritmo intendiamo una \hl{procedura per risolvere problemi} mediante un
  dispositivo di \hl{calcolo automatico}.
\end{defn}

Gli \hl{algoritmi} godono di alcune \hl{importanti proprietà}, anche queste
enunciate in modo informale.

\begin{prop}
  Sia \hl{$A$ un algoritmo} in esecuzione su una \hl{macchina $\mathcal{M}$
  dotata di un processore meccanico (digitale) e di una memoria utilizzabile dal
  processore in modo arbitrario}. Si ha che:

  \begin{enumerate}
    \item La \hl{sequenza di istruzioni} di $A$ dev'essere \hl{finita};
    \item \hl{Qualunque istruzione} di $A$ dev'essere \hl{eseguibile dal
      processore} meccanico di $\mathcal{M}$;
    \item La \hl{computazione è discreta}, ossia l'informazione è codificata
      digitalmente e la computazione procede attraverso passi discreti;
    \item $A$ è \hl{eseguito in modo deterministico};
    \item \hl{Non c'è limite} sulla quantità di \hl{dati in ingresso e in
      uscita};
    \item \hl{Non c'è limite} sulla quantità di \hl{memoria richiesta} per
      effettuare una computazione;
    \item \hl{Non c'è limite} sul \hl{numero di passi discreti richiesti} per
      effettuare una computazione.
  \end{enumerate}
\end{prop}

Possiamo \hl{descrivere ogni problema calcolabile tramite un sistema di calcolo
automatico con un algoritmo} e quindi, per la tesi di Church, \hl{ogni algoritmo
potrà essere eseguito da una macchina di Turing}. Possiamo allora
\hl{riformulare} la tesi di Church come:

\begin{prop}[Tesi di Church]\label{thm:tesi-church-2}
  \hl{Ogni algoritmo si può codificare con un macchina di Turing}.
\end{prop}

Quali sono però i problemi che possiamo risolvere tramite un algoritmo? Una
risposta un po' banale è: quelli risolvibili dalle macchine di Turing.

\subsection{Enumerazione algoritmica}\label{sec:enum-alg}

\begin{defn}[\hl{Insieme enumerabile algoritmicamente}]\label{def:enum-alg}
  Un \hl{insieme} $S$ può essere \hl{enumerato algoritmicamente} se possiamo
  trovare una \hl{biezione $E$ tra $S$ $\mathbb{N}$ calcolabile con un
  algoritmo}.
\end{defn}

Dimostriamo che l'insieme delle macchine di Turing è un insieme enumerabile
algoritmicamente:

\begin{prop}[\hl{Enumerazione delle TM}]\label{thm:enum-alg-TM}
  L'\hl{insieme} di \hl{tutte le macchine di Turing} a \hl{nastro singolo} con
  alfabeto \hl{$A = \{ 0,1,\not{b}\}$} è un \hl{insieme enumerabile
  algoritmicamente}.
\end{prop}
\begin{proof}
  Consideriamo le TM con solo due stati. Iniziamo con il calcolare la
  cardinalità dell'insieme di tutte le possibili funzioni di transizione
  realizzabili. Sappiamo che $\delta$ ha forma:

  \[
    \delta : Q \times A \to Q \times A \times \{R,L,S\} \cup \{\bot\}
  \]

  Sfruttando un risultato della teoria insiemistica che ci dice che il numero di
  funzioni $f: D \to R$ è $|R|^{|D|}$, otteniamo che il numero di funzioni sarà:

  \[
    {[|Q|*|A|*(3+1)]}^{2*3} = 19^6
  \]

  Considerando che abbiamo 4 possibili scelte di stati finali, otteniamo un
  numero di $4*19^6$ macchine di Turing a 2 stati. Iterando il procedimento,
  otterremo sempre un numero finito e al più numerabile di TM\@. Ora ci basta
  ordinare secondo un ordine arbitrario e quindi scrivere un algoritmo che le
  enumeri.
\end{proof}

Il numero \hl{$E(M)$} è detto \hl{numero di Gödel} della TM $\mathcal{M}$ ed
indica il suo \hl{indice nella enumerazione algoritmica} di tutte le TM
creabili. La \hl{$E$} è detta la \hl{gödelizzazione} dell'insieme delle TM\@.

\subsection{Macchina di Turing universale}\label{sec:utm}

Chiediamoci ora se le \hl{macchine di Turing} riescano a \hl{modellare i
calcolatori programmabili}. Una TM con queste caratteristiche è \hl{detta
macchina di Turing universale (UTM)}. La \hl{UTM computa} la funzione
\hl{$g(y,x) = f_y(x)$} dove $f_y$ è la funzione calcolata dalla TM di indice
$y$.

Per come è definita, sembrerebbe che la UTM sia un diverso tipo di automa
rispetto alla TM\@: la prima lavora $\mathbb{N}^2$ mentre la seconda si
$\mathbb{N}$. Sappiamo però che la \hl{cardinalità di $\mathbb{N}^2$ è uguale a
quella di $\mathbb{N}$} in quanto esiste la biezione:

\begin{equation}
  d(x,y) = \frac{(x+y)(x+y+1)}{2} + x
\end{equation}

Possiamo quindi esprimere $g(y,x)$ come $\hat{g}(n) = g(d^{-1}(n))$ con $n =
d(y,x)$.

Una \hl{UTM} che calcola $\hat{g}$ \hl{opererà in questo modo}:

\begin{enumerate}
  \item Dato $n$ calcola \hl{$\langle y,x \rangle = d^{-1}(n)$};
  \item Costruisce la \hl{funzione di transizione $M_y$} calcolando
    \hl{$E^{-1}$} e la memorizza sul nastro;
  \item In un'altra porzione di nastro \hl{memorizza una codifica della
    configurazione di $M_y$};
  \item Lascia sul nastro \hl{$f_y(x)$ se e solo se $M_y(x)$ termina la
    computazione}.
\end{enumerate}

\subsection{Funzioni calcolabili e problemi definibili}\label{sec:func-calc}

\hl{È possibile calcolare tutte le funzioni da $\mathbb{N}$ a $\mathbb{N}$?} In
caso \hl{negativo}, per la tesi di Church, \hl{esisterebbero problemi non
risolvibili tramite algoritmi}. Calcoliamo la cardinalità dell'insieme di
funzioni naturali a variabile naturale. Consideriamo il sottoinsieme di $f:
\mathbb{N} \to \{0,1\}$. È possibile calcolare la cardinalità di questo insieme
ed essa è pari a quella di $\wp(\mathbb{N})$ ossia $2^{\aleph_0}$ ossia la
cardinalità del continuo. Visto che abbiamo considerato un sottoinsieme, la
\hl{cardinalità che cerchiamo è sicuramente maggiore di quella del continuo}.
Poiché l'\hl{insieme di funzioni calcolabili dalle macchine di Turing è per
definizione numerabile} (di cardinalità $\aleph_0$) \hl{non abbiamo abbastanza
TM} per risolvere tutti i problemi possibili.

Precedentemente abbiamo detto che i problemi di dominio naturale sono sempre
traducibili come la computazioni di una funzione di dominio naturale. Abbiamo
però visto che non tutte le funzioni di questo tipo sono computabili. \hl{Per
definire un problema}, infatti, \hl{ci serve una frase}, una stringa, \hl{di
qualche linguaggio} che li caratterizzi. Per definizione, \hl{ogni linguaggio è
un insieme numerabile} e ciò renderà anche l'\hl{insieme dei problemi definibili
numerabile}. Quindi esistono problemi che non sono nemmeno definibili.

Concentriamoci sui problemi che sono \hl{definibili}. \hl{Essi sono sempre
risolvibili?} La risposta è \hl{negativa}. Un famoso problema definibile ma non
risolvibile è il \hl{``Halting Problem''}.

\begin{prop}[\hl{Halting problem}]
  \hl{Costruito un programma che, dati dei dati in ingresso, esegue una
  computazione che potrebbe terminare, è possibile determinare in anticipo se
  terminerà?}
\end{prop}
\begin{proof}
  Formalmente ci stiamo cheidendo se esiste una TM tale che data $f_y$, calcola
  $g(y,x)$ totale tale che:

  \[
    g(y,x) =
    \begin{cases}
      1 & \quad \text{se } f_y(x) \neq \bot \\
      0 & \quad \text{se } f_y(x) = \bot
    \end{cases}
  \]

  Esistono diversi metodi di dimostrazione. Noi useremo quello per
  diagonalizzazione a quello usato da Cantor per dimostrare la cardinalità del
  continuo.

  Enumeriamo tutte le funzione calcolabili da una macchina di Turing e i loro
  valori:

  \[
    \begin{array}{c|ccc}
          & 1      & 2      & \ldots \\
      f_1 & f_1(1) & f_1(1) & \ldots \\
      f_2 & f_2(1) & f_2(1) & \ldots \\
      f_3 & f_3(1) & f_3(1) & \ldots \\
      \vdots & \vdots & \vdots & \ddots
    \end{array}
  \]

  Ipotizziamo allora per assurdo che la nostra funzione $g$ sia calcolabile.
  Definiamo

  \[
    h(x) =
    \begin{cases}
      1    & \quad \text{se } g(x,x) = 0\\
      \bot & \quad \text{altrimenti} \\
    \end{cases}
  \]

  La funzione $h$ è ovviamente calcolabile se anche $g$ lo sarà. Abbiamo quindi
  definito una funzione che si pone sulla diagonale della nostra tavola delle
  funzioni.

  Se $h$ è calcolabile, e lo è visto che per ipotesi anche $g$ è calcolabile,
  esisterà una TM di indice $i$ tale che $h = f_i$. Provando a calcolare $h(i)$
  otteniamo:

  \begin{enumerate}
    \item Se $h(i) = f_i(i) = 1$ allora $g(i,i)=0$, ossia $f_i(i)=\bot$ che è
      una contraddizione
    \item Se $h(i) = f_i(i) = 0$ allora $g(i,i)=1$, ossia $f_i(i)\neq\bot$ che è
      una contraddizione
  \end{enumerate}

  Siamo arrivati così ad un assurdo e quindi $g$ non è calcolabile.
\end{proof}

L'Halting Problem ci permette di affermare con fermezza che l'insieme dei
\hl{problemi risolvibili è strettamente incluso in quello dei problemi
descrivibili}.

\subsubsection{Specializzazioni e generalizzazioni}\label{sec:spec-gen}

Consideriamo la funzione:

\begin{equation}
  h'(x) =
  \begin{cases}
    1 & \quad \text{se } f_y(x) = \bot \\
    0 & \quad \text{altrimenti}
  \end{cases}
\end{equation}

Essa è un \hl{caso particolare del Halting Problem} dove abbiamo imposto che in
$g(y,x)$ sarà $y=x$. Si dimostra che \hl{$h'$ non è computabile}. Nota bene che
$h'$ \hl{non è un corollario e non deriva dal Halting problem}. Infatti un
\hl{caso specifico} di un problema \hl{non risolvibile non è detto che sia
anch'esso non risolvibile} e, viceversa, la \hl{generalizzazione di un problema
risolvibile non per forza mantiene la risolvibilità}. Se un problema è già
\hl{risolvibile}, però, la \hl{sua specializzazione sarà anch'essa risolvibile}
e viceversa la \hl{generalizzazione di un problema non risolvibile sarà ancora
non risolvibile}.

\subsubsection{Il problema delle funzioni totali}\label{sec:func-tot}

Consideriamo un'altra funzione:

\begin{equation}\label{eqn:func-k}
  k(y) =
  \begin{cases}
    1 & \quad \text{se } \forall x \in \mathbb{N}, f_y(x) \neq \bot\\
    0 & \quad \text{altrimenti}\\
  \end{cases}
\end{equation}

La \hl{funzione, in pratica, vale $1$ se la funzione $f_y(x)$ è totale e 0
altrimenti}. Da un punto di vista pratico, questa funzione è ancora più
importante di quella derivata dal problema dell'arresto. In questo caso,
infatti, ci chiediamo se il programma non termini per qualsiasi ingresso, invece
di chiedercelo solo per uno. Dimostriamo che la \hl{funzione $k$ non è
computabile}.

\begin{prop}
  \hl{La funzione}~\ref{eqn:func-k} \hl{non è computabile}.
\end{prop}
\begin{proof}
  Ipotizziamo per assurdo che la funzione sia computabile. Definiamo $g(x) = w$
  con $w$ pari al numero di Gödel della $x$-esima TM che calcola una funzione
  totale. Se $k$ è computabile, allora lo sarà ang $g$. Infatti possiamo trovare
  una procedura algoritmica che calcola $g(x)$:

  \begin{enumerate}
    \item Calcoliamo $k(x)$ al crescere di $x$. Trovato $x_0|_{k(x_0)=1}$
      poniamo $g(0) = x_0$ e riprendiamo a calcolare $k$ da $x_0 + 1$ in avanti;
    \item Trovato $x_1|_{k(x_1)=1}$ poniamo $g(1) = x_1$ e iteriamo.
  \end{enumerate}

  È facile vedere che $g$ è strettamente monotona. Possiamo calcolare $g^{-1}$
  anch'essa strettamente monotona ma non totale. Definiamo

  \[
    f_{g(x)}(x) +1 = f_w(x) +1
  \]

  Sappiamo che $f_w(x)$ è calcolabile e totale per definizione di $g$ e quindi
  anche $h$ lo sarà. Esisterà allora un $\bar{w}|_{f_{\bar{w}}(\cdot)=h(\cdot)}$
  Dato che $h$ è totale, sicuramente anche $g^{-1} \neq \bot$. Poniamo allora
  $g^{-1}(\bar{w})=\bar{x}$. Studiamo la forma di $h$: per definizione avremo

  \[
    h(\bar{x})=f_{g(\bar{x})}(\bar{x}) + 1 = f_{\bar{w}}(\bar{x}) +1
  \]

  Ma, siccome $h(\cdot) = f_{\bar{w}}(\cdot)$, abbiamo anche $h(\bar{x}) =
  f_{\bar{w}}(\bar{x})$. Cadiamo allora in un assurdo e quindi la funzione $k$
  non è calcolabile.
\end{proof}

Nota bene che la \hl{definizione di $k$ ha una quantificazione universale}.
Potrebbe essere, quindi, che \hl{per qualche valore specifico di $x$ possiamo
stabilire il valore di $k(y)$. Non siamo però in grado di dire se possiamo farlo
per ogni singolo ingresso possibile}.

\subsection{Decidibilità e semidecidibilità}\label{sec:problemi-decisione}

Concentriamoci sui problemi \hl{con risposta binaria, detti anche di decisione}.
Questo tipo di problemi hanno \hl{due risposte possibili ``vero'' e ``falso''}.
Un problema di questo tipo \hl{può essere decidibile, semidecidibile o
indecidibile}. La prima e la ultima hanno significato ovvio, approfondiamo la
seconda.

\begin{defn}[\hl{Problema semidecidibile}]\label{def:problema-semidecidibile}
  Un problema si dice \hl{semidecidibile} se esiste un \hl{algoritmo che ritorni
  ``vero'' se il problema ha risposta affermativa}.
\end{defn}

\begin{nota}
  La definizione di semidecidibilità \hl{non ci impone limiti su quello che fa
  l'algoritmo in caso di esito negativo}. Esso può ritornare il valore ``falso''
  oppure anche non terminare.
\end{nota}

\paragraph{Semidecidibilità e testing} Un \hl{gran numero di problemi
indecidibili} si può dimostrare che \hl{sono semidecidibili}. Uno di questi è il
\hl{problema dell'arresto}: l'algoritmo basta che guardi se la TM si ferma su
uno stato di accettazione. \hl{L'utilità della proprietà di semidecidibilità è
che ci permette di rilevare se c'è un errore invece di garantirne la sua
assenza}. Ciò ha importanti applicazioni pratiche nella verifica di programmi
basata sul \hl{testing}:

\begin{lem}[Asserzione di Dijkstra]
  Il testing può dimostrare la presenza di errori, non la loro assenza.
\end{lem}

Tutti i \hl{problemi di decisione} possono essere \hl{riformulati come ``dato un
insieme $S$, $x \in S$''}. Alternativamente possiamo calcolare la \hl{funzione
caratteristica} dell'insieme $S$:

\begin{equation}
  \mhl{
    \mathbf{1}_{S} =
    \begin{cases}
      1 & \quad \text{se } x \in S \\
      0 & \quad \text{altrimenti}
    \end{cases}
  }
\end{equation}

L'insieme \hl{$S$} può essere \hl{ricorsivo (decidibile) oppure ricorsivamente
numerabile (semidecidibile)}.

\begin{defn}[\hl{Insieme ricorsivo (decidibile)}]\label{def:insieme-decidibile}
  Un insieme $S$ si dice \hl{ricorsivo} o decidibile se e solo se la sua
  \hl{funzione caratteristica è computabile}.
\end{defn}

\begin{defn}[\hl{Insieme ricorsivamente enumerabile (semidecidibile)}]\label{def:insieme-semidecidibile}
  Un insieme $S$ si dice \hl{ricorsivamente enumerabile} (RE) o semidecidibile
  se e solo se:

  \begin{itemize}
    \item $S$ è l'insieme \hl{vuoto};
    \item $S$ è l'\hl{immagine di una funzione totale computabile}:

      \begin{equation}
        S = I_{g_S} = \{ x: g_S(y), y \in \mathbb{N} \}
      \end{equation}
  \end{itemize}
\end{defn}

Il termine di insieme semidecidibile deriva dal fatto che se $x \in S$
enumerando gli elementi di $S$ prima o poi lo troverò, altrimenti sono mai certo
di poter rispondere ``falso'' enumerando in quanto potrei non aver ancora
trovato $x$.

Tra la decidibilità e la semidecidibilità ci sono diversi importanti legami:

\begin{thm}[\hl{Decidibilità implica semidecidibilità}]\label{thm:dec-semidec}
  Se un insieme $S$ è \hl{ricorsivo (decidibile), esso è ricorsivamente
  enumerabile (semidecidibile)}.
\end{thm}
\begin{proof}
  Studiamo i vari casi possibili nella definizione di semidecidibilità:

  \begin{itemize}
    \item Se $S$ è vuoto, è RE per definizione;
    \item Se $S$ non è vuoto, costruiamo una funzione totale e computabile di
      cui $S$ è immagine. Poiché sappiamo che esisterà un $k \in S$ tale che
      $\mathbf{1}_S(k) = 1$, possiamo definire la funzione come

      \[
        g_S(x) =
        \begin{cases}
          x & \quad \text{se } \mathbf{1}_S(x) = 1 \\
          k & \quad \text{se } \mathbf{1}_S(x) = 0
        \end{cases}
      \]

      Con $g_S$ totale, computabile e $\mathbf{I}_{g_S} = S$. $S$ sarà, quindi,
      RE\@.
  \end{itemize}
\end{proof}

\begin{thm}[\hl{semidecidibilità + semidecidibilità = decidibilità}]\label{thm:0.5+0.5=1}
  Si un insieme $S$, esso sarà \hl{ricorsivo se e solo se sono ricorsivamente
  enumerabili sia $S$ che $\bar{S} = \mathbb{N} \setminus S$}.
\end{thm}
\begin{proof}
  Dimostriamo che se $S$ è ricorsivo allora $S$ e $\bar{S}$ sono RE\@.
  Innanzitutto $S$ è ricorsivo, per il teorema~\ref{thm:dec-semidec} esso è
  anche RE\@. Inoltre possiamo osservare che anche $\mathbf{1}_{\bar{S}}$ è
  calcolabile in quanto è pari a $\mathbf{1}_S$ con 1 e 0 scambiati,
  permettendoci di affermare che anche $\bar{S}$ è RE\@.

  Dimostriamo ora l'implicazione inversa. Osserviamo che $S \cup \bar{S} =
  \mathbb{N}$ e $S \cap \bar{S} = \emptyset$ e quindi una qualunque $x \in
  \mathbb{N}$ appartiene a una e una sola delle due enumerazioni di $S$ e
  $\bar{S}$:

  \[
    (\forall x \in \mathbb{N}, \exists y : x = g_{\bar{S}}(y) \lor x = g_S(y))
      \land (\neg \exists z : g_{\bar{S}}(z) = g_S(z))
  \]

  Posso essere, quindi, certo di trovare qualsiasi $x$ nell'enumerazione

  \[
    \{ g_S(0), g_{\bar{S}}(0), g_S(1), g_{\bar{S}}(1), \ldots \}
  \]

  Nel momento in cui trovo $x$ in posizione dispari concludo che $x \notin S$,
  altrimenti $x \in S$. So quindi calcolare $\mathbf{1}_S$, rendendo $S$
  ricorsivo.
\end{proof}

Da questi due teoremi possiamo trarre un po' di risvolti importanti.
Innanzitutto possiamo affermare che gli \hl{insiemi decidibili sono chiusi
rispetto al complemento}. Possiamo usare la teoria degli insiemi ricorsivi per
cercare di capire se possiamo enumerare tutte le funzioni calcolabili e totali.

\begin{prop}[\hl{Definione delle funzioni calcolabili e totali}]\label{thm:def-func-tot}
  Dato un insieme \hl{$S$} per cui:

  \begin{enumerate}
    \item \hl{Se $i \in S$ allora $f_i$ e calcolabile e totale};
    \item \hl{Se $f$ e totale e computabile allora $\exists i \in S : f_i =
      f_i$}.
  \end{enumerate}

  Esso \hl{non sarà ricorsivamente enumerabile}.
\end{prop}
\begin{proof}
  Ipotizziamo per assurdo che esista una funzione caratteristica
  $\mathbf{1}_S(i)$ computabile. Definiamo:

  \[
    h(x) =
    \begin{cases}
      f_x(x) + 1 & \quad \text{se } \mathbf{1}_S(x) = 1 \\
      0          & \quad \text{altrimenti}
    \end{cases}
  \]

  Abbiamo che per ogni $x$ $h(x) \neq f_{\mathbf{1}_S(x)}(x)$. Quindi $h(x)$ è
  calcolabile ma diversa da tutte le funzioni calcolabili, il che è un assurdo.
\end{proof}

\hl{Non è possibile quindi definire con un formalismo RE} (automi, grammatiche e
funzioni ricorsive) \hl{capace di definire l'insieme dei tutte e sole le
funzioni calcolabili totali}. Quindi non posso descrivere in nessun modo
descrivere come è fatto l'insieme di tutti e soli i programmi che terminano
sempre:

\begin{itemize}
  \item Gli FSA e i PDA definiscono solo funzioni totali ma non tutte
  \item Le TM definiscono tutte le funzioni calcolabili, ma anche quelle non
    totali
  \item Il C mi permette di scrivere qualunque algoritmo, ma anche che non
    terminato
\end{itemize}

Riusciamo, però, ad \hl{aggirare il problema e considerare l'insieme di tutte le
funzioni e rimuovere con un artificio le funzioni parziali?} Arricchiamo
$\mathbb{N}$ con un nuovo valore $\bot$ oppure assegnamo un calore convenzionale
ad $f$ quando non è definita. \hl{Matematicamente questa operazione non causa
problemi, però si può dimostrare che per la funzione}:

\begin{equation}
  \mhl{
    g(x) =
    \begin{cases}
      f_x(x) + 1 & \quad \text{se } f_x(x) \neq \bot \\
      \bot       & \quad \text{altrimenti}
    \end{cases}
  }
\end{equation}

\hl{Non è possibile costruire una funzione computabile e totale che la estenda}.
Inoltre possiamo dimostrare che \hl{esistono insiemi che sono semidecidibili
senza essere decidibili}.

\begin{proof}[Dimostrazione. Esistenza di insiemi semidecidibili non decidibili]
  Consideriamo

  \[
    S = \{ x : f_x(x) \neq \bot \}
  \]

  Essa è il dominio della funzione $h(x) = f_x(x)$ che è computabile ma
  parziale. Poiché è possibile riscrivere questa affermazione in termini di
  immagine di una $g$ totale computabile, $S$ è RE\@. Sappiamo anche che la
  funzione caratteristica $\mathbf{1}_S = 1$ se $f_x(x) \neq \bot$, e 0
  altrimenti non è computabile e quindi $S$ non è decidibile.
\end{proof}

Possiamo costruire quindi un \hl{gerarchia di inclusioni strette} tra vari tipi di
insiemi:

\begin{equation}
  \mhl{
    \text{Ricorsivi} \subset \text{RE} \subset \wp(\mathbb{N})
  }
\end{equation}

\subsection{Stabilire decidibilità e semidecidibilità di un problema}\label{sec:stabilire-dec-sec-}

Enunciamo il \hl{primo risultato importante che ci servirà per capire se e come
possiamo stabilire la decidibilità (semidecidibilità)} di un problema.

\begin{thm}[\hl{Teorema di Kleene del punto fisso}]\label{thm:kleene-punto-fisso}
  Sia una \hl{funzione $t(\cdot)$ totale e computabile}. È \hl{sempre possibile
  trovare un $p \in \mathbb{N}$} tale che \hl{$f_p = f_{t(p)}$}. La funzione
  \hl{$f_p$ è detta punto fisso di $t(\cdot)$}.
\end{thm}
\begin{proof}
  Dato $u \in \mathbb{N}$ definiamo una TM che effettua il seguente calcolo
  sull'ingresso $x$: calcola $f_u(u) = z$ e quando il calcolo termina calcola
  $f_z(x)$. Possiamo costruire questa TM e cercare il suo numero di Gödel $g(u)$
  per una qualsiasi $u$. Otteniamo che la funzione della TM sarà esprimibile
  come:

  \[
    f_{g(u)}(x) =
    \begin{cases}
      f_{f_u(u)}(x) & \quad \text{se } f_u(u) \neq \bot \\
      \bot          & \quad \text{altrimenti}
    \end{cases}
  \]

  Sappiamo che data $g(\cdot)$ totale e calcolabile e $t(\cdot)$ anch'essa
  totale e computabile, lo sarà anche $t(g(\cdot))$. Chiamiamo $v$ il numero di
  Gödel di $t(g(\cdot))$, ottenendo $t(g(\cdot)) = f_v(\cdot)$. Ripetendo la
  costruzione che abbiamo fatto precedentemente otteniamo che:

  \[
    f_{g(v)} =
    \begin{cases}
      f_{f_v(v)}(x) & \quad \text{se } f_v(v) \neq \bot \\
      \bot          & \quad \text{altrimenti}
    \end{cases}
  \]

  Ricordando che $t(g(\cdot))$ è totale e computabile, otteniamo che
  $f_{g(v)}(x) = f_{f_v(v)}(x)$ per ogni $x$. Sostituendo nel secondo membro
  otteniamo:

  \[
    f_{g(v)} = f_{t(g(v))}
  \]

  Rendendo, quindi $f_{g(v)}$ il punto fisso di $t(\cdot)$.
\end{proof}

Possiamo ora enunciare una \hl{condizione per la decidibilità di un insieme}.

\begin{thm}[\hl{Teorema di Rice}]\label{thm:rice}
  Siano \hl{$F$ un'insieme di funzioni computabili} e l'insieme \hl{$S$ degli
  indici delle TM che calcolano le funzioni di $F$}. L'insieme \hl{$S = \{x:f_x
  \in F\}$} è \hl{decidibile se e solo se}:

  \begin{itemize}
    \item \hl{$F = \emptyset$};
    \item \hl{$F$ è l'insieme di tutte le funzioni computabili}.
  \end{itemize}
\end{thm}
\begin{proof}
  Supponiamo per assurdo che $S$ sia decidibile con $F$ non vuoto e diverso
  dall'insieme di tutte le funzioni computabili. Consideriamo la funzione
  caratteristica di $S$ $\mathbf{1}_S(x)$, essa sarà calcolabile per ipotesi.
  Possiamo quindi calcolare:

  \begin{enumerate}
    \item Il più piccolo $i \in \mathbb{N}$ tale che $f_i \in F$
    \item Il più piccolo $j \in \mathbb{N}$ tale che $f_j \notin F$
  \end{enumerate}

  Per quanto detto, la funzione:

  \[
    h_S(x) =
    \begin{cases}
      i & \quad \text{se } f_x \notin F \\
      j & \quad \text{altrimenti}
    \end{cases}
  \]

  Sarà anch'essa calcolabile e totale. Applicando il teorema di Kleene alla
  funzione appena definita otteniamo che esiste un punto fisso $f_{\bar{x}}$ tale
  per cui $f_{\bar{x}} = f_{h_s(\bar{x})}$. Siamo così arrivati ad una
  contraddizione in quanto:

  \begin{itemize}
    \item Se $h_S(\bar{x}) = i$: per definizione di $h_S$ abbiamo che
      $f_{\bar{x}} \notin F$, ma da quanto detto per il teorema di Kleene
      $f_{\bar{x}} = f_{h_S(\bar{x})} = f_i$ da cui, per come definito $i$, $f_i
      \in F$.
    \item Se $h_S(\bar{x}) = j$: per definizione di $h_S$ abbiamo che
      $f_{\bar{x}} \in F$, ma da quanto detto per il teorema di Kleene
      $f_{\bar{x}} = f_{h_S(\bar{x})} = f_j$ da cui, per come definito $j$, $f_j
      \notin F$.
  \end{itemize}
\end{proof}

Quindi \hl{in tutti i casi non banali l'insieme delle funzioni calcolabili con
una data caratteristica desiderata non è decidibile!} Quindi non sarà possibile
rispondere a molti quesiti importanti:

\begin{itemize}
  \item Il programma $P$ è corretto? Risolve un dato problema?
  \item È possibile stabilire l'equivalenza tra due programmi?
  \item È possibile stabilire se un generico programma gode di una qualsiasi
    proprietà non banale riferita alla funzione che calcola?
\end{itemize}

\hl{Stabilire se un generico problema è decidibile (semidecidibile) o meno è
indecidibile}. Ragionando in \hl{modo pratico} abbiamo \hl{tre possibili
alternative} per \hl{stabilire la decidibilità di} un problema:

\begin{enumerate}
  \item Se \hl{troviamo un algoritmo che termina sempre}, allora il problema è
    \hl{decidibile};
  \item Se \hl{troviamo un algoritmo che termina sempre se la risposta è
    ``vero'' ma può non terminare se la risposta è ``falso''}, allora il
    problema è \hl{semidecidibile};
  \item Se riusciamo a \hl{trovare una dimostrazione diagonale della
    indecidibilità} del problema allora esso è \hl{indecidibile}.
\end{enumerate}

La \hl{terza opzione} è \hl{molto laboriosa ma fattibile}. Il \hl{teorema di
Rice} ci permette facilmente di \hl{stabilire se un problema non è decidibile},
ma esso \hl{può} lo stesso \hl{essere semidecidibile}. Una \hl{tecnica
alternativa}, molto generale, è quella della \hl{riduzione dei problemi}: ci
permette di \hl{dimostrare in modo agevole l'indecidibilità di alcuni problemi}.

\subsubsection{La tecnica di riduzione di un problema}\label{sec:riduzione}

Consideriamo prima una visione operativa della tecnica di riduzione. Se abbiamo
un algoritmo per risolvere un problema $P$, possiamo riusarlo modificandolo per
risolvere problemi $P'$ simili a $P$. In generale se trovo un algoritmo che,
dato un esemplare di $P'$ ne costruisce la soluzione usando un esemplare di $P$
che so risolvere, ho ridotto $P'$ a $P$. Ciò significa che affinché $P'$ sia
riducibile a $P$, si dovrà avere che:

\begin{enumerate}
  \item $P$ risolvibile;
  \item C'è un algoritmo che per ogni istanza di $P'$ determina una
    corrispondente istanza di $P$ e costruisce algoritmicamente la soluzione
    dell'istanza di $P'$ usando la soluzione dell'istanza di $P$.
\end{enumerate}

Formalizziamo il tutto:

\begin{prop}[\hl{Tecnica di riduzione}]\label{thm:riduzione}
  \hl{Consideriamo due problemi: $y \in S'$ e $x \in S$} di cui il \hl{secondo è
  quello che vogliamo risolvere}. \hl{Se troviamo un a funzione $t$ calcolabile
  e totale} per cui:

  \begin{equation}
    \mhl{
      x \in S \iff t(x) \in S'
    }
  \end{equation}

  Il \hl{problema d'interesse è risolvibile}. Inoltre, dato $x$, \hl{calcolare
  $\mathbf{1}_{S'}(t(x))$ equivale a calcolare $\mathbf{1}_S(x)$}.

  La proposizione \hl{funziona anche in direzione inversa}: se so che \hl{$y \in
  S'$ non è risolvibile, se trovo la $t$ che rispetta la precedente condizione
  allora anche $x \in S$ non sarà risolvibile}.
\end{prop}

\begin{esempio}
  Dall'indecidibilità del problema dell'arresto della TM deduciamo
  l'indecidibilità del problema della terminazione del calcolo in generale. I
  passaggi operativi per dimostrare ciò che possiamo eseguire sono:

  \begin{enumerate}
    \item Costruiamo un programma $P$ che simuli una TM $M_i$ e memorizziamo il
      numero $x$ in un file $f$.
    \item Il programma $P$ termina la computazione su $f$ se e solo se $g(i,x)
      \neq \bot$.
    \item Se riuscissimo a scrivere un programma che riesce a predire il
      contenuto di $f$ avremmo risolto il problema dell'arresto, ma ciò non è
      possibile.
  \end{enumerate}
\end{esempio}

\begin{esempio}
  È decidibile dire se, durante l'esecuzione di un generico programma $P$ si
  accede ad una variabile non inizializzata?

  Supponiamo per assurdo che questo problema sia decidibile. Riduciamolo al
  problema dell'arresto:

  \begin{enumerate}
    \item Dato un generico programma $Q(n)$, costruisco un programma $P$ fatto
      in questo modo:

      \begin{align*}
        & \{ \\
        & \quad \mathtt{int \; x,y;} \\
        & \quad \mathtt{Q(n);} \\
        & \quad \mathtt{y=x;} \\
        & \}
      \end{align*}

      Avendo cura di usare variabili non presenti in $\mathtt{Q}$.
    \item L'accesso $\mathtt{y=x}$ alla variabile non inizializzata $x$ da parte
      di $P$ è fatto se e solo se $\mathtt{Q}$ termina.
  \end{enumerate}

  Se fossi in grado di decidere il problema dell'accesso a variabile non
  inizializzata, potrei decidere il problema della terminazione del calcolo, che
  è un assurdo.
\end{esempio}

\hl{Le proprietà dimostrate nei precedenti esempi non sono decidibili, ma sono
semidecidibili. Abbiamo un metodo operativo per determinare la semidecidibilità
di un problema?}

Innanzitutto il problema \hl{$\exists z : f_x(z) \neq \bot$ è semidecidibile}.
Una \hl{idea di dimostrazione è simulare l'azione della funzione ``in
diagonale''} eseguendo \hl{una sola mossa alla volta per ogni input} finché non
troviamo l'input per la quale la computazione non si arresta. \hl{Simulando
abbastanza passi di $f_x$, eventualmente lo troverò}.

\section{Complessità del calcolo}\label{sec:complessita}

Calcolare la \hl{complessità} di una computazione significa \hl{calcolare
l'efficienza e il costo in tempo di una computazione}. Come possiamo misurare
questi parametri?  Dobbiamo prima definire degli strumenti per valutare la
complessità e successivamente potremmo enunciare degli algoritmi e strutture
dati notevoli. Il nostro obiettivo sarà sviluppare gli strumenti per saper
progettare e combinare algoritmi e strutture dati che realizzano soluzioni
efficienti.

Per \hl{quantificare l'efficienza} di un algoritmo, faremo \hl{analisi
qualitative di due metriche}:

\begin{itemize}
  \item \hl{Tempo di calcolo impiegato};
  \item \hl{Spazio occupato} (registri, cache, RAM, disco o nastro).
\end{itemize}

Si possono fare analisi anche su altri aspetti come i costi di sviluppo, ma noi
non li considereremo. Per la \hl{tesi Church}, un \hl{problema è calcolabile
indipendentemente dallo strumento usato}, purché tale strumento sia \hl{Turing
completo}. Possiamo dire lo \hl{stesso per la complessità}? Purtroppo \hl{no}.
Dobbiamo, quindi, costruire uno \hl{strumento che tralasci considerazioni
superflue e sia utilizzabile per la maggioranza dei modelli di calcolo}. Noi
considereremo per convenzione quello della \hl{macchina di Turing
deterministica}.

Formalizziamo le nostre due metriche:

\begin{defn}[\hl{Complessità temporale}]\label{def:comp-temporale}
  Data la \hl{computazione $c_1 \vdash^\star c_r$} di una \hl{macchina di Turing
  $\mathcal{M}$} (a $k$ nastri) \hl{deterministica} la \hl{complessità temporale
  è $T_\mathcal{M}(x) = r$ se} $\mathcal{M}$ \hl{termina} in $c_r$, \hl{$\infty$
  altrimenti}.
\end{defn}

\begin{defn}[Complessità spaziale]\label{def:comp-spaziale}
  Data la \hl{computazione $c_1 \vdash^\star c_r$ di $\mathcal{M}$} (a $k$ nastri)
  \hl{deterministica}, la \hl{complessità spaziale} è:

  \begin{equation}
    \mhl{
      S_\mathcal{M}(x) = \sum_{j=1}^{k} \max_{i \in \{0, \ldots, r\}}(|\alpha_{ij}|)
    }
  \end{equation}

  Con $\alpha_{ij}$ il contenuto del $j$-esimo nastro alla $i$-esima mossa.
\end{defn}

\begin{nota}
  \hl{Complessità spaziale e temporale} sono \hl{legate} dalla seguente
  relazione:

  \begin{equation}
    \mhl{
      \forall x \quad \frac{S_\mathcal{M}(x)}{k} \leq T_\mathcal{M}(x)
    }
  \end{equation}
\end{nota}

Ad eseguire l'analisi su una TM, dobbiamo gestire \hl{un po' troppi dettagli}.
Effettuiamo, allora, delle \hl{semplificazioni}: esprimeremo la \hl{complessità
in base alla ``dimensione'' $n$ dei dati in ingresso}. A causa di questa
semplificazione dobbiamo \hl{considerare 3 casi per gestire la variazione di
ingressi diversi ma di stessa lunghezza}:

\begin{description}
  \item[\hl{Caso pessimo}]
    \begin{equation}
      \mhl{
        T_\mathcal{M}(n) = \max_{|x|=n} T_\mathcal{M}(x)\label{def:caso-pessimo}
      }
    \end{equation}

  \item[\hl{Caso ottimo}]
    \begin{equation}
      \mhl{
        T_\mathcal{M}(n) = \min_{|x|=n} T_\mathcal{M}(x)\label{def:caso-ottimo}
      }
    \end{equation}

  \item[\hl{Caso medio}]
    \begin{equation}
      \mhl{
        T_\mathcal{M}(n) = \frac{\sum_{|x|=n} T_\mathcal{M}(x)}{|I|^n}\label{def:caso-medio}
      }
    \end{equation}
\end{description}

Noi \hl{considereremo sempre il caso pessimo in quanto è il più rilevante}.
Inoltre \hl{l'analisi del caso medio risulta assai complessa} in quanto dovrebbe
tenere conto di ipotesi probabilistiche sulla distribuzione dei dati.

I \hl{valori esatti} delle due complessità per un dato $n$ \hl{non sono
particolarmente utili}. La prima (e più forte) semplificazione che facciamo è
quella di \hl{considerare solo il comportamento asintotico, ossia $n \to
\infty$}. Per esprimere il comportamento asintotico abbiamo \hl{3 notazioni}:

\begin{itemize}
  \item \hl{$\mathcal{O}$-grande}: limite asintotico \hl{superiore};
  \item \hl{$\Omega$-grande}: limite asintotico \hl{inferiore};
  \item \hl{$\Theta$-grande}: limite asintotico \hl{sia superiore che
    inferiore}.
\end{itemize}

Eseguire una approssimazione di questo genere causa \hl{due problemi pratici}.
Il primo è che il \hl{comportamento asintotico potrebbe essere un pessimo
modello per valori piccoli di $n$}; il secondo è che \hl{in qualche raro caso la
complessità per $n$ piccolo non corrisponde alla nostra intuizione, ossia una
algoritmo con complessità asintotica minore può essere più lento per valori
piccoli di $n$ rispetto ad uno con complessità asintotica maggiore}.

\begin{defn}[\hl{$\mathcal{O}$-grande}]\label{def:o-grande}
  Data una \hl{funzione $g(n)$, $\mathcal{O}(g(n))$ è l'insieme}:

  \begin{equation}
    \mhl{
      \mathcal{O}(g(n)) = \{ f(n) : \exists c>0, n_0>0 \; (\forall n>n_0 \;
        0 \leq f(n) \leq cg(n)) \}
    }
  \end{equation}
\end{defn}

\begin{defn}[\hl{$\Omega$-grande}]\label{def:omega-grande}
  Data una \hl{funzione $g(n)$, $\Omega(g(n))$ è l'insieme}:

  \begin{equation}
    \mhl{
      \Omega(g(n)) = \{ f(n) : \exists c>0, n_0>0 \; (\forall n>n_0 \;
        0 \leq cg(n) \leq f(n)) \}
    }
  \end{equation}
\end{defn}

\begin{defn}[\hl{$\Theta$-grande}]\label{def:theta-grande}
  Data una \hl{funzione $g(n)$, $\Theta(g(n))$ è l'insieme}:

  \begin{equation}
    \mhl{
      \Theta(g(n)) = \{ f(n) : \exists c_1>0, c_2>0 n_0>0 \; (\forall n>n_0 \;
        0 \leq c_1 g(n) \leq f(n) \leq c_2 g(n)) \}
    }
  \end{equation}
\end{defn}

\begin{prop}[Proprietà delle notazioni asintotiche]
  \begin{enumerate}
    \item
      \[
        \mhl{
          f(n) \in \Theta(g(n)) \iff f(n) \in \mathcal{O}(g(n)) \land
          f(n) \in \Omega(g(n))
        }
      \]
    \item Le tre notazioni godono della \hl{proprietà transitiva};
    \item Le tre notazioni godono della \hl{proprietà riflessiva};
    \item \hl{$f(n) \in \Theta(g(n)) \iff g(n) \in \Theta(f(n))$};
    \item \hl{$f(n) \in \mathcal{O}(g(n)) \iff g(n) \in \Omega(f(n))$}.
  \end{enumerate}
\end{prop}

\begin{nota}
  Per le proprietà enunciate sopra, la \hl{$\Theta$ è una relazione di
  equivalenza}.
\end{nota}

Noi abbiamo definito le notazioni asintotiche in termini insiemistici, ma
possiamo anche \hl{definirle come limiti}:

\begin{defn}[\hl{$\Theta$-grande (come limite)}]\label{def:theta-grande-lim}
  Diciamo che $f(n) \in \Theta(g(n))$ se e solo se:

  \begin{equation}
    \mhl{
      \lim_{n \to \infty} \frac{f(n)}{g(n)} = c , c \neq 0, c \neq \infty
    }
  \end{equation}
\end{defn}

\begin{defn}[\hl{$\mathcal{O}$-grande (come limite)}]\label{def:o-grande-lim}
  Diciamo che $f(n) \in \mathcal{O}(g(n))$ se e solo se:

  \begin{equation}
    \mhl{
      \lim_{n \to \infty} \frac{f(n)}{g(n)} = 0
    }
  \end{equation}

  Possiamo anche scrivere $\Theta(f(n)) < \Theta(g(n))$
\end{defn}

\subsection{Complessità degli altri modelli visti fino ad ora}\label{sec:comp-fsa-pda-tm}

Analizziamo velocemente la complessità degli altri modelli di calcolo introdotti
fino ad ora: gli FSA, i PDA e le TM a nastro singolo.

\paragraph{FSA} Gli FSA avranno sempre complessità spaziale \hl{$S_{FSA}(n) \in
\Theta(1)$ (complessità costante), in quanto privi di memoria}, e complessità
temporale \hl{$T_{FSA}(n) \in \Theta(n)$ poiché leggono l'input in sequenza}, un
carattere alla volta.

\paragraph{PDA} A causa di come funziona la stack, la complessità spaziale sarà
\hl{$S_{PDA}(n) \in \Theta(n)$}, mentre quella temporale sarà, come nel caso
degli FSA, \hl{$T_{PDA}(n) \in \Theta(n)$}.

\paragraph{TM a nastro singolo} La complessità spaziale \hl{non potrà mai
scendere sotto la linearità} ($S_\mathcal{M}(n) \in \Theta(n)$) mentre quella
temporale si dimostra essere \hl{al massimo $T_\mathcal{M}(n) \in \Theta(n^2)$}.
Le TM a nastro singolo sono, quindi, più potenti dei PDA ma anche più lente.

\subsection{Teoremi di accelerazione lineare}\label{sec:acc-lin}

Enunciamo ora dei teoremi che ci permettono di \hl{migliorare con facilità,
sebbene al massimo linearmente la complessità} dei nostri algoritmi.

\begin{thm}[\hl{Primo teorema di accelerazione lineare}]\label{thm:acc-lin-1}
  Se $L$ è il linguaggio accettato da una \hl{TM $\mathcal{M}$ a $k$ nastri in
  $S_\mathcal{M}(n)$}, per ogni $c \in \mathbb{R}^+$ posso costruire una \hl{TM
  $\mathcal{M}'$ a $k$ nastri che accetta $L$ con}:

  \begin{equation}
    \mhl{ S_{\mathcal{M}'}(n) < c \cdot S_\mathcal{M}(n) }
  \end{equation}
\end{thm}

Il trucco usato da questo teorema, e anche degli altri teoremi a seguire, sta
nel \hl{aumentare la dimensione dell'alfabeto in favore della complessità}. Scegliamo
infatti un \hl{``fattore di compressione'' $r$ tale che $rc>2$}. \hl{Per ogni alfabeto
$\Gamma_i$ dell'$i$-esimo nastro di $\mathcal{M}$ costruisco $\Gamma_i'$ di
$\mathcal{M}'$ assegnando un elemento per ogni $s\in\Gamma_i^r$}. Ci basterà
infine costruire l'\hl{organo di controllo di $\mathcal{M}'$} in modo tale per cui:

\begin{enumerate}
  \item Calcoli con i nuovi simboli sui nastri \hl{emulando le mosse di
    $\mathcal{M}$ spostando le testine sui nastri ogni $r$ movimenti di
    $\mathcal{M}$};
  \item \hl{Memorizzi la posizione della testina arricchendo ulteriormente gli
    alfabeti $\Gamma_i$}, oppure arricchendo l'insieme degli stati.
\end{enumerate}

\begin{thm}[\hl{Secondo teorema di accelerazione lineare}]\label{thm:acc-lin-2}
  Se $L$ è il linguaggio accettato da una \hl{TM $\mathcal{M}$ a $k$ nastri in
  $S_\mathcal{M}(n)$}, posso costruire una \hl{TM $\mathcal{M}'$ a $1$ nastro}
  che accetta $L$ con:

  \begin{equation}
    \mhl{ S_{\mathcal{M}'}(n) = c \cdot S_\mathcal{M}(n) }
  \end{equation}
\end{thm}

\begin{thm}[\hl{Terzo teorema di accelerazione lineare}]\label{thm:acc-lin-3}
  Se $L$ è il linguaggio accettato da una \hl{TM $\mathcal{M}$ a $k$ nastri in
  $S_\mathcal{M}(n)$}, per ogni $c \in \mathbb{R}^+$ posso costruire una \hl{TM
  $\mathcal{M}'$ a $1$ nastro} che accetta $L$ con:

  \begin{equation}
    \mhl{ S_{\mathcal{M}'}(n) < c \cdot S_\mathcal{M}(n) }
  \end{equation}
\end{thm}

\begin{thm}[\hl{Quarto teorema di accelerazione lineare}]\label{thm:acc-lin-4}
  Se $L$ è il linguaggio accettato da una \hl{TM $\mathcal{M}$ a $k$ nastri in
  $T_\mathcal{M}(n)$}, per ogni $c \in \mathbb{R}^+$ posso costruire una \hl{TM
  $\mathcal{M}'$ a $k+1$ nastri} che accetta $L$ con

  \begin{equation}
    \mhl{ T_{\mathcal{M}'} = \max(n+1, c\cdot T_\mathcal{M}) }
  \end{equation}
\end{thm}

Come anche il primo teorema di accelerazione lineare, il \hl{trucco sta nel
codificare in modo compresso i simboli dell'alfabeto} di $\mathcal{M}$. Dobbiamo
considerare che la compressione avviene a runtime, quindi \hl{$T_{\mathcal{M}'}$
sarà al massimo lineare}. Comprimendo $r$ simboli in uno, \hl{nel caso pessimo,
possono servirmi 3 mosse di $\mathcal{M}'$ per emulare $r+1$ di $\mathcal{M}$}.

I teoremi sopra sono \hl{validi} anche per le \hl{macchine di Von Neumann}.
Infatti equivalgono ad \hl{aumentare la dimensione della parola di memoria della
macchina} o, equivalentemente, ad usare operazioni vettoriali. Possiamo avere
speedup lineari arbitrariamente grandi aumentando il parallelismo fisico (stando
ai limiti della fisica ovviamente). \hl{Miglioramenti più che lineari sono
possibili solo cambiando algoritmo}. Quindi concepire algoritmi più efficienti è
di gran lunga più efficace della forza bruta.

\subsection{Un nuovo modello di calcolo: la macchina RAM}\label{sec:ram}

Le macchine di Turing e i calcolatori hanno solo \hl{differenze marginali}: un
\hl{calcolatore} è capace di fare \hl{operazioni aritmetiche su tipi a
dimensione finita in tempo costante}, la TM invece deve eseguire l'aritmetica
bit per bit. Ciò può essere ``emulato'' considerando una TM con un alfabeto
molto vasto: $|I| = 2^w$ se volgiamo operare in binario con una parola di $w$
bit. Inoltre un \hl{calcolatore} può \hl{accedere direttamente ad una cella di
memoria}, mentre la TM deve spendere $\Theta(n)$ ($n$ distanza tra la cella e la
testina) tempo per scorrere il nastro. È giunta ora di aggiornare il nostro
modello di calcolo per \hl{modellare un po' più da vicino i calcolatori reali:
la macchina RAM\@}.

La macchina RAM è dotata di un \hl{nastro di lettura $\mathtt{In}$ e uno di
scrittura $\mathtt{Out}$} come anche una TM\@. Il \hl{programma che esegue lo
assumiamo essere cablato} nell'organo di controllo e \hl{composto da diverse
istruzioni} che essa esegue. Anche la logica per la gestione del program counter
assumiamo essere già cablata. La \hl{RAM è dotata di una memoria ad
indirizzamento diretto e randomico} (da cui prende il nome)
\hl{$\mathtt{M}[n]$}, $n\in\mathbb{N}$. Tutte le \hl{istruzioni} del programma
useranno \hl{la prima cella di memoria $\mathtt{M}[0]$, detta accumulatore. Ogni
cella di memoria inoltre conterrà un intero}.

Enunciamo l'instruction set e la corrispettiva semantica.

\begin{table}[htb]
  \centering
  \begin{tabular}{ll}
    \toprule
    Istruzione & Semantica \\
    \midrule
    \texttt{LOAD X}   & $\mathtt{M}[0] \gets \mathtt{M}[X]$ \\
    \texttt{LOAD= X}  & $\mathtt{M}[0] \gets X$ \\
    \texttt{LOAD* X}  & $\mathtt{M}[0] \gets \mathtt{M}[\mathtt{M}[X]]$ \\
    \texttt{STORE X}  & $\mathtt{M}[X] \gets \mathtt{M}[0]$ \\
    \texttt{STORE* X} & $\mathtt{M}[\mathtt{M}[X]] \gets M[0]$ \\
    \texttt{ADD X}    & $\mathtt{M}[0] \gets \mathtt{M}[0] + \mathtt{M}[X]$ \\
    \texttt{SUB X}    & $\mathtt{M}[0] \gets \mathtt{M}[0] - \mathtt{M}[X]$ \\
    \texttt{MUL X}    & $\mathtt{M}[0] \gets \mathtt{M}[0] * \mathtt{M}[X]$ \\
    \texttt{DIV X}    & $\mathtt{M}[0] \gets \mathtt{M}[0] / \mathtt{M}[X]$ \\
    \texttt{ADD= X}   & $\mathtt{M}[0] \gets \mathtt{M}[0] + X$ \\
    \texttt{SUB= X}   & $\mathtt{M}[0] \gets \mathtt{M}[0] - X$ \\
    \texttt{MUL= X}   & $\mathtt{M}[0] \gets \mathtt{M}[0] * X$ \\
    \texttt{DIV= X}   & $\mathtt{M}[0] \gets \mathtt{M}[0] / X$ \\
    \texttt{HALT}     & $-$ \\
    \texttt{READ X}   & $\mathtt{M}[X] \gets In$ \\
    \texttt{READ* X}  & $\mathtt{M}[\mathtt{M}[X]] \gets In$ \\
    \texttt{WRITE X}  & $Out \gets \mathtt{M}[X]$ \\
    \texttt{WRITE= X} & $Out \gets X$ \\
    \texttt{WRITE* X} & $Out \gets \mathtt{M}[\mathtt{M}[X]]$ \\
    \texttt{JUMP l}   & $PC \gets l$ \\
    \texttt{JZ l}     & $PC \gets l$ se $\mathtt{M}[0] = 0$ \\
    \texttt{JGZ l}    & $PC \gets l$ se $\mathtt{M}[0] > 0$ \\
    \texttt{JLZ l}    & $PC \gets l$ se $\mathtt{M}[0] < 0$ \\
    \bottomrule
  \end{tabular}
  \caption{Instruction set (non completo) della macchina RAM\@.}%
  \label{tab:ram-isa}
\end{table}

Si può notare dalla tabella~\ref{tab:ram-isa} che sono ammesse 3 modalità di
indirizzamento: diretto, immediato e indiretto. Le tre modalità funzionano come
in un normale linguaggio assembly.

\subsection{Limiti del criterio di costo}\label{sec:log-costo}

Consideriamo il caso del calcolo di $2^{2^n}$ con una una macchina RAM\@. Uno
schema di implementazione può essere:

\begin{lstlisting}
  read(n);
  x = 2;
  for (int i = 0; i < n; i++) x = x * x;
  write(x);
\end{lstlisting}

La complessità temporale dell'implementazione sopra è $T_{RAM} = \Theta(n)$.
Qualcosa non quadra: mi servono $2^n$ bit solo per scrivere il risultato! \hl{Il
criterio di costo fino ad ora usato considera un intero arbitrario di dimensione
costante. L'approssimazione regge fin quando una singola parola della macchina
reale contiene gli interi che maneggiano}. Se questo \hl{non accade}, dobbiamo
tener conto del \hl{numero di cifre necessarie per rappresentare un intero,
perdendo il costo costante del salvataggio di interi e delle operazioni
elementari su di essi}. In questi casi eseguire operazioni su un intero $i$
costa tanto quanto il suo numero di cifre in base $b$.

Forniamo allora una \hl{criterio di costo più realistico}: il \hl{costo
logaritmico}. Una \hl{operazione} su un intero $i$ \hl{costerà tanto più sono le
sue cifre in una base $b \geq 2$}, ossia $\log_b(i) = \Theta(\log(i))$. Possiamo
\hl{omettere la base} del logaritmo poiché i \hl{logaritmi in diverse basi
differiscono tra di loro solo per una costante} (vedasi la formula di
cambiamento di base del logaritmo).

Applichiamo il nuovo criterio di costo alle principali operazioni aritmetiche.
Consideriamo $d = \log_2(i)$:

\begin{itemize}
  \item Le \hl{addizioni} e sottrazioni sono operazioni effettuate bit per bit,
    quindi avranno costo \hl{$\Theta(d)$}.
  \item La \hl{moltiplicazione} eseguita con il \hl{metodo scolastico} richiede
    di iterare sulle cifre 2 volte, quindi avrà costo \hl{$\Theta(d^2)$}. Studi
    sull'aritmetica ci dicono che la complessità è migliorabile, sebbene con un
    compromesso nella facilità di calcolo:

    \begin{itemize}
      \item \hl{Primo miglioramento: $\Theta(d^{\log_2(3)}) \approx
        \Theta(d^{1.58})$}
      \item \hl{Secondo miglioramento: $\Theta(d\log(d)\log(\log(d)))$}
      \item \hl{Miglior costo attualmente scoperto: $\Theta(d\log(d))$}
    \end{itemize}

  \item Le \hl{divisioni} con il \hl{metodo scolastico}, analogamente alle
    moltiplicazioni, hanno costo \hl{$\Theta(d^2)$}. Si è dimostrato che la
    complessità \hl{può essere migliorata} a \hl{$\Theta(\log^2(d)) \cdot
    \mathit{costo\_mul}$} dove $\mathit{costo\_mul}$ è il costo dell'algoritmo
    di moltiplicazione scelto.
\end{itemize}

Le operazioni di \hl{\texttt{JUMP} e \texttt{HALT}} hanno \hl{costo costante},
così come \hl{anche le istruzioni di salto condizionale}.

\hl{Per scegliere} tra i due criteri basta che \hl{controlliamo l'accuratezza
dell'approssimazione a costo costante}: se la dimensione di ogni singolo
elemento in ingresso non varia in modo significativo durante l'esecuzione usiamo
il costo cotante e altrimenti quello logaritmico.

\subsection{Legami tra le complessità dei vari modelli di calcolo}

Quanto effetto ha sulla complessità cambiare modello di calcolo? \hl{Sotto
ragionevoli ipotesi di criteri di costo, se un problema è risolvibile da una TM
$\mathcal{M}$ in $T_\mathcal{M}(n)$, allora è risolvibile da un qualsiasi altro
modello Turing-completo in $\pi(T_\mathcal{M})$ dove $\pi(\cdot)$ è un opportuno
polinomio}. Questa affermazione è detta \hl{``tesi di correlazione lineare''}.
Noi la dimostreremo solo tra i due modelli più importanti, la macchina \hl{RAM}
e la \hl{macchina di Turing}.

Prima di passare alla tesi di correlazione lineare, dimostriamo un \hl{risultato
intermedio} che useremo.

\begin{lem}[\hl{Occupazione sul nastro principale}]\label{thm:occupazione-nastro}
  Sia una macchina di Turing e una macchina RAM\@. Lo \hl{spazio occupato sul
  nastro principale è $\mathcal{O}(T_{RAM}(n))$}.
\end{lem}
\begin{proof}
  Ogni cella della RAM occupa $\log(i_j)+\log(\mathtt{M}[i_j])$ spazio e viene
  materializzata se e solo se la RAM effettua un operazione di \texttt{STORE}.
  L'istruzione di \texttt{STORE} costa alla RAM $\log(i_j) +
  \log(\mathtt{M}[i_j])$, quindi per riempire $r$ celle la RAM impiegherà
  $\sum_{j=1}^r \log(i_j) + \log(\mathtt{M}[i_j])$. Questa quantità di tempo è
  identica allo spazio che $r$ celle di memoria occuperanno sul nastro della
  TM\@.
\end{proof}

\begin{thm}[\hl{Correlazione temporale tra TM a $k$ nastri e RAM}]\label{thm:corr-tm-ram}
  Se un \hl{problema è risolvibile da una TM a $k$ nastri $\mathcal{M}$ in
  $T_\mathcal{M}(n)$ e da una macchina RAM in $T_{RAM}(n)$}, allora si avrà:

  \begin{equation}
    \mhl{ T_\mathcal{M}(n) = \pi(T_{RAM}(n)) }
  \end{equation}

  Dove $\pi(\cdot)$ è un opportuno polinomio.
\end{thm}
\begin{proof}
  Come primo passo dimostriamo che possiamo emulare un TM con una RAM in tempo
  polinomiale. Mappiamo innanzitutto le varie parti di una TM su una RAM\@:

  \begin{itemize}
    \item Lo stato della TM corrisponderà all'accumulatore della RAM\@;
    \item Una cella della RAM corrisponderà ad una cella di nastro;
    \item La RAM è suddivisa in blocchi da $k$ celle.
  \end{itemize}

  I blocchi saranno riempiti secondo questa strategia: nel blocco $0$ saranno
  salvate in ogni cella le posizioni delle $k$ testine; nei rimanenti $n>0$
  blocchi sarà salvato lo $n$-esimo blocco di ognuno dei $k$ nastri. La RAM
  emulerà la lettura di un carattere sotto la testina con un accesso indiretto,
  usando l'indice contenuto nel blocco $0$. Studiamo ora il costo
  dell'emulazione delle due operazioni che può effettuare una macchina di
  Turing:

  \begin{description}
    \item[Lettura] La lettura del blocco $0$ e dello stato avviene in
      $\Theta(k)$ mosse. La lettura dei valori sui nastri in corrispondenza
      delle testine avverrà in $\Theta(k)$ accessi indiretti.
    \item[Scrittura] La scrittura dello stato avviene in una mossa
      ($\Theta(1)$). Le scritture sui nastri e nel blocco $0$, come anche le
      letture, impiegano rispettivamente $\Theta(k)$ accessi indiretti e
      $\Theta(k)$ mosse.
  \end{description}

  La RAM è quindi capace di emulare una mossa della TM con $k$ mosse:

  \[
    T_{RAM}(n) = \Theta(T_\mathcal{M}(n))
      [ = \Theta(T_\mathcal{M}(n)\log(T_\mathcal{M}(n))) \text{ costo logaritmico} ]
  \]

  Studiamo ora l'emulazione da parte di una MT di una macchina RAM\@. Per
  semplicità ometteremo l'emulazione delle operazione di \texttt{MUL} e
  \texttt{DIV} in quanto non ledono alla generalità della dimostrazione.
  Organizziamo il nastro della TM come in figura~\ref{fig:thm-corr-tm-ram}.

  \begin{figure}[htb]
    \centering
    \begin{tikzpicture}
      \draw[black,thin,step=0.9] (0,0) grid (11.7, 0.9);

      \node[] at (0.45,  0.45) [] () {$\ldots$};
      \node[] at (1.35,  0.45) [] () {\Large$\triangleleft$};
      \node[] at (2.25,  0.45) [] () {\large$i_j$};
      \node[] at (3.15,  0.45) [] () {\Large$\ddagger$};
      \node[] at (4.05,  0.45) [] () {$\mathtt{M}[i_j]$};
      \node[] at (4.95,  0.45) [] () {\Large$\triangleright$};
      \node[] at (5.85,  0.45) [] () {$\ldots$};
      \node[] at (6.75,  0.45) [] () {\Large$\triangleleft$};
      \node[] at (7.65,  0.45) [] () {\large$i_k$};
      \node[] at (8.55,  0.45) [] () {\Large$\ddagger$};
      \node[] at (9.45,  0.45) [] () {$\mathtt{M}[i_k]$};
      \node[] at (10.35, 0.45) [] () {\Large$\triangleright$};
      \node[] at (11.25, 0.45) [] () {$\ldots$};
    \end{tikzpicture}
    \caption{Configurazione del nastro della TM\@.}%
    \label{fig:thm-corr-tm-ram}
  \end{figure}

  Il nastro è inizialmente vuoto, salveremo solo le celle in cui è avvenuta una
  \texttt{STORE}. Usiamo anche un ulteriore nastro per contenere il valore di
  $\mathtt{M}[0]$ in binario. Useremo anche un ultimo nastro come stoccaggio
  temporaneo per quando serve salvare per la prima volta $\mathtt{M}[i_j]$ ma
  $\mathtt{M}[i_k]$ e $\mathtt{M}[i_l]$ con $i_k < i_j < i_l$ sono già state
  salvate. Con questa configurazione, studiamo l'emulazione delle varie
  istruzioni della RAM (nel dettaglio vedremo solo \texttt{LOAD}, \texttt{STORE}
  e \texttt{ADD}):

  \begin{description}
    \item[\texttt{LOAD x}] Devo effettuare una ricerca di \texttt{x} sul nastro
      principale e poi copiare la porzione di nastro accanto nella zona dati di
      $\mathtt{M}[0]$ usando il nastro di supporto.
    \item[\texttt{STORE x}] Devo anche qui effettuare una ricerca di \texttt{x}
      sul nastro principale, se lo trovo vi salvo nello spazio adiacente il
      valore di $\mathtt{M}[0]$, altrimenti creo dello spazio usando il nastro
      di servizio se necessario e lo salvo.
    \item[\texttt{ADD x}] Effettuo ancora una ricerca di \texttt{x}, copio
      $\mathtt{M}[x]$ sul nastro di supporto, ne calcolo la somma scrivendo il
      risultato in $\mathtt{M}[0]$.
  \end{description}

  In generale possiamo dire grazie al lemma~\ref{thm:occupazione-nastro} che
  simulare una mossa della RAM richiede alle TM un numero di mosse minore o
  uguale ad una costante per la lunghezza del nastro principale. Quindi la TM
  impiega al più $\Theta(T_{RAM}(n))$ per simulare una mossa della RAM\@. Poiché
  ogni mossa della RAM ha costo unitario, possiamo dire che essa esegue
  $T_{RAM}(n)$ mosse. Quindi la simulazione completa della RAM da parte della TM
  costa al più

  \[
    \Theta(T_{RAM}(n) \cdot T_{RAM}(n)) = \Theta({(T_{RAM}(n))}^2)
  \]

  Quindi il legame tra $T_{RAM}(n)$ e $T_\mathcal{M}(n)$ è polinomiale.
\end{proof}

L'esistenza della correlazione polinomiale tra macchina RAM e macchina di Turing
ci permette di \hl{definire una classe di problemi risolvibili in tempo
polinomiale (classe P)}. Questo risultato ha portato ad una \hl{``testi di
trattabilità''}: i \hl{problemi risolvibili in P sono quelli trattabili}. In
questo caso per trattabili \hl{intendiamo risolvibili con complessità con
esponente ragionevole}. Infatti la classe P comprende anche polinomi come
$n^{30}$, ma \hl{empiricamente si è visto che la maggioranza dei problemi
polinomiali di interesse pratico ha un grado polinomiale accettabile} di solito
inferiore a $4$.

\section{Studio della complessità di algoritmi}\label{sec:comp-alg}

Dato un certo problema, un buon flusso di lavoro è il seguente:

\begin{enumerate}
  \item Concepire un algoritmo che lo risolve;
  \item Valutare la complessità dell'algoritmo trovato;
  \item Se la complessità calcolata è soddisfacente, implementare l'algoritmo
    nel linguaggio scelto.
\end{enumerate}

Per controllare la correttezza di un algoritmo, come abbiamo già visto, non
esiste una procedura generale. Ciò però non nega il fatto che per alcuni
particolari casi possiamo costruire degli algoritmi di controllo.

Il \hl{modello che useremo} per valutare la complessità è, ovviamente, la
\hl{macchina RAM}\@. Ci \hl{concentreremo}, inoltre, sulla \hl{complessità
temporale calcolata con il criterio di costo costante} in quanto gli algoritmi
trattati non hanno espansioni significative della dimensione dei singoli dati.
Nei rari casi in cui ciò accade, possiamo rappresentare questi numeri molto
grandi come vettori di numeri più piccoli. Il \hl{linguaggio} che useremo per
definire gli algoritmi è lo \hl{``pseudocodice''}. Esso non è altro che
\hl{un'astrazione delle caratteristiche dei linguaggi di programmazione più
comuni} (C, Java, ecc\dots). Una assunzione fondamentale sullo pseudocodice sarà
che \hl{ogni statement di esso può essere tradotto in un numero costante di
istruzioni RAM}\@.

\subsection{La sintassi dello pseudocodice}\label{sec:syntax-pseudocodice}

Innanzitutto ogni algoritmo sarà \hl{definito come una procedura, ossia una
funzione che prende un input e non ritorna nulla}. Forniamo ora la sintassi base
dello pseudocodice che useremo.

\paragraph{Operatori} Sono definiti i \hl{soliti operatori matematici}. Useremo
\hl{\peq{} come assegnamento e riserveremo \texttt{=} per uguaglianza}. Per i
\hl{confronti useremo i soliti} \texttt{<}, $\leq$, \texttt{>} e $\geq$.

\paragraph{Commenti} Sono legali solo \hl{commenti monoriga delimitati da
\pcom{}} oppure usando \texttt{//}.

\paragraph{Costrutti di controllo del flusso} Sono presenti \hl{tutti} i
costrutti di controllo del flusso che ci si aspetterebbe \hl{in un normale
linguaggio C-like}: \texttt{if}, \texttt{else}, \texttt{else if} e i cicli
\texttt{for\dots}, \texttt{while} e \texttt{do\dots while}.

\paragraph{Strutture dati e tipi aggregati} Sono definiti gli \hl{array} e sono
accessibili con una notazione C-like:

\begin{itemize}
  \item \hl{\texttt{A[i]} per indirizzare} lo $i-1$-esimo elemento
    (indicizzazione a partire da 0);
  \item \hl{\texttt{A[i..j]}} per estrarre un \hl{sotto-array} (slice).
\end{itemize}

\noindent È anche possibile creare \hl{tipi aggregati, i vari campi di questi
sono indirizzabili tramite `\texttt{.}'}. I tipi aggregati sono di default
\hl{identificati da un puntatore alla struttura}, quindi la notazione
`\texttt{.}' equivale al \texttt{->} del C/C++. Un \hl{puntatore indefinito ha
valore \texttt{NIL}}.

\paragraph{Chiamata di funzioni} Le chiamate a funzione seguono le consuete
regole di chiamata e ritorno di un valore. I \hl{parametri di tipo base sono
passati per valore, mentre i tipi aggregati per riferimento} (convenzione
Java-like).

\begin{esempio}
  Consideriamo la rimozione di un elemento rispettivamente da un vettore e da
  una lista.

  \begin{lstlisting}[language=pseudocodice,gobble=4]
    CancellaElV(v, len, e)
      i `\peq{}` 0
      while v[i] $\neq$ e
        i `\peq{}` i + 1
      while i < len -1
        i `\peq{}` v[i + 1]
        i `\peq{}` i + 1
      v[len - 1] `\peq` $\bot$

    CancellaElL(l, e)
      p `\peq` l
      while p.next $\neq$ NIL and p.next.value $\neq$ e
        p `\peq` p.next
      if p.next.value = e
        p.next `\peq` p.next.next
  \end{lstlisting}

  Sono entrambi, nel caso pessimo, $\Theta(n)$ dove $n$ è il numero degli
  elementi del vettore/lista.
\end{esempio}
\begin{esempio}
  Consideriamo il seguente algoritmo di moltiplicazione di matrici:

  \begin{lstlisting}[language=pseudocodice,gobble=4]
    A `\peq` Matrix(n, m)
    B `\peq` Matrix(m, o)

    MatrixMultiply(A, B)
      C `\peq` Matrix(n, o)
      for i `\peq` 0 to A.n - 1
        for j `\peq` 0 to B.o - 1
          C[i][j] `\peq` 0
          for k `\peq` 0 to A.m - 1
            C[i][j] `\peq` C[i][j] + A[i][k] * B[k][j]
      return C
  \end{lstlisting}

  La riga 5 viene eseguita $n*o$ volte, la 10 $n*m*o$ volte quindi l'algoritmo
  avrà complessità $\Theta(n*m*o)$ sia in generale che nel caso pessimo. Se le
  due matrici sono quadrate avremo $\Theta(n^3)$.
\end{esempio}

\subsection{Studio di algoritmi ricorsivi}\label{sec:alg-ricorsivi}

È possibile incontrare algoritmi la cui complessità non è immediatamente
esprimibile in forma chiusa. Il caso \hl{tipico} sono algoritmi che seguono la
\hl{strategia ``divide et impera''}. Questa strategia consiste nel
\hl{suddividere il problema in sottoproblemi con input $\frac{1}{b}$
dell'originale}; quando il sottoproblema ha \hl{ingresso} di dimensioni $n$
\hl{piccole a sufficienza può essere risolto a tempo costante}. Chiamiamo
\hl{$D(n)$} il costo del \hl{suddividere il problema} e con \hl{$C(n)$} il
\hl{costo di combinare le soluzioni}. Possiamo quindi esprimere il \hl{costo
totale $T(n)$} con la seguente \hl{equazione di ricorrenza}:

\begin{equation}
  \mhl{
    T(n) =
    \begin{cases}
      \Theta(1)                              & \quad \text{se } n < c \\
      D(n) + aT\left(\frac{n}{b}\right)+C(n) & \quad \text{altrimenti}
    \end{cases}
  }
\end{equation}

Dove le costanti \hl{$a$, $b$ e $c$} indicano \hl{rispettivamente} il \hl{numero
di chiamate ricorsive, il numero di suddivisioni dell'input e il numero sotto al
quale il sottoproblema ha costo costante}.

Per risolvere un problema in questa forma possiamo utilizzare \hl{3 tecniche:
sostituzione, studio dell'albero di ricorsione e il teorema dell'esperto}
(``master theorem'').

\subsubsection{Metodo di sostituzione}\label{sec:alg-ricorsivi-sost}

Il metodo di sostituzione è \hl{sostanzialmente una dimostrazione per induzione
del fatto che una soluzione ``intuita'' è effettivamente una soluzione}. Esso si
articola in 3 fasi:

\begin{enumerate}
  \item Intuire una soluzione (ovviamente);
  \item Sostituire la presunta soluzione nella ricorrenza;
  \item Dimostrare per induzione che la presunta soluzione è tale per
    l'equazione/disequazione alle ricorrenze.
\end{enumerate}

Usiamo come caso di studio l'algoritmo di ricerca binaria in quanto semplice e
dall'implementazione intuitiva. Possiamo esprimere la \hl{complessità della ricerca
binaria} come:

\begin{equation}
  \mhl{
    T(n) = \Theta(1) + T\left(\frac{n}{2}\right) + \Theta(1)
  }
\end{equation}

\hl{``Intuiamo'' una soluzione $T(n) = \mathcal{O}(\log(n))$}, ossia $T(n) \leq
c\log(n)$. Dobbiamo quindi dimostrare che

\begin{equation}
  T(n) = \Theta(1) + T\left(\frac{n}{2}\right) + \Theta(1) \leq c\log(n)
\end{equation}

Consideriamo \hl{vero per l'ipotesi di induzione $T(\frac{n}{2}) \leq
c\log(\frac{n}{2})$} in quanto $\frac{n}{2} < n$ e sostituiamo ottenendo:

\begin{equation}
  \mhl{
    T(n) \leq c\log\left(\frac{n}{2}\right) + \Theta(k) = c\log(n) - c\log(2) +
      \Theta(k) \leq c\log(n)
  }
\end{equation}

\begin{esempio}
  Determiniamo un limite superiore per $T(n) = 2T(\frac{n}{2})+n$. Intuiamo
  $\mathcal{O}(n\log(n))$, dimostriamo quindi che $T(n) \leq cn\log(n)$.
  Supponiamo vero per induzione che $T(n/2) \leq c(n/2\log(n/2))$ e sostituiamo:

  \begin{align*}
    T(n) & \leq 2c(n/2\log(n/2)) + n \leq cnlog(n/2)+n = \\
      & = cn\log(n) - cn\log(2) + n \leq \\
      & \leq cn\log(n) + (1-c\log(2))n < \\
      & < cn\log(n)
  \end{align*}

  Per dimostrare il caso base possiamo trovare un $n_0$ per il quale vale la
  nostra ipotesi, in questo caso $n_0 = 3$.
\end{esempio}
\begin{esempio}
  Troviamo un limite superiore per $T(n) = 2T(n/2) + 1$. Tentiamo di provare che
  $\mathcal{O}(n)$, ossia $T(n) = cn$. Supponiamo vero, sempre per induzione,
  $T(n/2) = cn/2$. Sostituiamo ottenendo che $T(n) \leq 2cn/2 + 1 = cn+1$. Non
  possiamo trovare un valore che faccia rispettare l'ipotesi: $cn+1 \geq cn$
  sempre. In questo caso non siamo riusciti a dimostrare il limite tramite
  sostituzione. Attenzione: ciò non implica che $T(n) \neq \mathcal{O}(n)$!
  Infatti se prendiamo come ipotesi $T(n) \leq cn-b$ con $b$ costante consente
  di dimostrare che $T(n) = \mathcal{O}(n)$.
\end{esempio}

\subsubsection{Studio dell'albero di ricorsione}\label{sec:alg-ricorsivi-albero}

Lo studio dell'albero di ricorsione ci \hl{fornisce un aiuto per trovare una
congettura da verificare con il metodo di sostituzione}. L'albero di ricorsione è
una \hl{rappresentazione delle chiamate ricorsive}, indicando per ognuna la
complessità. Ogni chiamata costituisce un nodo dell'albero, i chiamati appaiono
come figli del chiamante. Rappresentiamo \hl{l'albero di}:

\begin{equation}
  \mhl{
    T(n) = T\left(\frac{n}{3}\right) + T\left(\frac{2n}{3}\right) + n\label{eqn:albero-ricorsione}
  }
\end{equation}

\begin{figure}[htb]
  \centering
  \begin{tikzpicture}[
    level 1/.style = {sibling distance=4cm},
    level 2/.style = {sibling distance=2cm},
    level 3/.style = {sibling distance=1cm},
    level 4/.style = {sibling distance=1cm}
  ]
    \node{$n$}
      child{
        node{$\frac{n}{3}$}
          child{
            node{$\frac{n}{3^2}$}
              child {
                node{$\vdots$}
                  child{
                    node{$\frac{n}{3^k}$}
                  }
                  child{
                    node{$\frac{2n}{3^k}$}
                  }
              }
              child {
                node{$\vdots$}
              }
          }
          child{
            node{$\frac{2n}{3^2}$}
              child {
                node{$\vdots$}
              }
              child {
                node{$\vdots$}
              }
          }
      }
      child{
        node{$\frac{2n}{3}$}
          child{
            node{$\frac{2n}{3^2}$}
              child {
                node{$\vdots$}
              }
              child {
                node{$\vdots$}
              }
          }
          child{
            node{$\frac{2^2 n}{3^2}$}
              child {
                node{$\vdots$}
              }
              child {
                node{$\vdots$}
                  child{
                    node{$\frac{2^{k-1}n}{3^k}$}
                  }
                  child{
                    node{$\frac{2^k n}{3^k}$}
                  }
              }
          }
      };
  \end{tikzpicture}
  \caption{L'albero di ricorsione di~\ref{eqn:albero-ricorsione}.}%
  \label{fig:albero-ricorsione}
\end{figure}

L'albero ha la \hl{ramificazione a profondità massima posta sull'estrema destra}
della figura~\ref{fig:albero-ricorsione}. Sappiamo che essa ha \hl{profondità $k$
pari a}:

\begin{equation}
  \mhl{
    \frac{2^k}{3^k} n = 1 \implies{} k = \log_3(2^k n) = \cdots = c\log_3(n)
  }
\end{equation}

Il \hl{costo pessimo per il contributo di un dato livello è la $n$} della radice
dell'albero, \hl{congetturiamo allora che $T(n) = \Theta(n\log(n))$}. Possiamo
quindi proseguire la dimostrazione con i metodi visti
in~\ref{sec:alg-ricorsivi-sost}.

\subsubsection{Teorema dell'esperto}\label{sec:alg-ricorsivi-esperto}

Il teorema dell'esperto è uno \hl{strumento per risolvere buona parte delle
equazioni alle ricorrenze}. Affinché sia applicabile, la \hl{ricorrenza deve
avere la seguente forma}:

\begin{equation}
  \mhl{
    T(n) = aT\left(\frac{n}{b}\right) + f(n)
  }
\end{equation}

Con \hl{$a \geq 1$ e $b>1$}. L'idea di fondo è quella di \hl{confrontare
$n^{\log_b(a)}$ (effetto delle chiamate ricorsive) con quello di $f(n)$ (costo
di ogni singola chiamata)}. Le \hl{ipotesi} del teorema sono le seguenti:

\begin{enumerate}
  \item \hl{$a$ deve essere costante e maggiore di 1};
  \item \hl{$f(n)$ deve essere sommata, non sottratta o altro a
    $aT(\frac{n}{b})$};
  \item \hl{Il legame tra $n^{\log_b(a)}$ e $f(n)$ deve essere polinomiale}.
\end{enumerate}

Se queste ipotesi sono valide, è possibile ricavare informazioni sulla
complessità a seconda del caso in cui ci si trova:

\paragraph{Caso 1} Nel primo caso abbiamo che \hl{$f(n) =
\mathcal{O}(n^{\log_b(a) - \epsilon})$ per un $\epsilon>0$}. La \hl{complessità
risultante sarà $T(n) = \Theta(n^{\log_b(a)})$}. Intuitivamente si può intendere
questa situazione come il caso nel quale \hl{il costo della ricorsione domina
quello della chiamata}.

\paragraph{Caso 2} Nel secondo caso abbiamo che \hl{$f(n) =
\mathcal{O}(n^{\log_b(a)}{(\log(n))}^k)$}. La \hl{complessità risultante sarà
$T(n) = \Theta(n^{\log_b(a)}{(\log(n))}^{k+1})$}. In questo caso, invece,
possiamo intuire che \hl{il contributo della ricorsione e quello della singola
chiamata differiscono per meno di un termine polinomiale}.

\paragraph{Caso 3} Nell'ultimo caso abbiamo che \hl{$f(n) = \Omega(n^{\log_b(a)
+ \epsilon})$ per un $\epsilon >0$}. Se questo è vero, \hl{deve anche valere
$af(\frac{n}{b})<cf(n)$} per un qualche valore di \hl{$c<1$}. Se le ipotesi sono
rispettate \hl{abbiamo che $T(n) = \Theta(f(n))$}. Qui, invece, \hl{domina il
costo della singola chiamata}.

\subsection{Algoritmi di ordinamento}\label{sec:alg-odinamento}

Tra i problemi che capita più spesso di dover risolvere, l'ordinamento di una
collezione di oggetti è un classico. \hl{Un punto chiave dell'utilità
dell'ordinamento è consentire utilizzare una ricerca più efficiente, come ad
esempio quella binaria, sulla nostra collezione}. Analizzeremo soluzioni diverse
considerando la loro complessità temporale, spaziale e relative peculiarità.

\begin{defn}[\hl{Proprietà di stabilità di un ordinamento}]\label{def:prop-stabilita}
  Diciamo che un ordinamento gode della \hl{proprietà di stabilità se non
  modifica l'ordine di elementi duplicati}.
\end{defn}

\subsubsection{Insertion sort}\label{sec:insertion-sort}

L'insertion sort è il primo e il tra i più naturali algoritmi di ordinamento che
vedremo. L'algoritmo \hl{modella come un uomo ordinerebbe, ad esempio, un mazzo
di carte: selezioniamo un elemento della slice non ordinata e reinseriamolo al
giusto posto della slice ordinata}.

\begin{lstlisting}[
  language=pseudocodice,
  gobble=2,
  caption=Insertion Sort
]
  InsertionSort(A)
    for i `\peq` 1 to A.length - 1
      tmp `\peq` A[i]
      j `\peq` i - 1
      while j $\geq$ 0 and A[j] $>$ tmp
        A[j + 1] `\peq` A[j]
        j `\peq` j - 1
      A[j + 1] `\peq` tmp
\end{lstlisting}

Nel \hl{caso ottimo} abbiamo una complessità di \hl{$\Theta(n)$}, in quello
\hl{pessimo} invece \hl{$\Theta(n^2)$}, in \hl{generale} invece
\hl{$\mathcal{O}(n^2)$}. La \hl{complessità spaziale} è invece \hl{costante} in
quanto \hl{tutte le operazioni avvengono in-place}. Inoltre otterremo un
\hl{algoritmo stabile usando \texttt{A[j] > tmp}}, mentre uno \hl{instabile
usando $\mathtt{A[j]} \geq \mathtt{tmp}$}.

\subsubsection{Merge sort}\label{sec:merge-sort}

Possiamo sicuramente trovare algoritmi più efficienti. Intuitivamente si può
vedere che \hl{ogni algoritmo di ordinamento sarà $\Omega(n)$ e
$\mathcal{O}(n^2)$} (si possono trovare anche limiti superiori maggiori, ma noi
consideriamo solo ordinamenti ``intelligenti''). Proviamo ad avvicinarci al
limite inferiore teoretico. \hl{Astraiamo dalla specifica strategia di
ordinamento e studiamo il numero di confronti e scambi}. Consideriamo per
semplicità un \hl{array di $3$ elementi $v$}. Come si può vedere dalla
\hl{figura}~\ref{fig:albero-confronti}, otteniamo un \hl{albero quasi binario
con $n!$ foglie, dove $n$ è il numero di elementi}. Assumiamo che \hl{non ci
siano confronti ridondanti}. La \hl{lunghezza del più lungo percorso
radice-foglia è il numero massimo di confronti che devo fare per ordinare un
vettore. L'altezza dell'albero sarà}:

\begin{equation}
  \mhl{
    \log_2(n!) \approx n\log_2(n) - n\log_2(e) + \mathcal{O}(\log(n))
  }
\end{equation}

Dove abbiamo usato l'\hl{approssimazione di Sterling del fattoriale} per
ottenere che la \hl{migliore complessità ottenibile con questo metodo sarà
$\mathcal{O}(n\log(n))$}.

\begin{figure}[htb]
  \centering
  \begin{tikzpicture}[
    level 1/.style={sibling distance=7cm},
    level 2/.style={sibling distance=4cm},
    level 3/.style={sibling distance=4cm}
  ]
    \node {$v[1] \leq v[2]$}
      child {
        node {$v[2] \leq v[3]$}
          child {
            node {\color{ForestGreen}$\langle v[2],v[2],v[3] \rangle$}
            edge from parent node [left] {v}
          }
          child {
            node {$v[1] \leq v[3]$}
              child {
                node {\color{ForestGreen}$\langle v[1],v[3],v[2] \rangle$}
                edge from parent node [left] {v}
              }
              child {
                node {\color{ForestGreen}$\langle v[3],v[1],v[2] \rangle$}
                edge from parent node [right] {f}
              }
            edge from parent node [right] {f}
          }
        edge from parent node [left] {v}
      }
      child {
        node {$v[1] \leq v[3]$}
          child {
            node {\color{ForestGreen}$\langle v[2],v[1],v[3] \rangle$}
            edge from parent node [left] {v}
          }
          child {
            node {$v[2] \leq v[3]$}
              child {
                node {\color{ForestGreen}$\langle v[2],v[3],v[1] \rangle$}
                edge from parent node [left] {v}
              }
              child {
                node {\color{ForestGreen}$\langle v[3],v[2],v[1] \rangle$}
                edge from parent node [right] {f}
              }
            edge from parent node [right] {f}
          }
        edge from parent node [right] {f}
      };
  \end{tikzpicture}
  \caption{Albero dei confronti per l'ordinamento di $v$}%
  \label{fig:albero-confronti}
\end{figure}

Il primo algoritmo che vediamo che raggiunge questa complessità sarà il merge
sort. \hl{Il merge sort è un ordinamento ``divide et impera'' con complessità
$\Theta(n\log(n))$ in tutti i casi}. Nonostante l'eccezionale complessità in
caso pessimo, non è l'ordinamento perfetto perché è \hl{caratterizzato da molte
operazioni di memoria e una non trascurabile complessità spaziale}.

Il merge sort \hl{prima suddivide il vettore di elementi da ordinare in porzioni più
piccole, fin quando le partizioni non sono ordinabili in $\Theta(1)$, dopodiché
riassembla le varie slice}. È \hl{importante} che il \hl{riassemblamento dei risultati non
abbia complessità eccessiva}. Poiché la procedura di unione delle varie slice
è la parte principale della complessità, studiamo prima quella.

Consideriamo \hl{due slice \texttt{A[p..q]} e \texttt{A[q + 1..r]}, è facile}
dimostrare che la complessità della \hl{ricombinazione di questi sia lineare}:

\begin{lstlisting}[
  language=pseudocodice,
  gobble=2,
  caption=Funzione di merge dei vettori
]
  Merge(A, p, q, r)
    len1 `\peq` q - p + 1
    len2 `\peq` r - q
    Alloc(L[1..len1 + 1])
    Alloc(R[1..len2 + 1])
    for i `\peq` 1 to len1 // copia della prima meta'
      L[i] `\peq` A[p + i - 1]
    for i `\peq` 1 to len2 // copia della seconda meta'
      R[i] `\peq` A[q + i]
    L[len1 + 1] `\peq` $\infty$ // sentinella
    R[len2 + 1] `\peq` $\infty$ // sentinella
    i `\peq` 1
    j `\peq` 1
    for k `\peq` p to r
      if L[i] $\leq$ R[j]
        A[k] `\peq` L[i]
        i `\peq` i + 1
      else
        A[k] `\peq` R[j]
        j `\peq` j + 1
\end{lstlisting}

Vediamo ora il \hl{merge sort}:

\begin{lstlisting}[
  language=pseudocodice,
  gobble=2,
  caption=Merge Sort
]
  MergeSort(A, p, r)
    if p $<$ r - 1
      q `\peq` $\lfloor \frac{\mathtt{p + r}}{2} \rfloor$
      MergeSort(A, p, q)
      MergeSort(A, q + 1, r)
    else // caso base della ricorsione: solo 2 elementi
      if A[p] $<$ A[r]
        tmp `\peq` A[r]
        A[r] `\peq` A[p]
        A[p] `\peq` tmp
\end{lstlisting}

Il \hl{costo del merge sort} sarà dato dalla \hl{ricorrenza $T(n) =
2T(\frac{n}{2}) + \Theta(n)$}. Usando il \hl{secondo caso del master theorem
otteniamo $T(n) = \Theta(n\log(n))$}.

\hl{La stabilità del merge sort dipende dall'algoritmo d'unione: se consideriamo
$\leq$ allora sarà stabile, instabile con $<$}.

\subsubsection{Quicksort}\label{sec:quicksort}

Quicksort sarà il secondo algoritmo che vedremo che ha complessità vicina al
minimo teoretico. Anche esso è, come merge sort, un\hl{ algoritmo di tipo
``divide et impera''. La sua peculiarità è che l'ordinamento avviene senza uso
di spazio ausiliario}.

Il quicksort applica la \hl{strategia ``divide et impera'' ad una slice
\texttt{A[lo..hi]}}:

\begin{description}
  \item[Dividi] Scelgo un elemento \hl{\texttt{A[p]}, detto pivot, come punto di
    suddivisione della slice} di partenza e \hl{sposta tutti gli elementi di
    essa in modo che tutti quelli di \texttt{A[lo..p - 1]} siano minori del
    pivot}.
  \item[Impera] \hl{Ordina ricorsivamente \texttt{A[lo..p - 1]} e
    \texttt{A[p + 1..hi]} con quicksort}.
  \item[Combina] Non c'è \hl{nulla} da ricombinare in quanto tutto è eseguito in
    place.
\end{description}

L'algoritmo di \hl{quicksort} è \hl{molto semplice}:

\begin{lstlisting}[
  language=pseudocodice,
  gobble=2,
  caption=Quicksort
]
  Quicksort(A, lo, hi)
    if lo $<$ hi
      p `\peq` Partition(A, lo, hi)
      Quicksort(A, lo, p - 1)
      Quicksort(A, p + 1, hi)
\end{lstlisting}

La \hl{parte più importante} dell'algoritmo è \hl{\texttt{Partition()}}.
Studiamo \hl{due implementazioni di questa funzione}: una è attribuita a Lomuto
(\hl{\texttt{PartitionLomuto()}}) mentre l'altra è attribuita al creatore del
quicksort, Hoare (\hl{\texttt{PartitionHoare()}}).

\noindent\begin{minipage}{\textwidth}
  \centering
  \begin{minipage}{0.45\textwidth}
    \centering
    \begin{lstlisting}[
        language=pseudocodice,
        gobble=6,
        caption=Partizione secondo Lomuto
      ]
      PartionLomuto(A, lo, hi)
        pivot `\peq` A[hi]
        i `\peq` lo - 1
        for j `\peq` lo to hi
          if A[j] $\leq$ pivot
            i `\peq` i + 1
            Scambia(A, i, j)
        Scambia(A, i + 1, hi)
    \end{lstlisting}
  \end{minipage}
  \begin{minipage}{0.45\textwidth}
    \centering
    \begin{lstlisting}[
        language=pseudocodice,
        gobble=6,
        caption=Partizione secondo Hoare
      ]
      PartitionHoare(A, lo, hi)
        pivot `\peq` A[lo]
        i `\peq` lo - 1
        g `\peq` hi + 1
        while true
          do
            i `\peq` i + 1
          while A[i] $<$ pivot
          do
            j `\peq` j - 1
          while A[1] $>$ pivot
          if i $<$ j
            Scambia(A, i, j)
          else
            return j
    \end{lstlisting}
  \end{minipage}
\end{minipage}

La \hl{complessità della partizione secondo Lomuto è $\Theta(n)$}, come
\hl{anche quella di Hoare} ma la \hl{seconda effettua (in media) $1/3$ degli
scambi rispetto alla prima}. La partizione di \hl{Hoare} ha anche \hl{un altro
vantaggio}: \hl{se il vettore è composto da solo elementi uguali non eseguiamo
nessuno scambio}.

La \hl{complessità del quicksort} sarà:

\begin{equation}
  \mhl{
    T(n) = T(n/a) + T(n - n/a) + \Theta(n)
  }
\end{equation}

Dove \hl{$a$ dipende da quanto bene \texttt{Partition()} ha suddiviso il
vettore}. Il \hl{caso pessimo} del quicksort è un \hl{vettore diviso in porzioni
lunghe $n-1$ e $1$}. La ricorrenza diventerebbe:

\begin{equation}
  \mhl{
    T(n) = T(n-1) + T(1) + \Theta(n)
  }
\end{equation}

Che si dimostra facilmente essere \hl{$\Theta(n^2)$}. È un \hl{caso molto
specifico e molto poco probabile} nella vita reale in quanto i vettori sono
solitamente ordinati in modo casuale. Il \hl{caso ottimo} è un \hl{vettore
diviso in due porzioni lunghe $n/2$}. La ricorrenza diventa:

\begin{equation}
  \mhl{
    T(n) = 2T(n/2) + \Theta(n)
  }
\end{equation}

La \hl{stessa del merge sort}, che è \hl{$\Theta(n\log(n))$}. La \hl{costante
nascosta} dalla notazione asintotica si può calcolare ed \hl{è pari a $1.39$
rendendo il quicksort solo $39\%$ più lento del minimo teorico}.

\subsubsection{Counting sort}\label{sec:counting-sort}

Sappiamo che \hl{non è possibile essere più veloci di $\Theta(n\log(n))$ usando
algoritmi di ordinamento per confronto}. Le cose cambiano se però \hl{eliminiamo
la necessità di effettuare confronti}. Consideriamo un \hl{set di dati di cui
sappiamo che il dominio ha dimensioni contenute}. Un metodo per per ordinare gli
elementi senza confrontarli è \hl{calcolare prima l'istogramma delle frequenze}
e poi \hl{restituirne gli elementi in ordine}. Questa è l'idea dietro al
\hl{counting sort}.

\begin{lstlisting}[
  language=pseudocodice,
  gobble=2,
  caption=Counting sort
]
  CountingSort(A)
    Is[0..k] `\peq` 0 // operazione dal costo $\Theta(k)$
    for i `\peq` 0 to A.length
      Is[A[i]] `\peq` Is[A[i]] + 1
    idxA `\peq` 0
    for i `\peq` 0 to k
      while Is[i] $>$ 0
        A[idxA] `\peq` i
        idxA `\peq` idxA + 1
        Is[i] `\peq` Is[i] - 1
\end{lstlisting}

La complessità temporale è \hl{dominata dalle righe 6--10: $\Theta(n + k)$},
dove $k$ è la dimensione del nostro dominio. \hl{Se $k \gg n$ la complessità
sfugge dal controllo}.

Nella \hl{versione sopra}, il counting sort \hl{non è stabile}. È possibile,
però, escogitare una strategia per renderlo stabile. Il \hl{counting sort
stabile} parte come la variante instabile con il \hl{calcolare il numero delle
occorrenze di ogni elemento}. L'\hl{istogramma} costruito, però, viene
\hl{trasformato nel vettore contenente il conteggio degli elementi con valori
maggiori o uguali dell'indice del vettore}. Calcolato ciò, \hl{piazza un
elemento calcolando la sua posizione come il valore corrente dell'informazione
nel vettore, decrementandola}.

\begin{lstlisting}[
  language=pseudocodice,
  gobble=2,
  caption=Counting sort (versione stabile)
]
  CountingSort(A) // variante out-of-place
    B[0..A.length - 1] `\peq` 0
    Is[0..k] `\peq` 0
    for i `\peq` 0 to A.length
      Is[A[i]] `\peq` Is[A[i]] + 1
    sum `\peq` 0
    for i `\peq` 0 to k // calcola il numero di elementi $\leq$ i
      sum `\peq` sum + Is[i]
    for i `\peq` A.length - 1 to 0
      idx `\peq` Is[A[i]]
      B[idx - 1] `\peq` A[i]
      Is[A[i]] `\peq` Is[A[i]] - 1
    return B
\end{lstlisting}

\section{Strutture dati}\label{sec:strutture-dati}

Fino ad ora non ci siamo mai preoccupati del \hl{modo in cui abbiamo salvato i
nostri dati in memoria}. L'\hl{unico modo}, e il più semplice, che abbiamo usato
è stato quello di \hl{salvare tutti gli elementi in sequenza}. Questa modalità
di salvataggio, o \hl{struttura dati}, viene detta \hl{vettore}. Analizziamo
quindi come è possibile distribuire in memoria collezioni di elementi in modo
ottimizzato e intelligente.

Una \hl{struttura dati usa delle etichette opache (chiavi) per identificare gli
oggetti al suo interno. Esse, inoltre, supportano diverse operazioni sui loro
contenuti}:

\begin{itemize}
  \item \hl{\texttt{Search(S, k)}}: ricerca in \texttt{S} dell'elemento con chiave
    \texttt{k};
  \item \hl{\texttt{Minimum(S)}}: ricerca dell'elemento più piccolo in \texttt{S};
  \item \hl{\texttt{Maximum(S)}}: ricerca dell'elemento più grande in \texttt{S};
  \item \hl{\texttt{Successor(S, x.k)}}: restituisce il successore di \texttt{x} (se
    ordinati) o della sua chiave \texttt{k} in \texttt{S};
  \item \hl{\texttt{Predecessor(S, x.k)}}: restituisce il predecessore di \texttt{x}
    (se ordinati) o della sua chiave \texttt{k} in \texttt{S};
  \item \hl{\texttt{Insert(S, x)}}: inserisce \texttt{x} in \texttt{S};
  \item \hl{\texttt{Delete(S, x)}}: rimuove \texttt{x} da \texttt{S}.
\end{itemize}

\subsection{Vettori}\label{sec:array}

Analizziamo ora la complessità dei vettori. Essi sono una struttura compatta in
memoria in cui si accede direttamente ad ogni elemento data la sua posizione.
L'\hl{indice del vettore} agisce come \hl{chiave} a tutti gli effetti.

Se il \hl{vettore di lunghezza \texttt{n} non è ordinato le operazioni sopra
sono tutte lineari. Se il vettore è, invece, ordinato}:

\begin{itemize}
  \item \hl{Minimo e massimo sono costanti}, mentre \hl{ricerca e successore
    $\Theta(\log(n))$}.
  \item \hl{Inserimento e cancellazione} rimangono \hl{$\mathcal{O}(n)$}.
\end{itemize}

Inoltre gli \hl{inserimenti in un vettore pieno} possono o essere
\hl{rifiutati}, quindi \hl{$\Theta(1)$}, oppure \hl{causare una riallocazione},
quindi \hl{$\mathcal{O}(n)$}.

\subsection{Liste semplicemente connesse}\label{sec:linked-list}

Una lista semplice stocca gli \hl{elementi in modo sparso}: ogni elemento ha un
\hl{riferimento al successivo (puntatore)}. Se la \hl{lista di lunghezza
\texttt{n} non è ordinata} abbiamo che, come il vettore, \hl{tutte le operazioni
sono lineari tranne l'inserimento che è costante} (sempre in testa) e \hl{la
cancellazione se viene fornito un riferimento all'elemento}. Se la \hl{lista è,
invece, ordinata}:

\begin{itemize}
  \item \hl{Uno dei due tra minimo e massimo è $\Theta(1)$, l'altro
    $\Theta(n)$}. Se aggiungiamo un \hl{puntatore accessorio} diventano
    \hl{entrambi costanti}.
  \item \hl{Ricerca e successore sono $O(n)$}.
  \item \hl{Inserimento e cancellazione} diventano entrambi \hl{$O(n)$}.
\end{itemize}

\subsection{Pile o stack}\label{sec:stack}

Una pila è una \hl{struttura dati LIFO} che \hl{supporta} solo le seguenti
operazioni: \hl{\texttt{Push(S, e)}, \texttt{Pop(S, e)} e \texttt{Empty(S)}}.
Una stack può essere \hl{implementata} sia usando una \hl{lista} che un
\hl{vettore}.

Se usiamo l'\hl{implementazione basata sulla lista, le 3 operazioni sono tutte
costanti}. Se utilizziamo quella \hl{basata sul vettore}, invece, dobbiamo
utilizzare \hl{una variabile ausiliaria} (\texttt{ToS}, \texttt{Top Of Stack})
\hl{per mantenere la complessità costante}. Inoltre \hl{\texttt{Push()}} può
avere \hl{costo lineare in caso di riallocazione}.

Nella pratica, avere dati sparsi in memoria può penalizzare la performance a
causa delle cache-misses. Può, quindi, valere la pena di usare una stack basata
su un vettore usando uno schema di riallocazione intelligente.

\subsection{Code o queues}\label{sec:queue}

Una coda è una \hl{struttura dati FIFO} che \hl{supporta} solo le seguenti
operazioni: \hl{\texttt{Enqueue(Q, e)}, \texttt{Dequeue(Q)} e
\texttt{Empty(Q)}}. Come nel caso delle pile, è \hl{possibile realizzare} una
coda sia con una \hl{lista} che con un \hl{vettore}.

\paragraph{Vettore} Se realizziamo una coda \hl{con vettore}, lo \hl{stoccaggio}
dei dati sarà effettuato in un \hl{vettore \texttt{A} lungo \texttt{l} con
indice del primo elemento \texttt{0}}. Teniamo traccia della \hl{posizione dove
va inserito un nuovo elemento e di quella dell'elemento più vecchio con due
indici \texttt{tail} e \texttt{head} e del numero di elementi contenuti
\texttt{n}}. Gli \hl{indici} verranno \hl{incrementati modulo \texttt{l}}
(vettore circolare). Le \hl{operazioni} saranno \hl{implementate} così:

\begin{itemize}
  \item \hl{\texttt{Enqueue(Q, e)}:} se \texttt{n < l}, \hl{inserisci l'elemento
    in \texttt{A[tail]} e incrementa \texttt{n} e \texttt{tail}}, altrimenti
    segnala l'errore. Abbiamo una complessità \hl{costante}.
  \item \hl{\texttt{Dequeue(Q, e)}:} se \texttt{n > 0}, \hl{restituisci
    \texttt{A[head]} corrente, decrementa \texttt{n} e incrementa
    \texttt{head}}. Abbiamo ancora complessità \hl{costante}.
  \item \hl{\texttt{Empty(Q)}:} restituisci \hl{\texttt{n == 0}}. Ovviamente
    \hl{costante}.
\end{itemize}

\noindent Per \hl{ampliare lo stoccaggio}, possiamo \hl{creare una nuova coda di
dimensione maggiori e spostare gli elementi uno a uno usando \texttt{Enqueue()}
e \texttt{Dequeue()}}.

\paragraph{Lista} Se usiamo una \hl{lista teniamo traccia dell'ultimo elemento
della lista (oltre al primo) con un puntatore} \texttt{tail}, mantenendo
\hl{invariati} gli \hl{algoritmi} delle varie operazioni. Possiamo, quindi,
\hl{mantenere la complessità costante}.

\subsection{Mazzo (deque)}\label{sec:deque}

È una struttura dati che si comporta \hl{come un mazzo di carte}. Possiamo
vederla anche come una \hl{pila in cui è possibile aggiungere sia in testa che
in coda}. Le \hl{operazioni} supportate sono: \hl{\texttt{PushFront(Q,e)},
\texttt{PushBack(Q,e)}, \texttt{PopFront(Q)}, \texttt{PopBack(Q)} e
\texttt{Empty(Q)}}. Come le pile e le code, il mazzo \hl{può essere implementato
sia con un vettore, sia con una lista}.

\paragraph{Vettore} Se usiamo un vettore, adottiamo una \hl{strategia analoga a
quella usata per le code implementate con vettore}:

\begin{itemize}
  \item \hl{\texttt{PushBack()} e \texttt{PopFront()}} si comportano
    rispettivamente \hl{come \texttt{Enqueue()} e \texttt{Dequeue()}}.
  \item La \hl{\texttt{PopBack()}} \hl{restituisce \texttt{A[tail]}, decrementa
    \texttt{n} e \texttt{tail} se \texttt{n > 0}}. Complessità \hl{costante}.
  \item La \hl{\texttt{PushFront()} decrementa \texttt{head}, inserisce
    l'elemento in \texttt{A[head]} e incrementa \texttt{n} se \texttt{n < l}}.
    Complessità \hl{costante}.
  \item La \hl{\texttt{Empty()}} restituisce \hl{\texttt{n = 0}}. Complessità
    \hl{costante}.
\end{itemize}

\noindent Anche per \hl{ampliare lo stoccaggio} useremo la \hl{stessa strategia}
che abbiamo usato per le \hl{code}.

\paragraph{Lista} Per \hl{implementare} un mazzo con una \hl{lista non basta più
una lista semplice}, singolarmente concatenata, ma \hl{serve una doppiamente
concatenata}. Questo ci permette di aggiungere e rimuovere in testa e in coda in
tempo costante.

\begin{itemize}
  \item \hl{\texttt{PushBack()} e \texttt{PopFront()}} si comportano come
    \hl{\texttt{Enqueue()} e \texttt{Dequeue()}} di una coda realizzata con una
    lista.
  \item La \hl{\texttt{PopBack()} restituisce \texttt{tail.prev} corrente se
    diverso da \texttt{head}, rimuovendolo dalla lista}. Costo \hl{costante}.
  \item La \hl{\texttt{PushFront()} aggiunge un elemento in testa, aggiornando
    \texttt{head} e il suo successore}. Costo \hl{costante}.
  \item la \hl{\texttt{Empty()}} restituisce \hl{\texttt{head.next =
    tail.prev}}. Costo \hl{costante}.
\end{itemize}

\subsection{Dizionari}\label{sec:dictionary}

Il dizionario è una \hl{struttura dati astratta} che contiene \hl{elementi
accessibili direttamente data la loro chiave}. Assumiamo che le \hl{chiavi}
siano \hl{numeri naturali}, nel caso che non lo siano è sufficiente considerare
la loro rappresentazione binaria e il corrispondente numero. Le \hl{operazioni}
supportate sono \hl{\texttt{Insert()}, \texttt{Delete()} e \texttt{Search()}}.
Un dizionario può essere implementato con diverse strutture dati concrete.

\subsubsection{L'approccio ingenuo}\label{sec:dictionary-key-array}

Un primo \hl{approccio ingenuo} è quello di considerare un \hl{insieme di chiavi limitato}
e \hl{implementare un dizionario come un semplice array di puntatori indicizzato
dalle chiavi stesse}. Le operazioni sarebbero:

\begin{itemize}
  \item \texttt{Insert()}: \texttt{D[e.key] \peq{} e}
  \item \texttt{Delete()}: \texttt{D[e.key] \peq{} NIL}
  \item \texttt{Search()}: \texttt{return D[e.key]}
\end{itemize}

La \hl{complessità computazionale} è \hl{costante} per tutte le operazioni. La
\hl{complessità spaziale}, invece, sarà \hl{$\mathcal{O}(|D|)$}, con \hl{$D$ il
dominio delle chiavi}. Quindi anche per chiavi abbastanza semplici, questa
implementazioni sarebbe assai onerosa in termini di spazio.

\subsubsection{Tabelle Hash}\label{sec:hash-tables}

Una \hl{tabella hash implementa un dizionario con una complessità di memoria
pari al numero di chiavi per cui è effettivamente presente un valore}. Quindi il
\hl{domino delle chiavi può essere arbitrariamente grande}, persino infinito.

Il \hl{tipico approccio} per una implementazione è \hl{preallocare spazio per
\texttt{m} chiavi e riallocare solo quando ci saranno \texttt{n > m} chiavi}.
Come \hl{indice} di questo vettore useremo il \hl{risultato di una speciale
funzione $h(k): D \to \{0, \ldots, m-1\}$ detta funzione di hash}. Se il calcolo
di \hl{$h(k)$ è $\mathcal{O}(k)$}, la tabella di hash ha la \hl{stessa
efficienza temporale} del \hl{dizionario} implementato nel \hl{precedente} modo
naif.

\paragraph{Gestione delle collisioni} \hl{Idealmente}, la \hl{funzione di hash
dovrebbe mappare ogni chiave su di un distinto elemento del suo codominio}. Ma
ciò è \hl{impossibile} poiché, per come li abbiamo definiti, \hl{$|D| \gg m$}.
Diremo che è avvenuta una \hl{collisione} ogniqualvolta \hl{dati $k_1$, $k_2$
tali che $k_1 \neq k_2$ si ha che $h(k_1) = h(k_2)$}. Vedremo 2 strategie per la
gestione efficiente dei conflitti: l'indirizzamento chiuso, o open hashing, e
l'indirizzamento aperto, o closed hashing.

\paragraph{Indirizzamento chiuso} \hl{Ogni riga}, detta \hl{bucket}, della
tabella \hl{contiene la testa di una lista} al posto del puntatore ad un singolo
elemento. Nel caso di \hl{collisione, l'elemento nuovo viene aggiunto in testa
alla lista}. Per \hl{cercare o cancellare un elemento di chiave $k$}, è
necessario \hl{cercare nell'intera lista del bucket} $h(k)$.

\paragraph{Indirizzamento aperto} In caso di collisione \hl{si seleziona secondo
una regola deterministica un altro bucket} in una procedura detta di
\hl{ispezione (probing)}. Nel caso \hl{non si trovino bucket vuoti si può
fallire}, con costo \hl{$\Theta(m)$}, \hl{oppure riallocare una tabella più
grande e reinserire} tutti gli elementi della vecchia nella nuova
\hl{(re-hashing)} con costo \hl{$\Theta(n)$}. La funzione
\hl{\texttt{Search()}}, se l'\hl{elemento non viene trovato nel suo bucket,
effettua la stessa ispezione svolta durante l'inserimento}. La
\hl{cancellazione} è effettuata \hl{inserendo} un opportuno valore, detto
\hl{tombstone} che non corrisponde ad alcuna chiave. Analizziamo diverse
possibili procedure di probing e i rispettivi vantaggi e svantaggi.

\subparagraph{Ispezione lineare} È il metodo \hl{più semplice}. Dato \hl{$h(k,
0) = a$} il \hl{bucket dove avviene la collisione} al primo tentativo \hl{($i =
0$)}, si sceglie \hl{$h(k,i) = a + ci \bmod n$} come \hl{bucket} candidato per
\hl{l'$i$-esimo tentativo}. Il \hl{problema principale} di questo metodo è il
caso in cui \hl{avvengono molte collisioni su un dato bucket}. In questo caso,
detto di \hl{clustering} delle collisioni, \hl{peggiorerà con ogni nuova
ispezione la probabilità di collisione nei bucket adiacenti}. Per \hl{alcune
scelte di $h(k)$}, è possibile avere un \hl{forte peggioramento delle
prestazioni dovuto al clustering}. È possibile avere un \hl{clustering di
dimensione logaritmica nella dimensione della tabella} a costo di effettuare il
\hl{re-hashing molto prima} che la tabella sia piena \hl{(circa a metà)}.

\subparagraph{Ispezione quadratica} Per mitigare il fenomeno del clustering,
usiamo una \hl{funzione di probing quadratica: $h(k,i) = a + c_1 i + c_2 i^2
\mod{n}$}. Insorge, però, un altro problema: \hl{la funzione di probing non
garantisce a priori la visita di tutte le celle}. \hl{Esiste} una sequenza
particolare, però, che \hl{visita tutte le celle nel caso di tabelle di
dimensione $2^m$}, come dimostrato dal \hl{lemma}~\ref{thm:tabelle-2-m}, Il
problema del \hl{clustering però non è ancora del tutto risolto in quanto chiavi
con la stessa posizione iniziale generano ancora clustering poiché hanno la
stessa sequenza di ispezione}. Sarà, anche in questo caso, necessario fare
\hl{re-hashing a tabella non piena}.

\begin{lem}[Sequenza di \hl{probing ideale} per tabelle di \hl{dimensione $2^m$}]\label{thm:tabelle-2-m}
  \hl{La sequenza}:

  \begin{equation}
    \mhl{
      h(k,i) = a + \frac{1}{2} i + \frac{1}{2} i^2
    }
  \end{equation}

  \hl{genera tutti i valori in $[0; n-1]$}.
\end{lem}
\begin{proof}
  Effettuiamo una dimostrazione per assurdo. Supponiamo che esistano $0 < p < q
  < n-1$ tali che $\frac{1}{2}(p + p^2) = \frac{1}{2}(q + q^2) \mod{n}$. Ciò
  implica che $p + p^2 = q + q^2 \mod{2n}$. Fattorizzando l'eguaglianza
  otteniamo che $(q-p)(p+q+1) = 0 \mod{2n}$. Analizziamo i 3 casi in cui si
  avvererebbe questa disuguaglianza:

  \begin{enumerate}
    \item Se $q - p = 0 \mod{2n}$ significa che $q = p$; contro ipotesi e quindi
      impossibile.
    \item $(p + q + 1) \neq 0 \mod{2n}$ perché per la scelta di $p$ e $q$ la
      somma rientra nel range $[1; 2n - 2]$.
    \item Poiché stiamo lavorando in modulo $2n$ e il modulo introduce divisori
      dello $0$, è possibile che $(q-p)(p+q+1) = 0 \mod{2n}$ anche con le
      considerazioni dei precedenti punti. Poiché $(q-p) - (p+q+1) = 2p + 1$,
      significa che almeno uno dei due addendi è dispari. Essendo $n = 2^m$, il
      fattore pari è per forza multiplo di $2n = 2^{m+1}$ ma abbiamo che $(q-p)
      \leq n-1$ e $(p+q+1) \leq 2n-2$ per come abbiamo scelto $p$ e $q$.
      Assurdo!
  \end{enumerate}

  È quindi impossibile che $(q-p)(p+q+1) = 0 \mod{2n}$, quindi l'ipotesi
  iniziale $\frac{1}{2}(p + p^2) = \frac{1}{2}(q + q^2) \mod{n}$ è falsa.
\end{proof}

\subparagraph{Doppio hashing} Definiamo \hl{$h(k,i) = h_1(k) + h_2 (k)i
\mod{n}$} facendo sì che \hl{l'ispezione dipenda dalla chiave}. Per
\hl{garantire che la sequenza di probing sia in grado di visitare tutte le
caselle dobbiamo fare sì che $h_2(k)$ sia coprimo con $n$}. Un modo semplice per
garantire ciò è:

\begin{itemize}
  \item \hl{Per $n = 2^m$ fare sì che $h_2$ generi solo numeri dispari}.
  \item \hl{Se $m$ è primo, fare sì che $h_2$ generi numeri minori di $m$}.
\end{itemize}

\noindent È importante che \hl{$h_2$ non restituisca mai zero}, sennò la
sequenza di probing degenererebbe.

\paragraph{Ipotesi di hashing uniforme semplice} Una \hl{opportuna scelta di
$h(k)$ fa sì che ogni chiave abbia la stessa probabilità $\frac{1}{n}$ di finire
in una qualsiasi delle $n$ celle}. Si dice che siamo in ipotesi di hashing
uniforme semplice \hl{(IHUS)}. Come possiamo \hl{determinare una ``scelta
opportuna''}? Dipende, ovviamente, dalla \hl{distribuzione delle chiavi} da
inserire. Consideriamo 2 metodi abbastanza semplici per ricavare una $h(k)$ che
soddisfa la IHUS.

\subparagraph{Metodo della divisione} Il metodo più semplice è porre \hl{$h(k) =
k \bmod n$}. La \hl{distribuzione} dei risultati \hl{non è uniforme in $\{0,
\ldots, n-1\}$ e va evitato se $m = 2^i$} in quanto $h(k)$ dipenderebbe solo dai
bit meno significativi. \hl{Non funziona però malissimo se $n$ è vicino ad una
potenza di 2}.

\subparagraph{Metodo della moltiplicazione} Un altro metodo semplice è porre
\hl{$h(k) = \lfloor n(\alpha k - \lfloor \alpha k \rfloor) \rfloor$}, con
\hl{$\alpha \in \mathbb{R}$} costante. In questo caso, la \hl{dimensione} della
tabella $n$ \hl{non è critica}. Perciò spesso \hl{si prende $n = 2^m$} in modo
da effettuare le moltiplicazioni con semplici shift. Una \hl{scelta} possibile
\hl{per $\alpha$ è la sezione aurea $\frac{\sqrt{5} + 1}{2}$}: si è visto
empiricamente che fornisce una buona distribuzione.

\paragraph{Costo delle operazioni} Nel \hl{caso pessimo}, ossia quello in cui
\hl{tutti gli elementi collidono}, la struttura degenera in un array/lista di
lunghezza \texttt{n}: \hl{$\mathcal{O}(n)$}. Studiamo separatamente le due
modalità di indirizzamento.

\subparagraph{Indirizzamento chiuso} Definiamo \hl{fattore di carico $\alpha =
\frac{n}{m}$}. Sotto \hl{IHUS}, abbiamo che la \hl{lunghezza media della lista
sarà il fattore di carico}. Quindi il \hl{tempo medio per cercare una chiave non
presente sarà $\Theta(\alpha + 1)$}, come \hl{anche} quello per la \hl{ricerca
di una chiave presente} nella tabella. Quindi \hl{se $\alpha$ non è eccessivo},
\hl{in media} tutte le operazioni avranno complessità \hl{$\Theta(1)$}.

\subparagraph{Indirizzamento aperto} Il tempo impiegato per trovare un elemento
\hl{dipenderà dalla sequenza di ispezione}. \hl{Generalizziamo la IHUS} dicendo
che anche \hl{tutte le sequenze di ispezione siano equiprobabili}. Il
\hl{fattore di carico} è sempre definito alla \hl{stessa maniera}. Se
consideriamo \hl{$X$ la v.a. che modella il numero di passi di ispezione fatti
senza trovare il valore desiderato}, abbiamo che \hl{$P(X > i) = \alpha^{i+1}$}.
Il valore medio sarà \hl{$E(X) = \frac{1}{1-\alpha}$}. Il \hl{numero medio di
tentativi} è ricavato assumendo di trovarlo insieme al $j$-esimo tentativo e
mediando il numero di insuccessi su tutte le $n$ chiavi presenti nella tabella:
\hl{si ottiene $\frac{1}{\alpha}\log(\frac{1}{1-\alpha}$}.

\paragraph{Hashing universale} Finora abbiamo \hl{ipotizzato} che le
\hl{collisioni fossero accidentali}. Esse però possono essere \hl{indotte
sfruttando debolezze della funzione di hashing}. Un modo per evitare questo
problema è \hl{non scegliere una sola funzione di hashing, ma una intera
famiglia di buone funzioni}. Si può dimostrare che \hl{$h_{a,b}(k) = ((ak + b)
\bmod p) \bmod n$ con $p > n$ primo distribuisce uniformemente le chiavi della
tabella per ogni $a,b \in \mathbb{Z}_0$}. Sarà quindi sufficiente \hl{scegliere
casualmente $a$ e $b$ per ogni istanza della tabella}.

\subsection{Alberi binari}\label{sec:tree}

Vediamo ora una importante struttura dati: l'albero. Abbiamo già fatto uso degli
alberi in maniera informale. Gli alberi con adeguate proprietà sono una
\hl{rappresentazione efficiente per insiemi di dati ordinati}.

\begin{defn}[Albero]\label{def:tree}
  Un albero è una \hl{coppia $(V, E)$} dove \hl{$V$} è un insieme di \hl{nodi} e
  \hl{$E$} un insieme di \hl{archi}, ossia di \hl{coppie di nodi ordinate}.
  \hl{Ogni nodo può apparire un'unica volta come destinazione di un arco}
  (secondo elemento della coppia). \hl{Non sono possibili cicli}.
\end{defn}

Chiameremo \hl{radice l'unico nodo dell'albero privo di un arco entrante},
mentre \hl{foglia quelli senza archi uscenti}. Il \hl{padre} di un nodo sarà il
\hl{nodo da cui l'arco entrante in esso ha origine}; \hl{viceversa il figlio} di
un nodo è il nodo in cui degli archi uscenti da esso termina. Chiameremo
\hl{livello} la \hl{distanza in numero di archi tra la radice ed un nodo} e,
infine, diremo che un \hl{albero è completo se non è possibile aggiungere un
nodo con livello minore o uguale a quello dei nodi già presenti}.

Noi studieremo gli \hl{alberi binari}, ossia alberi in cui un nodo ha \hl{al massimo 2
figli}. È utile dare una definizione ricorsiva di albero binario:

\begin{defn}[Albero binario]\label{def:binary-tree}
  Un albero è formato da un nodo radice a cui sono collegati due alberi,
  quello destro e quello sinistro. Un albero può essere vuoto.
\end{defn}

Le azioni sull'albero \hl{indicizzeranno i nodi con una chiave intera}, in modo
simile a come facevamo per le tabelle di hash. Definiamo un nodo \texttt{N} la
struttura:

\begin{lstlisting}[language=pseudocodice,gobble=2]
  struct Node:
    Node left;   // figlio sinistro
    Node right;  // figlio destro
    Node parent; // padre (NIL per la radice)
    int   key;   // chiave
    Data  data;
\end{lstlisting}

\hl{Ogni albero \texttt{A} è un riferimento alla radice}.

Un albero può essere \hl{materializzato in memoria con una struttura basata su
puntatori} oppure tramite un \hl{array: la radice sarà l'elemento con indice 0;
dato un nodo contenuto in posizione $i$ il suo figlio sinistro sarà in posizione
$2i+1$ e quello destro in $2i + 2$; dato un nodo in posizione $i$ il padre sarà
salvato in posizione $\lfloor \frac{i-1}{2} \rfloor$}.

\paragraph{Visita di un albero} L'operazione naturale di un albero, oltre ai
consueti inserimento, ricerca e cancellazione, è l'attraversamento (o visita).
La visita di un albero \hl{consiste nell'enumerare le chiavi contenute secondo
un particolare ordine}. Ovviamente le visite avranno tutte complessità
\hl{$\Theta(n)$} con \hl{$n$ il numero di nodi dell'albero}. Vediamo alcune
delle strategie più usate.

\noindent\begin{minipage}{\textwidth}
  \centering
  \begin{minipage}{0.45\textwidth}
    \centering
    \begin{lstlisting}[
      language=pseudocodice,
      gobble=6,
      caption=Visita in ordine
    ]
      InOrder(T)
        if T = NIL
          return
        InOrder(T.left)
        Print(T.key)
        InOrder(T.right)
    \end{lstlisting}
  \end{minipage}
  \begin{minipage}{0.45\textwidth}
    \centering
    \begin{lstlisting}[
      language=pseudocodice,
      gobble=6,
      caption=Visita anticipata
    ]
      PreOrder(T)
        if T = NIL
          return
        Print(T.key)
        PreOrder(T.left)
        PreOrder(T.right)
    \end{lstlisting}
  \end{minipage}
  \begin{minipage}{0.45\textwidth}
    \centering
    \begin{lstlisting}[
      language=pseudocodice,
      gobble=6,
      caption=Visita posticipata
    ]
      PostOrder(T)
        if T = NIL
          return
        PostOrder(T.left)
        PostOrder(T.right)
        Print(T.key)
    \end{lstlisting}
  \end{minipage}
\end{minipage}

\subsubsection{Alberi binari di ricerca}\label{sec:bst}

Uno degli usi più comuni degli alberi binari è utilizzare quelli per cui è
\hl{valida una data relazione tra le chiavi}. Vediamo uno particolare di questi:
\hl{l'albero di ricerca binario o BST}.

\begin{defn}[Albero di ricerca binario]\label{def:bst}
  Un albero binario è detto albero di ricerca binario (BST) se \hl{per un
  qualunque suo nodo valgono}:

  \begin{enumerate}
    \item \hl{Se $y$ è contenuto nel sotto-albero sinistro di $x$ vale
      $y.key \leq x.key$}
    \item \hl{Se $y$ è contenuto nel sotto-albero destro di $x$ vale
      $y.key \geq x.key$}
  \end{enumerate}
\end{defn}

È ovvio che \hl{inserimenti e cancellazioni devono conservare questo invariante}.
Una \hl{visita in ordine} (\texttt{InOrder()}) del BST \hl{stampa le chiavi in ordine}.
Se nella definizione~\ref{def:bst} rendiamo le \hl{disuguaglianze strette} otteniamo
un BST che \hl{non accetta elementi duplicati}. Vediamo ora le principali operazioni
eseguibili su un BST.

\paragraph{Ricerca} La struttura dei BST li rende candidati naturali per una
ricerca efficiente. L'\hl{algoritmo}~\ref{lst:bst-search} ha \hl{complessità
$\mathcal{O}(h)$} dove \hl{$h$ è l'altezza dell'albero}. Nel \hl{caso ottimo},
ossia di \hl{albero ben bilanciato}, la complessità migliora a
\hl{$\mathcal{O}(\log(n))$}, mentre nel \hl{caso} pessimo, ossia di albero
\hl{degenerato a lista}, peggiora a \hl{$\mathcal{O}(n)$}.

\begin{lstlisting}[
  language=pseudocodice,
  gobble=2,
  caption=Ricerca in un BST,
  label=lst:bst-search
]
  Ricerca(T,x)
    if T = NIL or T.key = x.key
      return T
    if T.key < x.key
      return Ricerca(T.right, x)
    else
      return Ricerca(T.left, x)
\end{lstlisting}

\paragraph{Minimo e massimo} Cerchiamo l'elemento con chiave minima (massima),
ossia quello più a sinistra (destra) del BST. Come prima, la complessità è
$\mathcal{O}(h)$.

\noindent\begin{minipage}{\linewidth}
  \centering
  \begin{minipage}{0.45\linewidth}
    \centering
    \begin{lstlisting}[
        language=pseudocodice,
        gobble=6
      ]
        Min(T)
          cur `\peq` T
          while cur.left $\neq$ NIL
            cur `\peq` cur.left
          return cur
    \end{lstlisting}
  \end{minipage}
  \begin{minipage}{0.45\linewidth}
    \centering
    \begin{lstlisting}[
        language=pseudocodice,
        gobble=6
      ]
        Min(T)
          cur `\peq` T
          while cur.right $\neq$ NIL
            cur `\peq` cur.right
          return cur
    \end{lstlisting}
  \end{minipage}
\end{minipage}

\paragraph{Successore} Il \hl{successore di un elemento $x$ di un elemento è
l'elemento $y$ con la più piccola chiave maggiore di di quella di $x$} nel BST.
Abbiamo due casi possibili di ricerca:

\begin{itemize}
  \item Il \hl{sotto-albero destro di $x$ non è vuoto}, significando che il
    \hl{successore} di $x$ sarà il \hl{minimo di quel sotto-albero}.
  \item Il sotto-albero destro di $x$ è vuoto, significando che il
    \hl{successore di $x$ sarà il progenitore più prossimo a $x$ per cui $x$
    appare nel suo sotto-albero sinistro}.
\end{itemize}

\noindent Lo pseudocodice della ricerca del successore è
l'algoritmo~\ref{lst:bst-next}. Anche in questo caso la complessità è
\hl{$\mathcal{O}(h)$}, sia nel caso ottimo che nel pessimo.

\begin{lstlisting}[
  language=pseudocodice,
  gobble=2,
  caption=Ricerca del successore in un BST,
  label=lst:bst-next
]
  Successore(x)
    if x.right $\neq$ NIL
      return Min(x.right)
    y `\peq` x.p
    while y $\neq$ NIL and t.right = x
      x `\peq` y
      y `\peq` y.p
    return y
\end{lstlisting}

\paragraph{Inserimento} L'inserimento di un nuovo elemento deve per forza
\hl{rispettare la proprietà fondamentale del BST}. Considereremo il caso di
\hl{BST che non ammette duplicati}. L'\hl{idea} di fondo è \hl{eseguire una
ricerca} (che ovviamente fallirà) e \hl{inserire il nuovo nodo nel posto
\texttt{NIL} trovato}. La complessità sarà ancora \hl{$\mathcal{O}(h)$}.

\begin{lstlisting}[
  language=pseudocodice,
  gobble=2,
  caption=Inserimento di un elemento in un BST,
]
  Inserisci(T, x)
    pre `\peq` NIL
    cur `\peq` T.root
    while cur $\neq$ NIL     // ciclo di ricerca
      pre `\peq` cur
      if x.key < cur.key
        cur `\peq` cur.key
      else
        cur `\peq` cur.right
    x.p `\peq` pre           // inserimento
    if pre = NIL
      T.root `\peq` x
    else if x.key < pre.key
      pre.left `\peq` x
    else
      pre.right `\peq` x
\end{lstlisting}

\paragraph{Cancellazione} La \hl{strategia} di cancellazione \hl{dipende dal
numero di figli dell'elemento da rimuovere}:

\begin{enumerate}
  \setcounter{enumi}{-1}
  \item L'elemento non ha figli quindi è \hl{sufficiente eliminarlo} ripulendo la
    memoria e i puntatori del padre.
  \item L'elemento può essere \hl{sostituito dal suo unico figlio} nel suo
    ruolo.
  \item \hl{Sovrascriviamo il valore dell'elemento da rimuovere con quello del
    suo successore, eliminandolo}. Il successore $s$ di un elemento con due
    figli $x$ infatti non ha mai figlio sinistro $f$: se ciò fosse vero si
    avrebbe \texttt{s.key < f.key < x.key}, ma ciò è impossibile per la
    definizione stessa di successore.
\end{enumerate}

\noindent Anche in questo caso otteniamo \hl{complessità $\mathcal{O}(h)$}. Un
algoritmo che implementa il ragionamento sopra è il seguente.

\begin{lstlisting}[
  language=pseudocodice,
  gobble=2,
  caption=Rimozione di un elemento in un BST,
]
  Cancella(T, x)
    // Individuiamo il nodo da cancellare
    if x.left = NIL or x.right = NIL
      da_canc `\peq` = x
    else
      da_canc `\peq` Successore(x)

    // Individuiamo il sotto-albero da spostare
    if da_canc.left $\neq$ NIL
      sottoa `\peq` da_canc.left
    else
      sottoa `\peq` da_canc.right
    if sottoa $\neq$ NIL
      sottoa.p `\peq` da_canc.p

    // Correggiamo il valore del padre
    if da_canc.p = NIL
      T.root `\peq` sottoa
    else if da_canc = da_canc.p.left
      da_canc.p.left `\peq` sottoa
    else
      da_canc.p.right `\peq` sottoa

    // Copiamo il valore della chiave
    if da_canc $\neq$ x
      x.key `\peq` da_canc.key
    Free(da_canc)
\end{lstlisting}

\subsubsection{Alberi RB}\label{sec:rbt}

Abbiamo visto nella sezione~\ref{sec:bst} che tutte la complessità di tutte le
operazioni dipende dall'altezza $h$ dell'albero. Nel migliore dei casi $h =
\log(n)$, nel peggiore $h = n$. \hl{È critico quindi riuscire a garantire che un
BST non degeneri a seguito di inserimenti e cancellazioni}. Si può dimostrare
che \hl{l'altezza attesa di un BST è $\mathcal{O}(\log(n))$ se le chiavi hanno
una distribuzione uniforme. A noi ci serve, però, un approccio deterministico e
necessitiamo del concetto di albero bilanciato}.

\hl{Intuitivamente}, diciamo che un \hl{albero è bilanciato quando la distanza
delle foglie dalla radice è limitata superiormente per tutte le foglie}. Una
definizione operativa analoga è stata data da Adelson-Velskii e Landis nel 1962:

\begin{defn}[Albero bilanciato]\label{def:balanced-tree}
  Un albero si dice bilanciato se \hl{per ogni nodo le altezze dei due
  sotto-alberi differiscono al più di 1}.
\end{defn}

Adelson-Velskii e Landis proposero, insieme alla definizione, anche una
\hl{modifica ai BST e ai metodi di accesso che garantisse il bilanciamento
(alberi AVL)}. Gli \hl{alberi RB} (RBT o alberi rosso-neri) sono una
\hl{ottimizzazione della versione proposta} da Adelson-Velskii e Landis che
\hl{sacrifica parte del bilanciamento} a favore di migliori prestazioni di
inserimento e rimozione.

\begin{defn}[Albero RB]\label{def:rbt}
  Definiamo \hl{albero RB} un \hl{BST i cui nodi sono dotati di un attributo aggiuntivo
  (colore)} che può assumere \hl{due valori: rosso e nero}. I \hl{nodi} dello RBT
  soddisfano le seguenti \hl{proprietà}:

  \begin{enumerate}
    \item Ogni \hl{nodo è o rosso o nero};
    \item La \hl{radice} è \hl{nera};
    \item Le \hl{foglie} sono \hl{nere};
    \item I \hl{figli di un nodo rosso sono entrambi neri};
    \item \hl{Per ogni nodo dell'albero, tutti i cammini dai suoi discendenti
      alle foglie contenute nei suoi sotto-alberi hanno lo stesso numero di nodi
      neri}.
  \end{enumerate}
\end{defn}

Chiamiamo, per comodità, \hl{altezza nera (black height) di un nodo $x$ il
valore $bh(x)$ pari al numero di nodi neri, escluso $x$ se è il caso, nel
percorso che ca da $x$ alle foglie}.

Per convenzione, consideriamo che \hl{i dati sono mantenuti unicamente nei nodi
interni e le foglie sono tutte nulle rappresentate da \texttt{T.nil}, per
definizione nero}. Anche il \hl{padre della radice punta a \texttt{T.nil}}.

Tutte le \hl{operazioni che non vanno a modificare la struttura dell'albero}
(ricerca, minimo, massimo ecc\ldots) \hl{operano come se l'albero RB fosse un
BST}. Le \hl{operazioni di inserimento e cancellazione}, invece,
\hl{necessitano di ``riparare''} l'albero, ossia ridistribuire gli elementi in
modo da non violare gli invarianti RB. \hl{Per avere una complessità
accettabile} è necessario che l'operazione di \hl{riparazione}, o
ribilanciamento, possa \hl{avvenire con modifiche solamente locali}.

\begin{thm}[Buon bilanciamento]\label{thm:rb-bilanciamento}
  Un \hl{albero RB} con \hl{$n$ nodi interni ha altezza massima}:

  \begin{equation}
    \mhl{
      h_{\mathit{max}} = 2\log(n+1)
    }
  \end{equation}
\end{thm}
\begin{proof}
  Dimostriamo che un sotto-albero con radice $x$ ha almeno $2^{bh(x)} - 1$ nodi
  per induzione sull'altezza del sotto-albero.

  \begin{description}
    \item[Caso base] $x$ è un foglia, il sotto-albero contiene almeno
      $2^{bh(x)} - 1 = 2^0 - 1 = 0$ nodi.
    \item[Passo] Dato $x$, entrambi i suoi figli hanno altezza nera $bh(x)$ o
      $bh(x) - 1$. Dato che l'altezza dei figli è minore di quella di $x$ per
      ipotesi induttiva i loro sotto-alberi hanno almeno $2^{bh(x)-1} - 1$ nodi
      interni. L'albero radicato in $x$ contiene quindi almeno
      $2^{bh(x)-1} - 1 + 2^{bh(x)-1} - 1 + 2 = 2^{bh(x)}$ nodi. Per la proprietà
      4, almeno metà dei nodi su un qualunque percorso radice-foglia sono neri.
      L'altezza nera della radice è almeno $\frac{h}{2}$, per quanto detto prima
      il sotto-albero radicato in essa contiene almeno $2^\frac{h}{2} - 1$ nodi.
      Otteniamo quindi $n \geq 2^\frac{h}{2} - 1 \to h \leq 2\log(n + 1)$.
  \end{description}
\end{proof}

Conseguenza del teorema sopra è che \hl{le operazioni di ``query'' saranno
$\mathcal{O}(2\log(n+1))$}. \hl{Se riesco a riparare} le violazioni degli
invarianti \hl{in maniera efficiente} avrò anche che \hl{le modifiche}
all'albero \hl{saranno $\mathcal{O}(2\log(n+1))$}.

\paragraph{Rotazione} Definiamo prima un'operazione di vitale importanza per il
ribilanciamento: la rotazione. Essa è \hl{un'operazione locale a due nodi di un BST
che cambia il livello a cui sono situati due nodi senza violare le proprietà del
BST}.

\begin{lstlisting}[
  language=pseudocodice,
  gobble=2,
  caption=Algoritmo della rotazione verso destra
]
  LeftRotate(T, x)
    y `\peq` x.right
    x.right `\peq` y.left
    if y.left $\neq$ T.nil
      y.left.p `\peq` x
    y.p `\peq` x.p
    if x.p = T.nil
      T.root `\peq` y
    else if x = x.p.left
      x.p.left `\peq` y
    else
      x.p.right `\peq` y
    y.left `\peq` x
    x.p `\peq` y
\end{lstlisting}

\begin{figure}[htb]
  \centering
  \begin{tikzpicture}[level distance=1.25cm]
    \node at (2.5, 0.4) {\texttt{LeftRotate(T, x)} $\to$};
    \node at (2.5, -4.25) {$\gets$ \texttt{RightRotate(T, x)}};

    \node at (0,0) {$\rho$}
      child {
        node[circle,draw] {$x$} edge from parent[->]
          child {
            node {$\alpha$} edge from parent[->]
          }
          child {
            node[circle,draw] {$y$} edge from parent[->]
              child { node {$\beta$} edge from parent [->] }
              child { node {$\gamma$} edge from parent[->] }
          }
      };

    \node at (5,0) {$\rho$}
      child {
        node[circle,draw] {$y$} edge from parent[->]
          child {
            node[circle,draw] {$x$} edge from parent[->]
              child { node {$\alpha$} edge from parent [->] }
              child { node {$\beta$} edge from parent [->] }
          }
          child {
            node {$\gamma$} edge from parent[->]
          }
      };
  \end{tikzpicture}
  \caption{Schema di funzionamento delle rotazioni di un albero}%
  \label{fig:bst-rotate}
\end{figure}

\paragraph{Inserimento} L'inserimento procede ad \hl{inserire il nuovo elemento
come se l'albero fosse un semplice BST salvo assegnare \texttt{T.nil} al posto
di \texttt{NIL} e colorare il nodo appena inserito di rosso}. L'inserimento di
un nuovo nodo rosso \hl{può causare la violazione delle proprietà 2 e 4} degli
alberi RB. È compito di \texttt{RiparaRBInserisci(z)}, dato il nodo \texttt{z}
inserito, riparare l'albero. Possono esserci diversi \hl{casi}:

\begin{itemize}
  \item \hl{Con \texttt{z.p} figlio sinistro del ``nonno'' di \texttt{z} possono
    esserci 3 casi a seconda del colore del ``zio'' e della posizione di
    \texttt{z} e del suo padre}.
  \item \hl{Simmetricamente} ci saranno 3 casi per quando il padre di \texttt{z}
    è figlio destro del ``nonno''.
\end{itemize}

\noindent Consideriamo solo i \hl{3 casi del lato sinistro}.

\begin{enumerate}
  \item \hl{Lo zio \texttt{y} è rosso}. Innanzitutto \hl{ricoloriamo
    \texttt{z.p.p}, \texttt{z.p} e \texttt{y}}. Successivamente invoco \\
    \hl{\texttt{RiparaRBInserisci(z.p.p)}} poiché \texttt{z.p.p} potrebbe avere
    un padre rosso. Se invece \hl{\texttt{z.p.p} è la radice allora posso
    ricolorarla di nero senza problemi}.
  \item \hl{Lo zio \texttt{y} è nero e \texttt{z} è figlio destro del padre
    \texttt{x}}. In questo caso eseguiamo una \hl{\texttt{LeftRotate(T, x)}
    spostando la riparazione su \texttt{z} con \texttt{z.left = x}} (caso 3).
  \item \hl{Lo zio \texttt{y} è nero e \texttt{z} è figlio sinistro del padre
    \texttt{x}}. Ci basterà \hl{scambiare i colori di \texttt{z.p.p = x.p} e
    \texttt{x}} ed eseguire una \hl{\texttt{RightRotate(T, x}.p)}.
\end{enumerate}

\begin{lstlisting}[
  language=pseudocodice,
  gobble=2,
  caption=Algoritmo di riparazione a seguito di un inserimento,
  label=lst:rb-riapara-inserisci,
]
  RiparaRBInserisci(T, z)
    while z.p.color = red
      if z.p `\peq` z.p.p.left
        y `\peq` z.p.p.right
        if y.color = red          // caso 1
          z.p.color `\peq` black
          y.color `\peq` black
          z.p.p.color `\peq` red
          z `\peq` z.p.p
        else
          if z = z.p.right        // caso 2
            z `\peq` z.p
            LeftRotate(z)
          z.p.color `\peq` black      // caso 3
          z.p.p.color `\peq` red
          RightRotate(z.p.p)
      else
        y `\peq` z.p.p.left
        if y.color = red          // caso 1
          z.p.color `\peq` black
          y.color `\peq` black
          z.p.p.color `\peq` red
          z `\peq` z.p.p
        else
          if z = z.p.left         // caso 2
            z `\peq` z.p
            RightRotate(z)
          z.p.color `\peq` black      // caso 3
          z.p.p.color `\peq` red
          LeftRotate(z.p.p)
    T.root.color `\peq` black
\end{lstlisting}

Nei \hl{casi 2 e 3} la procedura \hl{\texttt{RiparaRBInserisci()} deve solo
effettuare un cambio di colori locale e 2 o 1 rotazioni/e}. Tutte queste
operazioni sono \hl{$\mathcal{O}(k)$}. Nel \hl{primo caso} la routine
\hl{continua analizzando il nodo padre del nodo corrente}. Nel \hl{caso pessimo}
il ciclo itera un \hl{numero di volte pari a meta dell'altezza dell'albero}. Ciò
significa che l'intero inserimento prenderà al più \hl{$\mathcal{O}(\log(n))$}.

\paragraph{Cancellazione} La cancellazione procede a cancellare il nuovo
elemento \hl{come se l'albero fosse un semplice BST salvo l'uso di
\texttt{T.nil} al posto di \texttt{NIL} e invocare la procedura di
ribilanciamento}. Nel caso sia \hl{eliminato un nodo rosso è impossibile violare
le proprietà} e quindi non sarà necessario nessun cambiamento. Se il \hl{nodo
eliminato invece è nero}, la funzione \hl{\texttt{RiparaRBCancella(x)}, dato il
nodo \texttt{x} presente al posto di quello cancellato \texttt{z} ribilancia
l'albero}. La funzione di riparazione gestisce \hl{5 casi} (come
nell'inserimento, \hl{omettiamo i simmetrici} 5 casi per quando \texttt{x} è
figlio destro):

\begin{enumerate}
  \setcounter{enumi}{-1}
  \item \hl{Caso banale: \texttt{x} è rosso}. Semplicemente \hl{ricoloriamo}
    \texttt{x} di nero.
  \item \hl{\texttt{x} è nero con fratello \texttt{w} rosso}. \hl{Scambiamo i
    colori di \texttt{w} e \texttt{w.p}} e invochiamo una
    \hl{\texttt{LeftRotate(x.p)}}. Ci riconduciamo ai \hl{casi 2,3 o 4}.
  \item \hl{texttt{x} è nero con fratello \texttt{w} nero e nipoti entrambi
    neri}. Coloriamo \hl{\texttt{w} di rosso} e invochiamo \\
    \hl{\texttt{RiparaRBCancella(x.p)}}.
  \item \hl{\texttt{x} è nero con fratello \texttt{w} nero e nipote destro
    nero}. \hl{Scambiamo di colore \texttt{w} e \texttt{w.left}} ed invochiamo
    \hl{\texttt{RightRotate(w)}} riconducendoci al \hl{caso 4}.
  \item \hl{\texttt{x} è nero con fratello \texttt{w} nero e nipote destro
    rosso}. Assegnamo a \hl{\texttt{w} il colore di \texttt{w.p}} e rendiamo
    \hl{\texttt{w.right} nero}. Invochiamo quindi \hl{\texttt{LeftRotate(w.p)}}.
\end{enumerate}

\noindent Nei \hl{casi 0,1,3 e 4} della funzione \texttt{RiparaRBCancella()}
vengono effettuati un \hl{numero costante di rotazioni e scambi di colore},
rendendo il tutto \hl{$\mathcal{O}(k)$}. L'unica \hl{chiamata ricorsiva} avviene
nel \hl{caso 2}. Poiché ad ogni chiamata, nel caso pessimo, si risale di un
livello verso la radice, verranno effettuate \hl{al massimo
$\mathcal{O}(\log(n))$ chiamate}. Detto ciò, possiamo affermare che la procedura
di \hl{cancellazione sarà $\mathcal{O}(\log(n))$} come le altre operazioni di
modifica su alberi RB.

\subsubsection{Mucchi (heap)}\label{sec:heap}

Il mucchio, o heap, è una struttura dati ad albero nella quale \hl{la chiave del
nodo padre è sempre maggiore (max-heap) di quella dei figli}. \hl{Nessuna relazione
sussiste tra le chiavi di due fratelli}. È possibile definire anche la variante
dove il nodo padre è minore rispetto ai figli, creando una min-heap. Poiché
parliamo lavoriamo con alberi binari, anche la nostra heap sarà detta binaria.

\hl{Manteniamo le heaps come alberi binari quasi completi}. In memoria li
vedremo come \hl{array di elementi ordinati per livello}. Terremo anche \hl{due
attributi ausiliari: \texttt{heapsize}, il numero di elementi nello heap, e
\texttt{length} che indica la lunghezza dell'array di supporto}.

\begin{figure}[htb]
  \centering
  \begin{tikzpicture}[
    level distance=1cm,
    level 1/.style={sibling distance=2.75cm},
    level 2/.style={sibling distance=2cm}
  ]
    \node[circle,draw] {30}
      child {
        node[circle,draw] {19}
          child { node[circle,draw] {7} }
          child { node[circle,draw] {11} }
      }
      child {
        node[circle,draw] {20}
            child { node[circle,draw] {3} }
      };
  \end{tikzpicture}
  \caption{Esempio di heap salvata nel vettore $H = [ 30, 19, 20, 7, 11, 3 ]$}%
  \label{fig:es-heap}
\end{figure}

Quindi il primo elemento sarà la radice, i 2 elementi successivi saranno il
primo livello, i 4 elementi il secondo e così via. Le foglie mancanti saranno,
quindi, sempre quelle a occupare gli ultimi posti dell'array.

Gli heap, in particolare gli heap binary che affronteremo, trovano impiego per
l'\hl{implementazione di code con priorità e l'ordinamento di vettori}. Le
\hl{operazioni} su un max-heap che vedremo sono: \hl{texttt{Max()},
\texttt{Inserisci()}, \texttt{Cancella\_Max()}, \texttt{Costruisci\_Max\_Heap()}
e \texttt{Max\_Heapify()}}.

\paragraph{Operazioni} Per implementare le primitive necessarie necessitiamo di
una \hl{procedura di supporto: \texttt{Max\_Heapify()}}. Per semplicità, nel trattare
queste operazioni considereremo gli \hl{indici come 1-based}.

\subparagraph{\texttt{Max\_Heapify()}} La funzione \texttt{Max\_Heapify(A, n)}
riceve come \hl{input un array è una posizione in esso}. \hl{Si assume che i due
sotto-alberi con radice in \texttt{Left(n) = 2n} e \texttt{Right(n) = 2n + 1}
siano dei max-heap}. La \hl{routine modificherà}, quindi, \hl{\texttt{A}
affinché l'albero radicato in \texttt{n} sia un max-heap}. La procedura causerà
la discesa del nuovo valore verso le foglie finché sarà maggiore dei figli. Nel
caso pessimo la \hl{complessità sarà $\mathcal{O}(\log(n))$} in un heap con $n$
elementi.

\begin{lstlisting}[
  language=pseudocodice,
  gobble=2,
  caption=Psudocodice di \texttt{Max\_Heapify()}
]
  Max_Heapify(A, n)
    l `\peq` Left(n)
    r `\peq` Right(n)
    if l $\leq$ A.heapsize and A[l] > A[n]
      posmax `\peq` l
    else
      posmax `\peq` n
    if r $\leq$ A.heapsize and A[r] > A[posmax]
      posmax `\peq` r
    if posmax $\neq$ n
      Swap(A[n], A[posmax])
      Max_Heapify(A, posmax)
\end{lstlisting}

\subparagraph{\texttt{Costruisci\_Max\_Heap()}} La routine \hl{trasforma un
array in una heap chiamando iterativamente \texttt{Max\_Heapify()}}. Poiché uno
\hl{heap binario è sempre alto $\lfloor \log(n) \rfloor$} per come l'abbiamo
definito, il \hl{numero di nodi con altezza $h$} sarà:

\begin{equation}
  \mhl{
    h \leq \frac{2^{\lfloor \log(n) \rfloor}}{2^h} \leq \frac{n}{2^h}
  }
\end{equation}

\noindent Calcolare \hl{\texttt{Max\_Heapify()}} per un nodo richiede \hl{al più
$\mathcal{O}(h)$ spostamenti verso il basso}. Possiamo quindi calcolare il
\hl{costo complessivo sommando, per ogni livello, il costo di ``mucchificare''
ogni elemento di esso ottenendo}:

\begin{equation}
  \mhl{ \sum_{h = 0}^{\lfloor \log(n) \rfloor} \frac{n}{2^h}\mathcal{O}(h) } =
    n\mathcal{O}(\sum_{h = 0}^{\lfloor \log(n) \rfloor} \frac{h}{2^h}) =
    \mhl{ n * k }
\end{equation}

\noindent Poiché $\sum_{h = 0}^{\lfloor \log(n) \rfloor} \frac{h}{2^h}$
converge. Avremo quindi che \hl{\texttt{Costruisci\_Max\_Heap()} avrà costo
$\mathcal{O}(n)$}.

\begin{lstlisting}[
  language=pseudocodice,
  gobble=2,
  caption=Pseudocodice di \texttt{Max\_Heapify()}
]
  Costruisci_Max_Heap(A)
    A.heapsize `\peq` A.legnth
    for i `\peq` $\lfloor \mathtt{A.length/2} \rfloor$ downto 1
      Max_Heapify(A, i)
\end{lstlisting}

\subparagraph{\texttt{Max()}} Operazione banale eseguita in tempo costante:
\texttt{return A[1]}.

\subparagraph{\texttt{Cancella\_Max()}} Estrarre l'elemento con la massima
chiave \hl{costa $\mathcal{O}(\log(n))$}. \hl{In media, però, il costo è
inferiore}. Si nota come la rimozione sia più efficiente rispetto a quella in un
vettore ordinato, dove è $\mathcal{O}(n)$.

\begin{lstlisting}[
  language=pseudocodice,
  gobble=2,
  caption=Pseudocodice di \texttt{Cancella\_Max()}
]
  Cancella_Max(A)
    if A.heapsize < 1
      return $\bot$
    max `\peq` A[1]
    A[1] `\peq` A[A.heapsize]
    Max_Heapify(A, 1)
    return max
\end{lstlisting}

\subparagraph{\texttt{Inserisci()}} Inserisce un elemento con una data chiave
\texttt{key}. La \hl{complessità sarà $\mathcal{O}(\log(n))$}.

\begin{lstlisting}[
  language=pseudocodice,
  gobble=2,
  caption=Pseudocodice di \texttt{Inserisci()}
]
  Inserisci(A, key)
    A.heapsize `\peq` A.heapsize + 1
    A[A.heapsize] `\peq` key
    i `\peq` A.heapsize
    while i > 1 and A[Parent(i)] < A[i]
      Swap(A[Parent(i)], A[i])
      i `\peq` Parent(i)
\end{lstlisting}

\paragraph{Code con priorità} Una \hl{coda con priorità} è una struttura dati a
\hl{coda} in cui \hl{è possibile dare una priorità numerica agli elementi
all'interno}. Gli \hl{elementi con priorità maggiore verranno estratti sempre
prima di elementi con priorità minore} indipendentemente dall'ordine di
inserimento. L'implementazione più comune di una coda con priorità è, come già
detto prima, un max-heap nel quale la priorità di un elemento sarà la sua
chiave. L'\hl{accodamento} di nuovi elementi verrà effettuato tramite
\hl{\texttt{Inserisci()}} e la \hl{rimozione} dell'elemento con massima priorità
tramite \hl{\texttt{Cancella\_Max()}}. Quindi una coda con priorità così
implementata ha \hl{costo $\mathcal{O}(\log(n))$ sia per enqueue che per
dequeue}. La \hl{costruzione di una coda} a partire da un array tramite
\texttt{Costruisci\_Max\_Heap()}, invece, ha \hl{costo lineare}.

\paragraph{Ordinamento} Ordinare un array in ordine crescente può essere fatto
trovando il massimo tra i suoi elementi e posizionandolo sempre alla fine della
slice già ordinata. Questo è il procedimento del \hl{\texttt{SelectionSort()}}.
Un ordinamento così strutturato ha complessità $\mathcal{O}(n^2)$. \hl{Se però
prima di applicare rendiamo l'array un max-heap, riusciamo a rendere la
complessità $\mathcal{O}(n\log(n))$ nel caso pessimo. Questo è il cosiddetto
heapsort}.

\begin{lstlisting}[
  language=pseudocodice,
  gobble=2,
  caption=Pseudocodice di che implementa lo heapsort
]
  HeapSort(A)
    Costruisci_Max_Heap(A)
    for i `\peq` A.length downto 2
      Swap(A[1], A[i])
      A.heapsize `\peq` A.heapsize -1
      Max_Heapify(A, 1)
\end{lstlisting}

\noindent Come detto prima, lo \hl{heapsort ha complessità
$\mathcal{O}(n\log(n))$ in caso pessimo}, il minimo teorico. Inoltre ha
\hl{complessità spaziale costante}, rendendolo più vantaggioso rispetto al
mergesort. Nonostante ciò \hl{nel caso medio rimane più lento del quicksort}.
Come mergesort (la versione in-place) e quicksort, anche \hl{heapsort non è
stabile}.

\subsection{Grafi}\label{sec:graphs}

Il grafo è la struttura dati più naturale per rappresentare un insieme di
oggetti legati da una generica relazione. Questa relazione è rappresentata da un
insieme di coppie di oggetti, ordinate o meno.

\begin{defn}[\hl{Grafo}]\label{def:graph}
  Un \hl{grafo} è una \hl{coppia $\mathcal{G} = (\mathbf{V}, \mathbf{E})$} con
  \hl{$\mathbf{V}$ un insieme di nodi} (o vertici) e \hl{$\mathbf{E}$ un insieme
  di archi} (detti anche lati).
\end{defn}

Se un grafo ha \hl{$|\mathbf{V}|$ nodi}, esso avrà \hl{al più
${|\mathbf{V}|}^2$} archi. Forniamo della nomenclatura utile che useremo:

\begin{itemize}
  \item Due \hl{nodi collegati} da un arco si dicono \hl{adiacenti}.
  \item Un \hl{cammino tra due nodi $v_1$ e $v_2$ è un insieme di archi di cui
    il primo ha origine in $v_1$, l'ultimo termina in $v_2$ e ogni nodo compare
    almeno una volta sia come destinazione di un arco che come sorgente}.
  \item Un grafo è detto \hl{orientato} se la \hl{coppia di nodi} che
    costituisce un arco è \hl{ordinata}.
  \item Un grafo è \hl{connesso} se \hl{esiste un percorso per coppia di nodi}.
  \item Un grafo è \hl{completo} (completamente connesso) se \hl{esiste un arco
    tra ogni coppia di nodi}.
  \item Un percorso è un \hl{ciclo} se il \hl{nodo di inizio e di fine
    coincidono}. Il ciclo si dice \hl{orientato se segue la direzione degli
    archi}.
  \item Un \hl{grafo privo di cicli} è detto \hl{aciclico}.
\end{itemize}

Sono possibili due strategie per \hl{rappresentare un grafo in memoria}:
\hl{liste o matrici di adiacenza}. Le \hl{liste di adiacenza} sono un
\hl{vettore di liste lungo $|\mathbf{V}|$, indicizzato dai nomi dei nodi. Ogni
lista contiene i nodi adiacenti all'indice della sua testa}. La \hl{matrice di
adiacenza} è invece una \hl{matrice $|\mathbf{V}| \times |\mathbf{V}|$ di valori
booleani con righe e colonne indicizzate dai nomi dei nodi}. La \hl{cella alla
riga $i$, colonna $j$} contiene \hl{$1$ se l'arco $(v_i, v_j)$ è presente nel
grafo e $0$ altrimenti}. Le \hl{liste} sono una \hl{rappresentazione più
compatta se il grafo è sparso} ($|\mathbf{E}| \leq {|\mathbf{V}|}^2$) in quanto
sono \hl{$\Theta(|\mathbf{V}| + |\mathbf{E}|)$} \hl{contro} i
\hl{$\Theta({|\mathbf{V}|}^2)$} di una \hl{matrice di adiacenza}. Le \hl{matrici
di adiacenza} possono eseguire il \hl{test di appartenenza in tempo costante}.
Le \hl{liste}, invece, possono \hl{contare il numero di archi uscenti da un nodo
linearmente rispetto al numero di questi}, invece delle \hl{matrici} che sono
\hl{lineari rispetto al numero totale di nodi}.

Per rappresentare \hl{grafi non orientati} posso \hl{ottimizzare lo spazio}
sfruttandone le proprietà:

\begin{itemize}
  \item La \hl{matrice di adiacenza di un grafo non orientato è simmetrica}
    rispetto alla diagonale principale: posso \hl{stoccarne solo metà}.
  \item Nelle \hl{liste di adiacenza possono stoccare solo uno dei due archi},
    \hl{raddoppiando però il tempo di ricerca per un nodo adiacente}.
\end{itemize}

\paragraph{Operazioni sui grafi} Le operazioni sui grafi sono tipicamente di
ispezione, ossia visita in ampiezza o in profondità, oppure vanno a determinare
determinate proprietà del grafo, come ad esempio trovare le componenti connesse,
stabilire l'ordinamento topologico, trovare il percorso più breve tra due nodi e
individuare cicli. Vediamone un po'.

\subparagraph{Visita in ampiezza} Chiamata anche \hl{Breadth First Search (BFS)} è
una strategia di visita che \hl{visita tutti i nodi di un grafo $\mathcal{G}$ a
partire da una sorgente $s$ visitando prima tutti i nodi con un cammino tra loro
ed $s$ lungo $n$ prima di visitare quelli con un cammino lungo $n+1$}. Per
evitare di iterare all'infinito nel caso di cicli, \hl{useremo dei ``colori'' per
segnare i nodi}:

\begin{itemize}
  \item I nodi \hl{bianchi} devono essere \hl{ancora visitati}.
  \item I nodi \hl{grigi} sono stati \hl{visitati ma devono essere visitati
    quelli adiacenti}.
  \item I nodi \hl{neri} sono stati \hl{visitati e sono stati anche visitati gli
    adiacenti}.
\end{itemize}

\noindent Memorizzeremo \hl{in una coda, inizializzata con la sola sorgente}, i
nodi ancora \hl{da visitare}. \hl{Estrarremo un nodo dalla coda e ne visiteremo
i vicini bianchi, colorandoli di grigio calcolandone la distanza e accodandoli
affinché siano a loro volta visitati}. Marchiamo quindi il \hl{nodo estratto di
nero} e \hl{iteriamo} estraendo il successivo \hl{finché la coda non è vuota}.
La complessità totale di questo algoritmo sarà \hl{$\mathcal{O}(|\mathbf{V}| +
|\mathbf{E}|)$}.

\begin{lstlisting}[
  language=pseudocodice,
  gobble=2,
  caption=Pseudocodice che implementa un BFS
]
  VisitaAmpiezza(G, s)
    for each n $\in \mathbf{V} \setminus \{s\}$
      n.color `\peq` white
      n.dist `\peq` $\infty$
    s.color `\peq` grey
    s.dist `\peq` 0
    Q `\peq` $\emptyset$
    Enqueue(Q, s)
    while $\lnot$IsEmpty(Q)
      curr `\peq` Dequeue(Q)
      for each v $\in \mathtt{curr.adiacenti}$
        if v.color = white
          v.color `\peq` gray
          v.dist `\peq` curr.dist + 1
          Enqueue(Q, v)
        curr.color `\peq` black
\end{lstlisting}

\noindent La visita in ampiezza \hl{si può trasformare in un algoritmo di
ricerca: basta inserire un controllo appena si sta per accodare un nuovo
elemento}.

\subparagraph{Visita in profondità} A differenza della visita in ampiezza, nella
visita in profondità (\hl{Depth First Search o DFS}) \hl{visitiamo prima i nodi
adiacenti a quello dato, poi il nodo stesso seguendo i cammini fino in fondo}.
Lo pseudocodice di una DFS è \hl{uguale a quello di una BFS in qui però si
sostituisce una la coda con una pila. La complessità è la stessa}.

\subparagraph{Componenti connesse} È detta \hl{componente connessa di un grafo
$\mathcal{G}$ un insieme $\mathbf{S}$ di nodi tali per cui esiste un cammino
tra ogni coppia di essi, ma nessuno di essi è connesso a nodi non appartenenti a
$\mathbf{S}$}. Individuare le componenti connesse in un grafo \hl{equivale ad
etichettare i nodi con lo stesso valore se appartengono alla stessa componente}.
La complessità sarà \hl{$\mathcal{O}(|\mathbf{V}|)$}.

\begin{lstlisting}[
  language=pseudocodice,
  gobble=2,
  caption=Psudocodice per l'etichettatura delle componenti connesse,
  label=lst:componenti-connesse
]
  for each v $\in \mathbf{V}$
    v.etichetta `\peq` -1
  eti `\peq` 1
  for each v $\in \mathbf{V}$
    if v.etichetta = -1
      VisitaEdEtichetta(G, v, eti)
      eti `\peq` eti + 1
\end{lstlisting}

\noindent La \hl{funzione ausiliaria \texttt{VisitaEdEtichetta()}} usata
in~\ref{lst:componenti-connesse} si comporta come una \hl{BFS/DFS} che
\hl{imposta a \texttt{eti} il campo \texttt{etichetta} del nodo visitato}.

\subparagraph{Ordinamento topologico} L'\hl{ordinamento topologico} è un valore
utile da calcolare per un grafo orientato aciclico. Esso è \hl{una sequenza di
nodi tale per cui nessun nodo compare prima di un suo predecessore}. Il
predecessore di un nodo è così definito:

\begin{defn}[\hl{Predecessore}]\label{def:graph-predecessor}
  Dato un \hl{grafo orientato}, il \hl{predecessore di un nodo $v$} è un nodo
  \hl{$u$ tale per cui esiste un cammino da $u$ a $v$}.
\end{defn}

\noindent L'ordinamento topologico \hl{non è unico}! Inoltre se un \hl{grafo non
è connesso}, le \hl{componenti non connesse possono essere ordinate in qualunque
modo l'una rispetto all'altra}.

\begin{lstlisting}[
  language=pseudocodice,
  gobble=2,
  caption=Pseudocodice per calcolare l'ordinamento topologico
]
  // Come una DFS ma dopo aver colorato di nero un nodo lo
  // inseriamo in testa alla lista L
  VisitaProfOT(G, s, L)
    s.color `\peq` gray
    for each v $\in$ curr.adiacenti
      if v.color = white
        VisitaProfOT(G, v, L)
    s.color `\peq` black
    PushFront(L, s)

  OrdinamentoTopologico(G)
    for each v $\in \mathbf{V}$
      v.color `\peq` white
    for each v $\in \mathbf{V}$
      if v.color = white
        VisitaProfOT(G, s, L)
    return L
\end{lstlisting}

\subparagraph{Percorso più breve} Per l'individuazione del percorso più breve
vedremo l'\hl{algoritmo di Dijkstra}. Esso trova, dato \hl{un grafo orientato e
un suo nodo $s$}, i \hl{percorsi più brevi da un nodo a qualunque altro}.
L'algoritmo funziona \hl{sia su di un grafo classico che su un grafo pesato}. Il
principio di funzionamento è il seguente:

\begin{enumerate}
  \item \hl{Inserisco} ogni \hl{$v \in \mathbf{V} \setminus \{s\}$ in un insieme
    $\mathbf{Q}$} dopo aver impostato l'attributo \hl{distanza a $\infty$ e il
    precedente a \texttt{NIL}};
  \item \hl{Inserisco $s$ in $\mathbf{Q}$} dopo aver impostato la \hl{distanza
    di $s$ a 0 e il predecessore a \texttt{NIL}};
  \item \hl{Fin quando $\mathbf{Q}$ non è vuoto, estraggo il nodo $c$ con
    distanza minima e controllo per ogni adiacente $a$ se hanno distanza
    maggiore di \texttt{c.dist + Peso(c, a)}. Se ciò accade, impostiamo
    \texttt{a.pred \peq{} c} e \texttt{a.dist \peq{} c.dist + Peso(c, a)}}.
\end{enumerate}

\noindent Rappresenteremo l'insieme \hl{$\mathbf{Q}$ come una coda con priorità}
basata su una \hl{min-heap} dove la \hl{priorità è la distanza} in modo da
ottenere estrazione del minore in tempo costante e un cambio di priorità in
$\mathcal{O}(\log(|\mathbf{V}))$. La \hl{complessità totale risulterà
$\mathcal{O}((|\mathbf{E}| + |\mathbf{V}|)\log(|\mathbf{V}|)$}.

\begin{lstlisting}[
  language=pseudocodice,
  gobble=2,
  caption=Pseudocodice dell'algoritmo di Dijkstra
]
  DijkstraQueue(G, s)
  Q `\peq` $\emptyset$
  s.dist `\peq` 0
  for each v $\in \mathbf{V}$
    if v $\neq$ s
      v.dist `\peq` $\infty$
      v.pred `\peq` NIL
      AccodaPriorita(Q, v, v.dist)
  while Q $\neq \emptyset$
    u `\peq` CancellaMin(Q)
    for each v $\in$ u.succ
      ndis `\peq` u.dist + Peso(u, v)
      if v.dist > ndis
        v.dist `\peq` ndis
        v.prev `\peq` u
        DecrementaPriorita(Q, v, ndis)
\end{lstlisting}

\subparagraph{Individuazione di cicli} Il nostro problema è il seguente:
\hl{``Dato un grafo orientato per cui ogni nodo ha un solo successore,
determinare, dato un nodo di partenza, se il cammino che parte da esso ha
cicli''}. L'algoritmo migliore per risolvere questo problema è l'\hl{algoritmo
di Floyd}, o della lepre e della tartaruga. Illustriamo il funzionamento. Usiamo
\hl{due riferimenti $t$ ed $l$ che spostiamo per ogni iterazione: nel caso di
$t$ lo spostiamo al successore mentre nel caso di $l$ lo spostiamo al successore
del successore}. Entrambi partiranno dal nodo iniziale. Chiamiamo \hl{$C$ la
lunghezza del ciclo e $T$ quella della coda}. Quando \hl{$t$ ha effettuato $T =
qC + r$} passi, \hl{$l$} sarà sicuramente \hl{all'interno del ciclo in posizione
$qC + r \equiv_C r$ all'interno del ciclo}. \hl{Dopo altre $C-r$ mosse, $t$ si
si troverà $C-r$ posizioni nel ciclo mentre $l$ si troverà $r + 2(C-r) \equiv_C
C-r$ posizioni nel ciclo}. I due puntatori \hl{si sono incontrati!} Il
\hl{numero di mosse totale prima dell'incontro è $T+C-r=(q+1)C$}, un multiplo
della lunghezza del ciclo. Facendo \hl{ripartire da capo $t$ e muovendo $l$ a
partire dall'incontro un passo alla volta i due puntatori si rincontreranno
all'inizio del ciclo} (facilmente dimostrabile). La \hl{complessità temporale di
questo algoritmo è $\Theta(2(T+C)-r)$, mentre quella spaziale è costante}.

\begin{lstlisting}[
  language=pseudocodice,
  gobble=2,
  caption=Paseudocodice dell'algoritmo di Floyd
]
  FloydLT(G, x)
  t `\peq` x.succ
  l `\peq` x.succ.succ
  while l $\neq$ t
    t `\peq` t.succ
    l `\peq` l.succ.succ
  T `\peq` 0
  t `\peq` x
  while l $\neq$ t
    t `\peq` t.succ
    l `\peq` l.succ
    T `\peq` T + 1
  l `\peq` t.succ
  C `\peq` 0
  while l $\neq$ t
    l `\peq` l.succ
    C `\peq` C + 1
  return T, C
\end{lstlisting}

\end{document}
